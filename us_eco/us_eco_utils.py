# %%
"""
US Economic Data Utils - í†µí•© ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
- BLS APIì™€ FRED API í†µí•© ì§€ì›
- ë°ì´í„° ë¡œë“œ, ì €ì¥, ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸
- ì‹œê°í™” ë° ë¶„ì„ ê³µí†µ í•¨ìˆ˜ë“¤
- KPDS í¬ë§· ì‹œê°í™” ì§€ì›
"""

import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime as dt_datetime, timedelta
import requests
import json
import os
import sys
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
REPO_ROOT = Path(__file__).resolve().parents[1]
US_ECO_ROOT = REPO_ROOT / "us_eco"
DATA_DIR = US_ECO_ROOT / "data"
EXPORT_ROOT = REPO_ROOT

# KPDS ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
sys.path.append(str(REPO_ROOT))
from kpds_fig_format_enhanced import *


def ensure_directory(path: Path) -> Path:
    """Ensure directory exists and return the path."""
    path.mkdir(parents=True, exist_ok=True)
    return path


ensure_directory(DATA_DIR)


def data_path(*parts: str) -> Path:
    """Return a path under the shared us_eco/data directory."""
    return DATA_DIR.joinpath(*parts)


def repo_path(*parts: str) -> Path:
    """Return a path under the repository root."""
    return EXPORT_ROOT.joinpath(*parts)

# %%
# === API ì„¤ì • í´ë˜ìŠ¤ ===

class APIConfig:
    """API ì„¤ì • ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        # BLS API í‚¤ë“¤ (ê¸°ë³¸ê°’ - ê° íŒŒì¼ì—ì„œ ë®ì–´ì“¸ ìˆ˜ ìˆìŒ)
        self.BLS_API_KEY = '56b193612b614cdc9416359fd1c73a74'
        self.BLS_API_KEY2 = '0450ef37363c48b5bedd2ae6fc92dd6e'
        self.BLS_API_KEY3 = 'daf1ca7970b74e81b6a5c7a80a8b8a7f'
        self.CURRENT_BLS_KEY = self.BLS_API_KEY
        
        # FRED API í‚¤ (ê¸°ë³¸ê°’ - ê° íŒŒì¼ì—ì„œ ë®ì–´ì“¸ ìˆ˜ ìˆìŒ)
        self.FRED_API_KEY = 'f4bd434811e42e42287a0e5ccf400fff'
        
        # ì„¸ì…˜ ê°ì²´ë“¤
        self.BLS_SESSION = None
        self.FRED_SESSION = None
        
        # API ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
        self.BLS_API_AVAILABLE = True
        self.FRED_API_AVAILABLE = True
        
        try:
            import requests
            print("âœ“ requests ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê°€ëŠ¥")
        except ImportError:
            print("âš ï¸ requests ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜í•˜ì„¸ìš”: pip install requests")
            self.BLS_API_AVAILABLE = False
            self.FRED_API_AVAILABLE = False

# ì „ì—­ API ì„¤ì • ê°ì²´
api_config = APIConfig()

# %%
# === API ì´ˆê¸°í™” í•¨ìˆ˜ë“¤ ===

def initialize_bls_api(api_key=None):
    """
    BLS API ì„¸ì…˜ ì´ˆê¸°í™”
    
    Args:
        api_key: BLS API í‚¤ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
    
    Returns:
        bool: ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
    """
    global api_config
    
    if not api_config.BLS_API_AVAILABLE:
        print("âš ï¸ BLS API ì‚¬ìš© ë¶ˆê°€ (requests ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ)")
        return False
    
    if api_key:
        api_config.BLS_API_KEY = api_key
        api_config.CURRENT_BLS_KEY = api_key
    
    try:
        api_config.BLS_SESSION = requests.Session()
        print("âœ“ BLS API ì„¸ì…˜ ì´ˆê¸°í™” ì„±ê³µ")
        return True
    except Exception as e:
        print(f"âš ï¸ BLS API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def initialize_fred_api(api_key=None):
    """
    FRED API ì„¸ì…˜ ì´ˆê¸°í™”
    
    Args:
        api_key: FRED API í‚¤ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
    
    Returns:
        bool: ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
    """
    global api_config
    
    if not api_config.FRED_API_AVAILABLE:
        print("âš ï¸ FRED API ì‚¬ìš© ë¶ˆê°€ (requests ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ)")
        return False
    
    if api_key:
        api_config.FRED_API_KEY = api_key
    
    if not api_config.FRED_API_KEY or api_config.FRED_API_KEY == 'YOUR_FRED_API_KEY_HERE':
        print("âš ï¸ FRED API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    
    try:
        api_config.FRED_SESSION = requests.Session()
        print("âœ“ FRED API ì„¸ì…˜ ì´ˆê¸°í™” ì„±ê³µ")
        return True
    except Exception as e:
        print(f"âš ï¸ FRED API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def switch_bls_api_key():
    """BLS API í‚¤ë¥¼ ìˆœí™˜ ì „í™˜"""
    global api_config
    
    if api_config.CURRENT_BLS_KEY == api_config.BLS_API_KEY:
        api_config.CURRENT_BLS_KEY = api_config.BLS_API_KEY2
        print("ğŸ”„ BLS API í‚¤ë¥¼ KEY2ë¡œ ì „í™˜")
    elif api_config.CURRENT_BLS_KEY == api_config.BLS_API_KEY2:
        api_config.CURRENT_BLS_KEY = api_config.BLS_API_KEY3
        print("ğŸ”„ BLS API í‚¤ë¥¼ KEY3ë¡œ ì „í™˜")
    else:
        api_config.CURRENT_BLS_KEY = api_config.BLS_API_KEY
        print("ğŸ”„ BLS API í‚¤ë¥¼ KEY1ë¡œ ì „í™˜")

# %%
# === ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ë“¤ ===

BLS_MAX_YEAR_SPAN = 19  # inclusive span â†’ 20ë…„ ë‹¨ìœ„ ìš”ì²­


def _fetch_bls_series_range(series_id, start_year, end_year):
    """ë‹¨ì¼ BLS API í˜¸ì¶œë¡œ ì£¼ì–´ì§„ ì—°ë„ êµ¬ê°„ì„ ê°€ì ¸ì˜¨ë‹¤."""
    global api_config
    
    if not api_config.BLS_API_AVAILABLE or api_config.BLS_SESSION is None:
        print(f"âŒ BLS API ì‚¬ìš© ë¶ˆê°€ - {series_id}")
        return None

    url = 'https://api.bls.gov/publicAPI/v2/timeseries/data/'
    headers = {'Content-type': 'application/json'}

    payload = {
        'seriesid': [series_id],
        'startyear': str(start_year),
        'endyear': str(end_year),
        'catalog': False,
        'calculations': False,
        'annualaverage': False,
    }

    if api_config.CURRENT_BLS_KEY:
        payload['registrationkey'] = api_config.CURRENT_BLS_KEY

    try:
        print(f"ğŸ“Š BLSì—ì„œ ë¡œë”©: {series_id} ({start_year}~{end_year})")
        response = api_config.BLS_SESSION.post(url, data=json.dumps(payload), headers=headers, timeout=30)
        response.raise_for_status()
        
        json_data = response.json()
        
        if json_data.get('status') == 'REQUEST_SUCCEEDED':
            series_data = json_data['Results']['series'][0]['data']
            
            dates = []
            values = []
            
            for item in series_data:
                try:
                    year = int(item['year'])
                    period = item['period']
                    if period.startswith('M'):
                        month = int(period[1:])
                        date = pd.Timestamp(year, month, 1)
                        value = float(item['value'])
                        
                        dates.append(date)
                        values.append(value)
                except (ValueError, KeyError):
                    continue
            
            if dates and values:
                df = pd.DataFrame({'date': dates, 'value': values})
                df = df.sort_values('date')
                series = pd.Series(df['value'].values, index=df['date'], name=series_id)
                print(f"âœ“ BLS ì„±ê³µ: {series_id} ({len(series)}ê°œ í¬ì¸íŠ¸)")
                return series
            print(f"âŒ BLS ë°ì´í„° ì—†ìŒ: {series_id}")
            return None
        else:
            error_msg = json_data.get('message', 'Unknown error')
            print(f"âš ï¸ BLS API ì˜¤ë¥˜: {error_msg}")
            
            # Daily threshold ì´ˆê³¼ì‹œ API í‚¤ ì „í™˜ ì‹œë„
            if 'daily threshold' in error_msg.lower() or 'daily quota' in error_msg.lower():
                print("ğŸ“ˆ Daily threshold ì´ˆê³¼ - API í‚¤ ì „í™˜ ì‹œë„")
                switch_bls_api_key()
                
                # ìƒˆë¡œìš´ API í‚¤ë¡œ ì¬ì‹œë„
                payload['registrationkey'] = api_config.CURRENT_BLS_KEY
                try:
                    print(f"ğŸ”„ ìƒˆ API í‚¤ë¡œ ì¬ì‹œë„: {series_id}")
                    response = api_config.BLS_SESSION.post(url, data=json.dumps(payload), headers=headers, timeout=30)
                    response.raise_for_status()
                    
                    json_data = response.json()
                    if json_data.get('status') == 'REQUEST_SUCCEEDED':
                        series_data = json_data['Results']['series'][0]['data']
                        dates = []
                        values = []
                        
                        for item in series_data:
                            try:
                                year = int(item['year'])
                                period = item['period']
                                if period.startswith('M'):
                                    month = int(period[1:])
                                    date = pd.Timestamp(year, month, 1)
                                    value = float(item['value'])
                                    
                                    dates.append(date)
                                    values.append(value)
                            except (ValueError, KeyError):
                                continue
                        
                        if dates and values:
                            df = pd.DataFrame({'date': dates, 'value': values})
                            df = df.sort_values('date')
                            series = pd.Series(df['value'].values, index=df['date'], name=series_id)
                            print(f"âœ“ BLS ì¬ì‹œë„ ì„±ê³µ: {series_id}")
                            return series
                    
                    print(f"âŒ BLS ì¬ì‹œë„ ì‹¤íŒ¨: {series_id}")
                    return None
                except Exception as retry_e:
                    print(f"âŒ BLS ì¬ì‹œë„ ì¤‘ ì˜¤ë¥˜: {retry_e}")
                    return None
            
            return None
            
    except Exception as e:
        print(f"âŒ BLS ìš”ì²­ ì‹¤íŒ¨: {series_id} - {e}")
        return None


def get_bls_data(series_id, start_year=2020, end_year=None):
    """
    BLS APIì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (20ë…„ ì œí•œ íšŒí”¼ìš© ì²­í¬ ìš”ì²­).
    """
    if end_year is None:
        end_year = dt_datetime.now().year

    if start_year > end_year:
        print(f"âš ï¸ ì˜ëª»ëœ ì—°ë„ ë²”ìœ„: {start_year} > {end_year}")
        return None

    chunks = []
    chunk_start = start_year
    while chunk_start <= end_year:
        chunk_end = min(chunk_start + BLS_MAX_YEAR_SPAN, end_year)
        series_chunk = _fetch_bls_series_range(series_id, chunk_start, chunk_end)
        if series_chunk is not None and not series_chunk.empty:
            chunks.append(series_chunk)
        chunk_start = chunk_end + 1

    if not chunks:
        return None

    combined = pd.concat(chunks).sort_index()
    combined = combined[~combined.index.duplicated(keep='last')]
    return combined

def get_fred_data(series_id, start_date='2020-01-01', end_date=None):
    """
    FRED APIì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    
    Args:
        series_id: FRED ì‹œë¦¬ì¦ˆ ID
        start_date: ì‹œì‘ ë‚ ì§œ
        end_date: ì¢…ë£Œ ë‚ ì§œ (Noneì´ë©´ í˜„ì¬)
    
    Returns:
        pandas.Series: ë‚ ì§œë¥¼ ì¸ë±ìŠ¤ë¡œ í•˜ëŠ” ì‹œë¦¬ì¦ˆ ë°ì´í„°
    """
    global api_config
    
    if not api_config.FRED_API_AVAILABLE or api_config.FRED_SESSION is None:
        print(f"âŒ FRED API ì‚¬ìš© ë¶ˆê°€ - {series_id}")
        return None
    
    if end_date is None:
        end_date = dt_datetime.now().strftime('%Y-%m-%d')
    
    url = f'https://api.stlouisfed.org/fred/series/observations'
    params = {
        'series_id': series_id,
        'api_key': api_config.FRED_API_KEY,
        'file_type': 'json',
        'observation_start': start_date,
        'observation_end': end_date,
        'sort_order': 'asc'
    }
    
    try:
        print(f"ğŸ“Š FREDì—ì„œ ë¡œë”©: {series_id}")
        response = api_config.FRED_SESSION.get(url, params=params, timeout=30)
        response.raise_for_status()
        
        data = response.json()
        
        if 'observations' in data:
            observations = data['observations']
            
            dates = []
            values = []
            
            for obs in observations:
                try:
                    date = pd.to_datetime(obs['date'])
                    value = float(obs['value'])
                    
                    dates.append(date)
                    values.append(value)
                except (ValueError, KeyError):
                    continue
            
            if dates and values:
                series = pd.Series(values, index=dates, name=series_id)
                series = series.sort_index()
                
                print(f"âœ“ FRED ì„±ê³µ: {series_id} ({len(series)}ê°œ í¬ì¸íŠ¸)")
                return series
            else:
                print(f"âŒ FRED ë°ì´í„° ì—†ìŒ: {series_id}")
                return None
        else:
            print(f"âŒ FRED ì‘ë‹µì— ë°ì´í„° ì—†ìŒ: {series_id}")
            return None
            
    except requests.exceptions.HTTPError as e:
        if 'Bad Request' in str(e):
            print(f"âŒ FRED API ì˜¤ë¥˜: ì˜ëª»ëœ ì‹œë¦¬ì¦ˆ ID '{series_id}' - ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì‹œë¦¬ì¦ˆì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        else:
            print(f"âŒ FRED HTTP ì˜¤ë¥˜: {series_id} - {e}")
        return None
    except Exception as e:
        print(f"âŒ FRED ìš”ì²­ ì‹¤íŒ¨: {series_id} - {e}")
        return None

# %%
# === ë°ì´í„° ì €ì¥/ë¡œë“œ í•¨ìˆ˜ë“¤ ===

def ensure_data_directory(csv_file_path):
    """ë°ì´í„° ë””ë ‰í„°ë¦¬ ìƒì„± í™•ì¸"""
    path_obj = Path(csv_file_path)
    data_dir = path_obj.parent
    if not data_dir.exists():
        data_dir.mkdir(parents=True)
        print(f"ğŸ“ ë°ì´í„° ë””ë ‰í„°ë¦¬ ìƒì„±: {data_dir}")

def save_data_to_csv(data_df, csv_file_path):
    """
    ë°ì´í„°ë¥¼ CSVì— ì €ì¥
    
    Args:
        data_df: ì €ì¥í•  DataFrame
        csv_file_path: CSV íŒŒì¼ ê²½ë¡œ
    
    Returns:
        bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    if data_df.empty:
        print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    ensure_data_directory(csv_file_path)
    
    try:
        df_to_save = data_df.copy()
        df_to_save.index.name = 'date'
        df_to_save.to_csv(csv_file_path)
        print(f"ğŸ’¾ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {csv_file_path}")
        return True
    except Exception as e:
        print(f"âŒ CSV ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def load_data_from_csv(csv_file_path):
    """
    CSVì—ì„œ ë°ì´í„° ë¡œë“œ
    
    Args:
        csv_file_path: CSV íŒŒì¼ ê²½ë¡œ
    
    Returns:
        pandas.DataFrame: ë¡œë“œëœ ë°ì´í„° (ì‹¤íŒ¨ì‹œ None)
    """
    if not os.path.exists(csv_file_path):
        print("ğŸ“‚ ì €ì¥ëœ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    try:
        df = pd.read_csv(csv_file_path, index_col=0, parse_dates=True)
        print(f"ğŸ“‚ CSV ë°ì´í„° ë¡œë“œ: {len(df)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
        return df
    except Exception as e:
        print(f"âŒ CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

# %%
# === ë°ì´í„° ê³„ì‚° í•¨ìˆ˜ë“¤ ===

def calculate_mom_change(data):
    """ì „ì›”ëŒ€ë¹„ ë³€í™”ëŸ‰ ê³„ì‚°"""
    return data.diff()

def calculate_mom_percent(data):
    """ì „ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ê³„ì‚° (%)"""
    return (data.pct_change() * 100)

def calculate_yoy_change(data):
    """ì „ë…„ë™ì›”ëŒ€ë¹„ ë³€í™”ëŸ‰ ê³„ì‚°"""
    return data.diff(12)

def calculate_yoy_percent(data):
    """ì „ë…„ë™ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ê³„ì‚° (%)"""
    return (data.pct_change(12) * 100)

def calculate_average_change(data, months):
    """íŠ¹ì • ê¸°ê°„ í‰ê·  ëŒ€ë¹„ ë³€í™”ëŸ‰ ê³„ì‚°"""
    avg = data.rolling(window=months).mean()
    return data - avg.shift(1)

def calculate_average_percent_change(data, months):
    """íŠ¹ì • ê¸°ê°„ í‰ê·  ëŒ€ë¹„ ë³€í™”ìœ¨ ê³„ì‚°"""
    avg = data.rolling(window=months).mean()
    return ((data / avg.shift(1)) - 1) * 100

# %%
# === ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ í•¨ìˆ˜ë“¤ ===

def check_recent_data_consistency(csv_data, api_data, tolerance=10.0):
    """
    ìµœê·¼ ë°ì´í„°ì˜ ì¼ì¹˜ì„± í™•ì¸
    
    Args:
        csv_data: CSVì—ì„œ ë¡œë“œëœ ë°ì´í„°
        api_data: APIì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°
        tolerance: í—ˆìš© ì˜¤ì°¨
    
    Returns:
        dict: ì¼ì¹˜ì„± í™•ì¸ ê²°ê³¼
    """
    if csv_data is None or csv_data.empty:
        return {'needs_update': True, 'reason': 'CSV ë°ì´í„° ì—†ìŒ'}
    
    if api_data is None or api_data.empty:
        return {'needs_update': True, 'reason': 'API ë°ì´í„° ì—†ìŒ'}
    
    try:
        # ìµœê·¼ 3ê°œì›” ë°ì´í„° í™•ì¸
        csv_data.index = pd.to_datetime(csv_data.index)
        api_data.index = pd.to_datetime(api_data.index)

        csv_latest = csv_data.tail(3)

        csv_latest_date = csv_data.index.max()
        api_latest_date = api_data.index.max()

        if csv_latest_date is not None and api_latest_date is not None:
            if pd.notna(api_latest_date) and pd.notna(csv_latest_date):
                if api_latest_date > csv_latest_date:
                    return {
                        'needs_update': True,
                        'reason': 'API ìµœì‹  ë‚ ì§œê°€ ë” ìµœì‹ ',
                        'existing_latest': csv_latest_date.strftime('%Y-%m-%d'),
                        'api_latest': api_latest_date.strftime('%Y-%m-%d'),
                        'tolerance': tolerance,
                    }

        # ê³µí†µ ë‚ ì§œ ì°¾ê¸°
        common_dates = csv_latest.index.intersection(api_data.index)
        
        if len(common_dates) == 0:
            return {'needs_update': True, 'reason': 'ê³µí†µ ë‚ ì§œ ì—†ìŒ'}
        
        # ìµœê·¼ ë°ì´í„° ë¹„êµ
        inconsistencies = []
        
        for date in common_dates[-3:]:
            csv_row = csv_latest.loc[date]
            api_row = api_data.loc[date]
            
            for column in csv_row.index:
                if column in api_row.index:
                    csv_val = csv_row[column]
                    api_val = api_row[column]
                    
                    # NaN ê°’ ì²˜ë¦¬
                    if pd.isna(csv_val) and pd.isna(api_val):
                        continue
                    if pd.isna(csv_val) or pd.isna(api_val):
                        inconsistencies.append({
                            'date': date.strftime('%Y-%m'),
                            'series': column,
                            'csv_value': csv_val,
                            'api_value': api_val,
                            'difference': 'NaN ë¶ˆì¼ì¹˜',
                            'significant': True
                        })
                        continue
                    
                    # ì°¨ì´ ê³„ì‚°
                    diff = abs(csv_val - api_val)
                    
                    # ìœ ì˜ë¯¸í•œ ì°¨ì´ì¸ì§€ í™•ì¸
                    is_significant = diff > tolerance
                    
                    if is_significant:
                        inconsistencies.append({
                            'date': date.strftime('%Y-%m'),
                            'series': column,
                            'csv_value': csv_val,
                            'api_value': api_val,
                            'difference': diff,
                            'significant': True
                        })
        
        # ìœ ì˜ë¯¸í•œ ë¶ˆì¼ì¹˜ê°€ ìˆëŠ”ì§€ í™•ì¸
        significant_inconsistencies = [inc for inc in inconsistencies if inc['significant']]
        
        result = {
            'needs_update': len(significant_inconsistencies) > 0,
            'inconsistencies': inconsistencies,
            'significant_count': len(significant_inconsistencies),
            'total_compared': len(common_dates),
            'tolerance': tolerance
        }
        
        if result['needs_update']:
            result['reason'] = f'ìœ ì˜ë¯¸í•œ ë°ì´í„° ë¶ˆì¼ì¹˜ {len(significant_inconsistencies)}ê±´ ë°œê²¬'
        else:
            result['reason'] = 'ìµœê·¼ ë°ì´í„° ì¼ì¹˜'
        
        return result
        
    except Exception as e:
        print(f"âš ï¸ ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return {'needs_update': True, 'reason': f'í™•ì¸ ì˜¤ë¥˜: {str(e)}'}

def print_consistency_results(consistency_result):
    """ì¼ì¹˜ì„± í™•ì¸ ê²°ê³¼ ì¶œë ¥"""
    result = consistency_result
    
    print(f"\nğŸ” ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸ ê²°ê³¼")
    print(f"   ì—…ë°ì´íŠ¸ í•„ìš”: {result['needs_update']}")
    print(f"   ì‚¬ìœ : {result['reason']}")
    
    if 'inconsistencies' in result and result['inconsistencies']:
        print(f"   í—ˆìš© ì˜¤ì°¨: {result['tolerance']:,.1f}")
        print(f"   ë¹„êµ ê¸°ê°„: {result['total_compared']}ê°œì›”")
        print(f"   ì „ì²´ ë¶ˆì¼ì¹˜: {len(result['inconsistencies'])}ê±´")
        print(f"   ìœ ì˜ë¯¸í•œ ë¶ˆì¼ì¹˜: {result['significant_count']}ê±´")
        
        if result['significant_count'] > 0:
            print(f"\n   ğŸ“Š ìœ ì˜ë¯¸í•œ ì°¨ì´ ì„¸ë¶€ ë‚´ìš©:")
            for inc in result['inconsistencies']:
                if inc['significant']:
                    if isinstance(inc['difference'], str):
                        print(f"   - {inc['date']} {inc['series']}: {inc['difference']}")
                    else:
                        csv_val = inc['csv_value']
                        api_val = inc['api_value']
                        diff = inc['difference']
                        print(f"   - {inc['date']} {inc['series']}: CSV={csv_val:,.1f} vs API={api_val:,.1f} (ì°¨ì´: {diff:,.1f})")

# %%
# === ì‹œê°í™” í•¨ìˆ˜ë“¤ (KPDS í¬ë§·) ===

def create_timeseries_chart(data, series_names=None, chart_type='level', 
                           ytitle=None, korean_names=None, title=None):
    """
    ì‹œê³„ì—´ ì°¨íŠ¸ ìƒì„± (KPDS í¬ë§·)
    
    Args:
        data: DataFrame ë˜ëŠ” Series
        series_names: í‘œì‹œí•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸
        chart_type: 'level', 'mom', 'yoy', 'mom_change', 'yoy_change'
        ytitle: Yì¶• ì œëª©
        korean_names: í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
        title: ì°¨íŠ¸ ì œëª©
    
    Returns:
        plotly figure
    """
    if isinstance(data, pd.Series):
        data = data.to_frame()
    
    if series_names is None:
        series_names = data.columns.tolist()
    
    # ë°ì´í„° ì„ íƒ
    if not all(col in data.columns for col in series_names):
        available_cols = [col for col in series_names if col in data.columns]
        if not available_cols:
            print("âš ï¸ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        series_names = available_cols
    
    plot_data = data[series_names].copy()
    
    # ì°¨íŠ¸ íƒ€ì…ë³„ ë°ì´í„° ë³€í™˜
    if chart_type == 'mom':
        plot_data = calculate_mom_percent(plot_data)
        if ytitle is None:
            ytitle = "%"
    elif chart_type == 'yoy':
        plot_data = calculate_yoy_percent(plot_data)
        if ytitle is None:
            ytitle = "%"
    elif chart_type == 'mom_change':
        plot_data = calculate_mom_change(plot_data)
        if ytitle is None:
            ytitle = "ì²œ ëª…"
    elif chart_type == 'yoy_change':
        plot_data = calculate_yoy_change(plot_data)
        if ytitle is None:
            ytitle = "ì²œ ëª…"
    elif ytitle is None:
        ytitle = "ì²œ ëª…"
    
    # ì œëª© ì¶œë ¥
    if title:
        print(title)
    
    if plot_data.empty:
        print("âš ï¸ í”Œë¡¯í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ì‹œë¦¬ì¦ˆ ê°œìˆ˜ì— ë”°ë¥¸ ì°¨íŠ¸ í•¨ìˆ˜ ì„ íƒ
    if len(plot_data.columns) == 1:
        # ë‹¨ì¼ ì‹œë¦¬ì¦ˆ
        fig = df_line_chart(plot_data, plot_data.columns[0], ytitle=ytitle)
    else:
        # ë‹¤ì¤‘ ì‹œë¦¬ì¦ˆ
        if korean_names:
            labels = {col: korean_names.get(col, col) for col in plot_data.columns}
        else:
            labels = {col: col for col in plot_data.columns}
        fig = df_multi_line_chart(plot_data, plot_data.columns.tolist(), ytitle=ytitle, labels=labels)
    
    # 0ì„  ì¶”ê°€ (ë³€í™”ìœ¨/ë³€í™”ëŸ‰ ì°¨íŠ¸ì¸ ê²½ìš°)
    if chart_type in ['mom', 'yoy', 'mom_change', 'yoy_change']:
        fig.add_hline(y=0, line_width=1, line_color="black", opacity=0.5)
    
    return fig

def create_comparison_chart(data, series_names, periods=[1, 3, 6, 12], 
                           korean_names=None, title=None):
    """
    ë¹„êµ ì°¨íŠ¸ ìƒì„± (KPDS í¬ë§· ê°€ë¡œ ë°” ì°¨íŠ¸)
    
    Args:
        data: DataFrame
        series_names: ë¹„êµí•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸
        periods: ë¹„êµí•  ê¸°ê°„ë“¤ (ê°œì›” ìˆ˜)
        korean_names: í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘
        title: ì°¨íŠ¸ ì œëª©
    
    Returns:
        plotly figure
    """
    if data.empty:
        print("âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ìµœì‹  ë‚ ì§œ
    latest_date = data.index[-1]
    
    if title:
        print(title)
    
    # ì„œë¸Œí”Œë¡¯ ìƒì„±
    fig = make_subplots(
        rows=1, cols=len(periods),
        subplot_titles=[f"vs {p}ê°œì›” ì „" if p == 1 else f"vs {p}ê°œì›” í‰ê· " for p in periods],
        shared_yaxes=True,
        horizontal_spacing=0.05
    )
    
    for i, period in enumerate(periods):
        # ë°ì´í„° ê³„ì‚°
        categories = []
        values = []
        colors = []
        
        for series in series_names:
            if series not in data.columns:
                continue
            
            series_data = data[series]
            latest_value = series_data.iloc[-1]
            
            if period == 1:
                # ì „ì›” ëŒ€ë¹„
                prev_value = series_data.iloc[-2] if len(series_data) > 1 else latest_value
                change = ((latest_value / prev_value) - 1) * 100
            else:
                # Nê°œì›” í‰ê·  ëŒ€ë¹„
                avg_value = series_data.iloc[-(period+1):-1].mean()
                change = ((latest_value / avg_value) - 1) * 100
            
            if korean_names:
                korean_name = korean_names.get(series, series)
            else:
                korean_name = series
            categories.append(korean_name)
            values.append(change)
            colors.append(deepred_pds if change >= 0 else deepblue_pds)
        
        # ì •ë ¬
        sorted_data = sorted(zip(categories, values, colors), key=lambda x: x[1])
        categories, values, colors = zip(*sorted_data)
        
        # ë°” ì°¨íŠ¸ ì¶”ê°€
        fig.add_trace(
            go.Bar(
                y=list(categories),
                x=list(values),
                orientation='h',
                marker_color=list(colors),
                text=[f'{v:+.1f}%' for v in values],
                textposition='outside',
                showlegend=False
            ),
            row=1, col=i+1
        )
        
        # xì¶• ë²”ìœ„ ì„¤ì •
        max_val = max(abs(min(values)), max(values)) * 1.2
        fig.update_xaxes(range=[-max_val, max_val], row=1, col=i+1)
        
        # 0ì„  ì¶”ê°€
        fig.add_vline(x=0, line_width=1, line_color="black", row=1, col=i+1)
    
    # KPDS í°íŠ¸ ì„¤ì •
    font_family = 'NanumGothic'
    
    # ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸
    fig.update_layout(
        height=max(400, len(categories) * 40),
        width=1200,
        paper_bgcolor='white',
        plot_bgcolor='white',
        font=dict(family=font_family, size=FONT_SIZE_GENERAL, color="black")
    )
    
    # xì¶• ë¼ë²¨
    for i in range(len(periods)):
        fig.update_xaxes(
            title_text="ë³€í™”ìœ¨ (%)",
            title_font=dict(family=font_family, size=FONT_SIZE_AXIS_TITLE),
            showline=True, linewidth=1.3, linecolor='lightgrey',
            tickwidth=1.3, tickcolor='lightgrey',
            ticks='outside',
            row=1, col=i+1
        )
    
    return fig

def create_heatmap_chart(data, series_names, months=12, korean_names=None, title=None):
    """
    ë³€í™”ìœ¨ íˆíŠ¸ë§µ ìƒì„± (KPDS í¬ë§·)
    
    Args:
        data: MoM ë³€í™”ìœ¨ ë°ì´í„° DataFrame
        series_names: í‘œì‹œí•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸
        months: í‘œì‹œí•  ê°œì›” ìˆ˜ (Noneì´ë©´ ì „ì²´ ë°ì´í„°)
        korean_names: í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘
        title: ì°¨íŠ¸ ì œëª©
    
    Returns:
        plotly figure
    """
    if data.empty:
        print("âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ìµœê·¼ Nê°œì›” ë°ì´í„° (Noneì´ë©´ ì „ì²´)
    recent_data = data.tail(months) if months is not None else data
    
    # ì‹œë¦¬ì¦ˆ ì„ íƒ
    available_series = [s for s in series_names if s in recent_data.columns]
    if not available_series:
        print("âš ï¸ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ë°ì´í„° ì¤€ë¹„
    heatmap_data = recent_data[available_series].T
    
    # ë¼ë²¨ ë³€í™˜
    if korean_names:
        y_labels = [korean_names.get(col, col) for col in available_series]
    else:
        y_labels = available_series
    x_labels = [date.strftime('%Y-%m') for date in heatmap_data.columns]
    
    # ì œëª© ì¶œë ¥
    if title:
        print(title)
    
    # KPDS í°íŠ¸ ì„¤ì •
    font_family = 'NanumGothic'
    
    # íˆíŠ¸ë§µ ìƒì„±
    fig = go.Figure(data=go.Heatmap(
        z=heatmap_data.values,
        x=x_labels,
        y=y_labels,
        colorscale='RdBu_r',
        zmid=0,
        text=heatmap_data.values,
        texttemplate='%{text:.1f}%',
        textfont={"size": 10, "family": font_family},
        colorbar=dict(title="ë³€í™”ìœ¨ (%)", titlefont=dict(family=font_family, size=FONT_SIZE_AXIS_TITLE))
    ))
    
    fig.update_layout(
        xaxis=dict(
            title="ì›”",
            title_font=dict(family=font_family, size=FONT_SIZE_AXIS_TITLE),
            side="bottom",
            tickfont=dict(family=font_family, size=FONT_SIZE_GENERAL)
        ),
        yaxis=dict(
            title="ì¹´í…Œê³ ë¦¬",
            title_font=dict(family=font_family, size=FONT_SIZE_AXIS_TITLE),
            tickfont=dict(family=font_family, size=FONT_SIZE_GENERAL)
        ),
        width=1000,
        height=600,
        paper_bgcolor='white',
        plot_bgcolor='white',
        font=dict(family=font_family, size=FONT_SIZE_GENERAL, color="black")
    )
    
    return fig

def plot_economic_series(data_dict, series_list, chart_type='multi_line', data_type='mom',
                         periods=None, labels=None, left_ytitle=None, right_ytitle=None, 
                         target_date=None, korean_names=None, axis_allocation=None):
    """
    ë²”ìš© ê²½ì œ ë°ì´í„° ì‹œê°í™” í•¨ìˆ˜ - ì–´ë–¤ ê²½ì œ ë°ì´í„°ë“  ì›í•˜ëŠ” ì‹œë¦¬ì¦ˆë¡œ ë‹¤ì–‘í•œ ì°¨íŠ¸ ìƒì„±
    
    Args:
        data_dict: ë°ì´í„° ë”•ì…”ë„ˆë¦¬ (ì˜ˆ: {'raw_data': df, 'mom_data': df, 'mom_change': df})
        series_list: ì‹œê°í™”í•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['nonfarm_total', 'manufacturing'])
        chart_type: ì°¨íŠ¸ ì¢…ë¥˜ ('multi_line', 'dual_axis', 'horizontal_bar', 'single_line')
        data_type: ë°ì´í„° íƒ€ì… ('mom', 'raw', 'mom_change', 'yoy', 'yoy_change')
        periods: í‘œì‹œí•  ê¸°ê°„ (ê°œì›”, Noneì´ë©´ ì „ì²´ ë°ì´í„°)
        labels: ì‹œë¦¬ì¦ˆ ë¼ë²¨ ë”•ì…”ë„ˆë¦¬ (Noneì´ë©´ ìë™)
        left_ytitle: ì™¼ìª½ Yì¶• ì œëª© (ë‹¨ìœ„ë§Œ)
        right_ytitle: ì˜¤ë¥¸ìª½ Yì¶• ì œëª© (ë‹¨ìœ„ë§Œ)
        target_date: íŠ¹ì • ë‚ ì§œ ê¸°ì¤€ (ì˜ˆ: '2025-06-01', Noneì´ë©´ ìµœì‹  ë°ì´í„°)
        korean_names: í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
        axis_allocation: ì´ì¤‘ì¶• ì°¨íŠ¸ì—ì„œ ì™¼ìª½/ì˜¤ë¥¸ìª½ ì¶•ì— ë°°ì¹˜í•  ì‹œë¦¬ì¦ˆ ì§€ì •
    
    Returns:
        plotly figure
    """
    if not data_dict or 'raw_data' not in data_dict:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ë°ì´í„° íƒ€ì…ì— ë”°ë¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    if data_type == 'mom':
        if 'mom_data' in data_dict:
            data = data_dict['mom_data']
        else:
            data = calculate_mom_percent(data_dict['raw_data'])
        unit = "%"
        desc = "ì „ì›”ëŒ€ë¹„ ë³€í™”ìœ¨"
    elif data_type == 'raw':
        data = data_dict['raw_data']
        unit = "ì²œ ëª…"  # ê¸°ë³¸ê°’, í•„ìš”ì‹œ ìˆ˜ì •
        desc = "ìˆ˜ì¤€"
    elif data_type == 'mom_change':
        if 'mom_change' in data_dict:
            data = data_dict['mom_change']
        else:
            data = calculate_mom_change(data_dict['raw_data'])
        unit = "ì²œ ëª…"
        desc = "ì „ì›”ëŒ€ë¹„ ë³€í™”ëŸ‰"
    elif data_type == 'yoy':
        if 'yoy_data' in data_dict:
            data = data_dict['yoy_data']
        else:
            data = calculate_yoy_percent(data_dict['raw_data'])
        unit = "%"
        desc = "ì „ë…„ë™ì›”ëŒ€ë¹„ ë³€í™”ìœ¨"
    elif data_type == 'yoy_change':
        if 'yoy_change' in data_dict:
            data = data_dict['yoy_change']
        else:
            data = calculate_yoy_change(data_dict['raw_data'])
        unit = "ì²œ ëª…"
        desc = "ì „ë…„ë™ì›”ëŒ€ë¹„ ë³€í™”ëŸ‰"
    else:
        print("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” data_typeì…ë‹ˆë‹¤. 'mom', 'raw', 'mom_change', 'yoy', 'yoy_change' ì¤‘ ì„ íƒí•˜ì„¸ìš”.")
        return None
    
    if data.empty:
        print("âŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ê¸°ê°„ ì œí•œ ë˜ëŠ” íŠ¹ì • ë‚ ì§œ ê¸°ì¤€
    if target_date:
        try:
            target_date_parsed = pd.to_datetime(target_date)
            # í•´ë‹¹ ë‚ ì§œ ì´ì „ì˜ ë°ì´í„°ë§Œ ì„ íƒ
            filtered_data = data[data.index <= target_date_parsed]
            if filtered_data.empty:
                print(f"âš ï¸ {target_date} ì´ì „ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
            recent_data = filtered_data.tail(periods) if periods is not None else filtered_data
        except:
            print(f"âš ï¸ ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹ì…ë‹ˆë‹¤: {target_date}. 'YYYY-MM-DD' í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            return None
    else:
        recent_data = data.tail(periods) if periods is not None else data
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ í™•ì¸
    available_cols = [col for col in series_list if col in recent_data.columns]
    axis_allocation = axis_allocation or {}
    
    if not available_cols:
        print("âŒ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
        print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œë¦¬ì¦ˆ: {list(recent_data.columns)}")
        return None
    
    # ìë™ ë¼ë²¨ ìƒì„±
    if labels is None:
        if korean_names:
            labels = {col: korean_names.get(col, col) for col in available_cols}
        else:
            labels = {col: col for col in available_cols}
    
    # Yì¶• ì œëª© ìë™ ì„¤ì • (ë‹¨ìœ„ë§Œ)
    if left_ytitle is None:
        left_ytitle = unit
    
    # ì°¨íŠ¸ íƒ€ì…ë³„ ì‹œê°í™”
    if chart_type == 'multi_line':
        print(f"ê²½ì œ ì‹œë¦¬ì¦ˆ ë‹¤ì¤‘ ë¼ì¸ ì°¨íŠ¸ ({desc})")
        fig = df_multi_line_chart(
            df=recent_data,
            columns=available_cols,
            ytitle=left_ytitle,
            labels=labels
        )
    
    elif chart_type == 'single_line' and len(available_cols) == 1:
        print(f"ê²½ì œ ì‹œë¦¬ì¦ˆ ë‹¨ì¼ ë¼ì¸ ì°¨íŠ¸ ({desc})")
        fig = df_line_chart(
            df=recent_data,
            column=available_cols[0],
            ytitle=left_ytitle,
            label=labels[available_cols[0]]
        )
    
    elif chart_type == 'dual_axis' and len(available_cols) >= 2:
        left_cols = []
        right_cols = []

        if axis_allocation:
            requested_left = axis_allocation.get('left', [])
            requested_right = axis_allocation.get('right', [])

            left_cols = [col for col in requested_left if col in available_cols]
            right_cols = [col for col in requested_right if col in available_cols and col not in left_cols]

            remaining = [col for col in available_cols if col not in left_cols and col not in right_cols]
            for col in remaining:
                if len(left_cols) <= len(right_cols):
                    left_cols.append(col)
                else:
                    right_cols.append(col)

            if left_cols and not right_cols and len(left_cols) > 1:
                right_cols.append(left_cols.pop())
            if right_cols and not left_cols and len(right_cols) > 1:
                left_cols.append(right_cols.pop(0))

        if not left_cols or not right_cols:
            mid = len(available_cols) // 2
            left_cols = available_cols[:mid] if mid > 0 else available_cols[:1]
            right_cols = available_cols[mid:] if mid > 0 else available_cols[1:]

        if not right_cols:
            print("âŒ ì´ì¤‘ì¶• ì°¨íŠ¸ì—ëŠ” ì™¼ìª½/ì˜¤ë¥¸ìª½ ì¶•ì— ìµœì†Œ í•œ ê°œ ì´ìƒì˜ ì‹œë¦¬ì¦ˆê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return None

        print(f"ê²½ì œ ì‹œë¦¬ì¦ˆ ì´ì¤‘ì¶• ì°¨íŠ¸ ({desc})")
        fig = df_dual_axis_chart(
            df=recent_data,
            left_cols=left_cols,
            right_cols=right_cols,
            left_labels=[labels[col] for col in left_cols],
            right_labels=[labels[col] for col in right_cols],
            left_title=left_ytitle,
            right_title=right_ytitle or left_ytitle
        )
    
    elif chart_type == 'horizontal_bar':
        # ìµœì‹ ê°’ ê¸°ì¤€ ê°€ë¡œ ë°” ì°¨íŠ¸
        latest_values = {}
        for col in available_cols:
            latest_val = recent_data[col].dropna().iloc[-1] if not recent_data[col].dropna().empty else 0
            latest_values[labels[col]] = latest_val
        
        # ë‚ ì§œ ì •ë³´ í‘œì‹œ
        latest_date = recent_data.index[-1].strftime('%Y-%m') if not recent_data.empty else "N/A"
        date_info = f" ({latest_date})" if target_date else ""
        
        print(f"ê²½ì œ ì‹œë¦¬ì¦ˆ ê°€ë¡œ ë°” ì°¨íŠ¸ ({desc}){date_info}")
        fig = create_horizontal_bar_chart(
            data_dict=latest_values,
            positive_color=deepred_pds,
            negative_color=deepblue_pds,
            unit=unit
        )
    
    elif chart_type == 'vertical_bar':
        # ì‹œê³„ì—´ ì„¸ë¡œ ë°” ì°¨íŠ¸
        print(f"ê²½ì œ ì‹œë¦¬ì¦ˆ ì„¸ë¡œ ë°” ì°¨íŠ¸ ({desc})")
        fig = create_vertical_bar_chart(
            data=recent_data,
            columns=available_cols,
            labels=labels,
            ytitle=left_ytitle,
            unit=unit
        )
    
    else:
        print("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” chart_typeì´ê±°ë‚˜ ì‹œë¦¬ì¦ˆ ê°œìˆ˜ê°€ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print("   - single_line: 1ê°œ ì‹œë¦¬ì¦ˆ")
        print("   - multi_line: ì—¬ëŸ¬ ì‹œë¦¬ì¦ˆ")
        print("   - dual_axis: 2ê°œ ì´ìƒ ì‹œë¦¬ì¦ˆ")
        print("   - horizontal_bar: ì—¬ëŸ¬ ì‹œë¦¬ì¦ˆ")
        print("   - vertical_bar: ì—¬ëŸ¬ ì‹œë¦¬ì¦ˆ")
        return None
    
    # 0ì„  ì¶”ê°€ (ë³€í™”ìœ¨/ë³€í™”ëŸ‰ ì°¨íŠ¸ì¸ ê²½ìš°)
    if data_type in ['mom', 'yoy', 'mom_change', 'yoy_change'] and chart_type not in ['horizontal_bar', 'vertical_bar']:
        if hasattr(fig, 'add_hline'):
            fig.add_hline(y=0, line_width=1, line_color="black", opacity=0.5)
    
    return fig

def create_horizontal_bar_chart(data_dict, positive_color=None, negative_color=None, unit=""):
    """
    ê°€ë¡œ ë°” ì°¨íŠ¸ ìƒì„± (KPDS í¬ë§·)
    
    Args:
        data_dict: ë°ì´í„° ë”•ì…”ë„ˆë¦¬ {label: value}
        positive_color: ì–‘ìˆ˜ ìƒ‰ìƒ
        negative_color: ìŒìˆ˜ ìƒ‰ìƒ  
        unit: ë‹¨ìœ„
    
    Returns:
        plotly figure
    """
    if not data_dict:
        print("âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ìƒ‰ìƒ ê¸°ë³¸ê°’ ì„¤ì •
    if positive_color is None:
        positive_color = deepred_pds
    if negative_color is None:
        negative_color = deepblue_pds
    
    # ë°ì´í„° ì •ë ¬
    items = list(data_dict.items())
    items.sort(key=lambda x: x[1])  # ê°’ ê¸°ì¤€ ì •ë ¬
    
    categories = [item[0] for item in items]
    values = [item[1] for item in items]
    colors = [positive_color if val >= 0 else negative_color for val in values]
    
    # ë°” ì°¨íŠ¸ ìƒì„±
    fig = go.Figure(data=go.Bar(
        y=categories,
        x=values,
        orientation='h',
        marker_color=colors,
        text=[f'{v:+.1f}{unit}' for v in values],
        textposition='outside',
        showlegend=False
    ))
    
    # xì¶• ë²”ìœ„ ì„¤ì •
    max_val = max(abs(min(values)), max(values)) * 1.2 if values else 1
    fig.update_xaxes(range=[-max_val, max_val])
    
    # 0ì„  ì¶”ê°€
    fig.add_vline(x=0, line_width=1, line_color="black", opacity=0.5)
    
    # KPDS í°íŠ¸ ì„¤ì •
    font_family = 'NanumGothic'
    
    # ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸
    fig.update_layout(
        height=max(400, len(categories) * 40),
        width=800,
        paper_bgcolor='white',
        plot_bgcolor='white',
        font=dict(family=font_family, size=FONT_SIZE_GENERAL, color="black"),
        xaxis=dict(
            title=unit,
            title_font=dict(family=font_family, size=FONT_SIZE_AXIS_TITLE),
            showline=True, linewidth=1.3, linecolor='lightgrey',
            tickwidth=1.3, tickcolor='lightgrey',
            ticks='outside'
        ),
        yaxis=dict(
            title="",
            tickfont=dict(family=font_family, size=FONT_SIZE_GENERAL)
        )
    )
    
    return fig

def create_vertical_bar_chart(data, columns, labels=None, ytitle="", unit="", stacked=True):
    """
    ì‹œê³„ì—´ ì„¸ë¡œ ë°” ì°¨íŠ¸ ìƒì„± (KPDS í¬ë§·) - create_gdp_contribution_chart ìŠ¤íƒ€ì¼
    
    Args:
        data: DataFrame (ì‹œê³„ì—´ ë°ì´í„°)
        columns: í‘œì‹œí•  ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
        labels: ì»¬ëŸ¼ ë¼ë²¨ ë”•ì…”ë„ˆë¦¬ (Noneì´ë©´ ìë™)
        ytitle: Yì¶• ì œëª©
        unit: ë‹¨ìœ„
        stacked: Trueë©´ ëˆ„ì  ë§‰ëŒ€, Falseë©´ ê·¸ë£¹ ë§‰ëŒ€
    
    Returns:
        plotly figure
    """
    if data.empty or not columns:
        print("âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ë¼ë²¨ ìë™ ì„¤ì •
    if labels is None:
        labels = {col: col for col in columns}
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    available_cols = [col for col in columns if col in data.columns]
    if not available_cols:
        print("âŒ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ë°ì´í„° ì¤€ë¹„
    chart_data = data[available_cols].dropna()
    if chart_data.empty:
        print("âš ï¸ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ë‚ ì§œ ì¸ë±ìŠ¤ë¥¼ í‘œì¤€ datetimeìœ¼ë¡œ ë³€í™˜
    try:
        chart_data.index = pd.to_datetime(chart_data.index)
    except:
        pass  # ì´ë¯¸ datetimeì´ê±°ë‚˜ ë³€í™˜ ë¶ˆê°€ëŠ¥í•œ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
    
    # KPDS ìƒ‰ìƒ ë° í°íŠ¸ ì„¤ì •
    colors = [deepblue_pds, deepred_pds, beige_pds, blue_pds, grey_pds]
    font_family = 'NanumGothic'
    
    # ì„¸ë¡œ ë§‰ëŒ€ ì°¨íŠ¸ ìƒì„±
    fig = go.Figure()
    
    for i, col in enumerate(available_cols):
        korean_name = labels.get(col, col)
        values = chart_data[col].values
        
        # ë§‰ëŒ€ ì¶”ê°€
        fig.add_trace(go.Bar(
            x=chart_data.index,
            y=values,
            name=korean_name,
            marker_color=colors[i % len(colors)],
            text=[f'{v:+.1f}' if abs(v) >= 0.1 else f'{v:+.2f}' for v in values],
            textposition='inside' if stacked else 'outside',
            textfont=dict(size=10, color='white' if stacked else 'black'),
            showlegend=len(available_cols) > 1
        ))
    
    # ë ˆì´ì•„ì›ƒ ì„¤ì • (KPDS í‘œì¤€ ì¤€ìˆ˜)
    fig.update_layout(
        barmode='stack' if stacked else 'group',
        paper_bgcolor='white',
        plot_bgcolor='white',
        width=686,  # KPDS í‘œì¤€ ë„ˆë¹„
        height=400,  # KPDS í‘œì¤€ ë†’ì´
        font=dict(family=font_family, size=FONT_SIZE_GENERAL, color="black"),
        xaxis=dict(
            title=dict(text=None, font=dict(family=font_family, size=FONT_SIZE_AXIS_TITLE)),
            showline=True, linewidth=1.3, linecolor='lightgrey',
            tickwidth=1.3, tickcolor='lightgrey',
            ticks='outside',
            showgrid=False
        ),
        yaxis=dict(
            title="",  # Yì¶• ì œëª©ì€ annotationìœ¼ë¡œ ëŒ€ì²´
            showline=False,
            tickcolor='white',
            tickformat=',',
            showgrid=False
        ),
        legend=dict(
            orientation="h",  # ê°€ë¡œ ë°°ì—´
            yanchor="bottom",
            y=1.05,  # ì°¨íŠ¸ ìœ„ìª½
            xanchor="center",
            x=0.5,
            font=dict(family=font_family, size=FONT_SIZE_LEGEND),
            borderwidth=0,
            bordercolor="rgba(0,0,0,0)"
        ) if len(available_cols) > 1 else dict(showlegend=False)
    )
    
    # í‘œì¤€ ë‚ ì§œ í¬ë§· ì ìš© (ë‹¤ë¥¸ ì°¨íŠ¸ë“¤ê³¼ ë™ì¼)
    fig = format_date_ticks(fig, '%b-%y', "auto", chart_data.index)
    
    # Yì¶• ì œëª©ì„ annotationìœ¼ë¡œ ì¶”ê°€
    if ytitle:
        x_pos = calculate_title_position(ytitle, 'left')
        fig.add_annotation(
            text=ytitle,
            xref="paper", yref="paper",
            x=x_pos, y=1.1,
            showarrow=False,
            font=dict(size=FONT_SIZE_ANNOTATION, family=font_family, color="black"),
            align='left'
        )

    # 0ì„  ì¶”ê°€ (ê¸°ì—¬ë„ë‚˜ ë³€í™”ìœ¨ ë°ì´í„°ì¸ ê²½ìš°)
    if any('ê¸°ì—¬' in str(col) or 'contrib' in str(col).lower() or unit == '%' for col in available_cols):
        fig.add_hline(y=0, line_width=1, line_color="black", opacity=0.7)

    # ë™ì  ë§ˆì§„ ì ìš© (ë‹¤ë¥¸ ì°¨íŠ¸ë“¤ê³¼ ë™ì¼)
    margins = get_dynamic_margins(ytitle1=ytitle)
    fig.update_layout(margin=margins)
    
    return fig

def export_economic_data(data_dict, series_list, data_type='mom', periods=None, 
                        target_date=None, korean_names=None, export_path=None, 
                        file_format='excel'):
    """
    ê²½ì œ ë°ì´í„°ë¥¼ ì—‘ì…€/CSVë¡œ exportí•˜ëŠ” í•¨ìˆ˜ - plot_economic_seriesì™€ ë™ì¼í•œ ë¡œì§
    
    Args:
        data_dict: ë°ì´í„° ë”•ì…”ë„ˆë¦¬ (ì˜ˆ: {'raw_data': df, 'mom_data': df, 'mom_change': df})
        series_list: exportí•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['nonfarm_total', 'manufacturing'])
        data_type: ë°ì´í„° íƒ€ì… ('mom', 'raw', 'mom_change', 'yoy', 'yoy_change')
        periods: í‘œì‹œí•  ê¸°ê°„ (ê°œì›”, Noneì´ë©´ ì „ì²´ ë°ì´í„°)
        target_date: íŠ¹ì • ë‚ ì§œ ê¸°ì¤€ (ì˜ˆ: '2025-06-01', Noneì´ë©´ ìµœì‹  ë°ì´í„°)
        korean_names: í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
        export_path: exportí•  íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
        file_format: íŒŒì¼ í˜•ì‹ ('excel', 'csv')
    
    Returns:
        str: exportëœ íŒŒì¼ ê²½ë¡œ (ì„±ê³µì‹œ) ë˜ëŠ” None (ì‹¤íŒ¨ì‹œ)
    """
    if not data_dict or 'raw_data' not in data_dict:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ë°ì´í„° íƒ€ì…ì— ë”°ë¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (plot_economic_seriesì™€ ë™ì¼í•œ ë¡œì§)
    if data_type == 'mom':
        if 'mom_data' in data_dict:
            data = data_dict['mom_data']
        else:
            data = calculate_mom_percent(data_dict['raw_data'])
        unit = "%"
        desc = "ì „ì›”ëŒ€ë¹„ë³€í™”ìœ¨"
    elif data_type == 'raw':
        data = data_dict['raw_data']
        unit = "ì²œëª…"  # ê¸°ë³¸ê°’, í•„ìš”ì‹œ ìˆ˜ì •
        desc = "ìˆ˜ì¤€"
    elif data_type == 'mom_change':
        if 'mom_change' in data_dict:
            data = data_dict['mom_change']
        else:
            data = calculate_mom_change(data_dict['raw_data'])
        unit = "ì²œëª…"
        desc = "ì „ì›”ëŒ€ë¹„ë³€í™”ëŸ‰"
    elif data_type == 'yoy':
        if 'yoy_data' in data_dict:
            data = data_dict['yoy_data']
        else:
            data = calculate_yoy_percent(data_dict['raw_data'])
        unit = "%"
        desc = "ì „ë…„ë™ì›”ëŒ€ë¹„ë³€í™”ìœ¨"
    elif data_type == 'yoy_change':
        if 'yoy_change' in data_dict:
            data = data_dict['yoy_change']
        else:
            data = calculate_yoy_change(data_dict['raw_data'])
        unit = "ì²œëª…"
        desc = "ì „ë…„ë™ì›”ëŒ€ë¹„ë³€í™”ëŸ‰"
    else:
        print("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” data_typeì…ë‹ˆë‹¤. 'mom', 'raw', 'mom_change', 'yoy', 'yoy_change' ì¤‘ ì„ íƒí•˜ì„¸ìš”.")
        return None
    
    if data.empty:
        print("âŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ê¸°ê°„ ì œí•œ ë˜ëŠ” íŠ¹ì • ë‚ ì§œ ê¸°ì¤€ (plot_economic_seriesì™€ ë™ì¼í•œ ë¡œì§)
    if target_date:
        try:
            target_date_parsed = pd.to_datetime(target_date)
            filtered_data = data[data.index <= target_date_parsed]
            if filtered_data.empty:
                print(f"âš ï¸ {target_date} ì´ì „ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
            export_data = filtered_data.tail(periods) if periods is not None else filtered_data
        except:
            print(f"âš ï¸ ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹ì…ë‹ˆë‹¤: {target_date}. 'YYYY-MM-DD' í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            return None
    else:
        export_data = data.tail(periods) if periods is not None else data
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ í™•ì¸
    available_cols = [col for col in series_list if col in export_data.columns]
    
    if not available_cols:
        print("âŒ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
        print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œë¦¬ì¦ˆ: {list(export_data.columns)}")
        return None
    
    # ë°ì´í„° ì„ íƒ ë° ì»¬ëŸ¼ëª… ë³€ê²½
    final_data = export_data[available_cols].copy()
    
    # í•œêµ­ì–´ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€ê²½
    if korean_names:
        column_mapping = {}
        for col in available_cols:
            korean_name = korean_names.get(col, col)
            if unit and unit != "ì²œëª…":  # ë‹¨ìœ„ê°€ ìˆê³  ì²œëª…ì´ ì•„ë‹Œ ê²½ìš° (%, ë‹¬ëŸ¬ ë“±)
                column_mapping[col] = f"{korean_name} ({unit})"
            else:
                column_mapping[col] = korean_name
        final_data = final_data.rename(columns=column_mapping)
    
    # ë‚ ì§œ ì¸ë±ìŠ¤ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ë³€ê²½
    final_data.reset_index(inplace=True)
    final_data.rename(columns={final_data.columns[0]: 'ë‚ ì§œ'}, inplace=True)
    
    # export íŒŒì¼ ê²½ë¡œ ìë™ ìƒì„±
    if export_path is None:
        timestamp = dt_datetime.now().strftime('%Y%m%d_%H%M%S')
        series_str = '_'.join(available_cols[:3])  # ì²˜ìŒ 3ê°œ ì‹œë¦¬ì¦ˆë§Œ íŒŒì¼ëª…ì— í¬í•¨
        if len(available_cols) > 3:
            series_str += f"_ë“±{len(available_cols)}ê°œ"

        period_str = ""
        if periods is not None:
            period_str = f"_{periods}ê°œì›”"
        elif target_date:
            period_str = f"_{target_date}ê¹Œì§€"

        export_dir = repo_path('us_eco', 'exports')
        export_dir.mkdir(parents=True, exist_ok=True)
        if file_format == 'excel':
            export_path = export_dir / f"{desc}_{series_str}{period_str}_{timestamp}.xlsx"
        else:
            export_path = export_dir / f"{desc}_{series_str}{period_str}_{timestamp}.csv"
    else:
        export_path = Path(export_path)

    # exports ë””ë ‰í„°ë¦¬ ìƒì„±
    ensure_data_directory(export_path)
    
    try:
        # íŒŒì¼ ì €ì¥
        if file_format == 'excel':
            # ì—‘ì…€ ì €ì¥ (with styling)
            try:
                with pd.ExcelWriter(export_path, engine='openpyxl') as writer:
                    final_data.to_excel(writer, sheet_name='ë°ì´í„°', index=False)
                    
                    # ì›Œí¬ì‹œíŠ¸ ìŠ¤íƒ€ì¼ë§
                    worksheet = writer.sheets['ë°ì´í„°']
                    
                    # í—¤ë” ìŠ¤íƒ€ì¼ë§
                    from openpyxl.styles import Font, PatternFill, Alignment
                    header_font = Font(bold=True, color='FFFFFF')
                    header_fill = PatternFill(start_color='366092', end_color='366092', fill_type='solid')
                    
                    for cell in worksheet[1]:
                        cell.font = header_font
                        cell.fill = header_fill
                        cell.alignment = Alignment(horizontal='center', vertical='center')
                    
                    # ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ì¡°ì •
                    for column in worksheet.columns:
                        max_length = 0
                        column_letter = column[0].column_letter
                        for cell in column:
                            try:
                                if len(str(cell.value)) > max_length:
                                    max_length = len(str(cell.value))
                            except:
                                pass
                        adjusted_width = min(max_length + 2, 50)
                        worksheet.column_dimensions[column_letter].width = adjusted_width
                
                print(f"ğŸ“Š ì—‘ì…€ íŒŒì¼ë¡œ export ì™„ë£Œ: {export_path}")
                
            except ImportError:
                # openpyxlì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì—‘ì…€ ì €ì¥
                final_data.to_excel(export_path, index=False)
                print(f"ğŸ“Š ì—‘ì…€ íŒŒì¼ë¡œ export ì™„ë£Œ (ê¸°ë³¸ í˜•ì‹): {export_path}")
        
        else:  # CSV
            final_data.to_csv(export_path, index=False, encoding='utf-8-sig')  # í•œê¸€ ì§€ì›
            print(f"ğŸ“„ CSV íŒŒì¼ë¡œ export ì™„ë£Œ: {export_path}")
        
        # ë°ì´í„° ì •ë³´ ì¶œë ¥
        print(f"   ğŸ“… ê¸°ê°„: {final_data['ë‚ ì§œ'].iloc[0].strftime('%Y-%m-%d') if not final_data.empty else 'N/A'} ~ {final_data['ë‚ ì§œ'].iloc[-1].strftime('%Y-%m-%d') if not final_data.empty else 'N/A'}")
        print(f"   ğŸ“ˆ ì‹œë¦¬ì¦ˆ: {len(available_cols)}ê°œ")
        print(f"   ğŸ“Š ë°ì´í„° í¬ì¸íŠ¸: {len(final_data)}ê°œ")
        print(f"   ğŸ”¢ ë°ì´í„° íƒ€ì…: {desc}")
        
        return export_path
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return None

# %%
# === ë¶„ì„ í•¨ìˆ˜ë“¤ ===

def analyze_latest_trends(data, series_names, korean_names=None):
    """
    ìµœì‹  íŠ¸ë Œë“œ ë¶„ì„
    
    Args:
        data: ì›ë³¸ ë°ì´í„° DataFrame
        series_names: ë¶„ì„í•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸
        korean_names: í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘
    
    Returns:
        dict: ë¶„ì„ ê²°ê³¼
    """
    if data.empty:
        print("âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    latest_date = data.index[-1]
    mom_data = calculate_mom_percent(data)
    mom_change = calculate_mom_change(data)
    
    print(f"\nğŸ“Š ìµœì‹  íŠ¸ë Œë“œ ë¶„ì„ ({latest_date.strftime('%Yë…„ %mì›”')})")
    print("="*60)
    
    results = {
        'latest_date': latest_date,
        'series_analysis': {}
    }
    
    for series in series_names:
        if series not in data.columns:
            continue
        
        current_value = data[series].iloc[-1]
        mom_change_val = mom_change[series].iloc[-1]
        mom_percent_val = mom_data[series].iloc[-1]
        
        korean_name = korean_names.get(series, series) if korean_names else series
        
        print(f"\n{korean_name}:")
        print(f"   í˜„ì¬ê°’: {current_value:,.1f}")
        print(f"   ì „ì›”ëŒ€ë¹„: {mom_change_val:+.1f} ({mom_percent_val:+.1f}%)")
        
        results['series_analysis'][series] = {
            'korean_name': korean_name,
            'current_value': current_value,
            'mom_change': mom_change_val,
            'mom_percent': mom_percent_val
        }
    
    return results

# %%
# === í†µí•© ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ===

def load_economic_data(series_dict, data_source='BLS', csv_file_path=None,
                      start_date='2020-01-01', smart_update=True, force_reload=False,
                      tolerance=10.0):
    """
    ê²½ì œ ë°ì´í„° í†µí•© ë¡œë“œ í•¨ìˆ˜ (ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì§€ì›)
    
    Args:
        series_dict: ì‹œë¦¬ì¦ˆ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ {name: id}
        data_source: 'BLS' ë˜ëŠ” 'FRED'
        csv_file_path: CSV íŒŒì¼ ê²½ë¡œ
        start_date: ì‹œì‘ ë‚ ì§œ
        smart_update: ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì‚¬ìš© ì—¬ë¶€
        force_reload: ê°•ì œ ì¬ë¡œë“œ ì—¬ë¶€
        tolerance: ì¼ì¹˜ì„± í™•ì¸ í—ˆìš© ì˜¤ì°¨
    
    Returns:
        dict: ë¡œë“œëœ ë°ì´í„°ì™€ ë©”íƒ€ì •ë³´
    """
    print(f"ğŸš€ {data_source} ë°ì´í„° ë¡œë”© ì‹œì‘...")
    print("="*50)
    
    # API ì´ˆê¸°í™”
    if data_source == 'BLS':
        if not initialize_bls_api():
            print("âŒ BLS API ì´ˆê¸°í™” ì‹¤íŒ¨")
            return None
    elif data_source == 'FRED':
        if not initialize_fred_api():
            print("âŒ FRED API ì´ˆê¸°í™” ì‹¤íŒ¨")
            return None
    else:
        print("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° ì†ŒìŠ¤")
        return None
    
    # ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ë¡œì§
    needs_api_call = True
    consistency_result = None
    
    if smart_update and not force_reload and csv_file_path:
        print("ğŸ¤– ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ëª¨ë“œ í™œì„±í™”")
        
        # CSVì—ì„œ ë°ì´í„° ë¡œë“œ ì‹œë„
        csv_data = load_data_from_csv(csv_file_path)
        
        if csv_data is not None and not csv_data.empty:
            # ìµœì‹  ëª‡ ê°œ ë°ì´í„°ë§Œ APIë¡œ ê°€ì ¸ì™€ì„œ ë¹„êµ
            print("ğŸ” ìµœê·¼ ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸ ì¤‘...")
            
            # ëŒ€í‘œ ì‹œë¦¬ì¦ˆ í•˜ë‚˜ë§Œ í™•ì¸ (ë¹ ë¥¸ ì²´í¬)
            main_series = list(series_dict.keys())[0]
            main_series_id = series_dict[main_series]
            
            if data_source == 'BLS':
                recent_start_year = dt_datetime.now().year - 1
                recent_data = get_bls_data(main_series_id, recent_start_year)
            else:  # FRED
                recent_start = (dt_datetime.now() - timedelta(days=90)).strftime('%Y-%m-%d')
                recent_data = get_fred_data(main_series_id, recent_start)
            
            if recent_data is not None:
                # ì„ì‹œ DataFrame ìƒì„±
                temp_api_data = pd.DataFrame({main_series: recent_data})
                
                # ì¼ì¹˜ì„± í™•ì¸
                consistency_result = check_recent_data_consistency(csv_data, temp_api_data, tolerance)
                print_consistency_results(consistency_result)
                
                needs_api_call = consistency_result['needs_update']
                
                if not needs_api_call:
                    print("âœ… ìµœê·¼ ë°ì´í„°ê°€ ì¼ì¹˜í•¨ - API í˜¸ì¶œ ê±´ë„ˆë›°ê¸°")
                    return {
                        'raw_data': csv_data,
                        'mom_data': calculate_mom_percent(csv_data),
                        'mom_change': calculate_mom_change(csv_data),
                        'yoy_data': calculate_yoy_percent(csv_data),
                        'yoy_change': calculate_yoy_change(csv_data),
                        'load_info': {
                            'loaded': True,
                            'load_time': dt_datetime.now(),
                            'start_date': start_date,
                            'series_count': len(csv_data.columns),
                            'data_points': len(csv_data),
                            'source': f'CSV (ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸)',
                            'consistency_check': consistency_result
                        }
                    }
                else:
                    print("ğŸ“¡ ë°ì´í„° ë¶ˆì¼ì¹˜ ê°ì§€ - ì „ì²´ API í˜¸ì¶œ ì§„í–‰")
    
    # APIë¥¼ í†µí•œ ì „ì²´ ë°ì´í„° ë¡œë“œ
    if needs_api_call:
        print(f"ğŸ“Š {data_source} APIë¥¼ í†µí•œ ë°ì´í„° ìˆ˜ì§‘...")
        
        raw_data_dict = {}
        
        for series_name, series_id in series_dict.items():
            if data_source == 'BLS':
                start_year = int(start_date[:4])
                series_data = get_bls_data(series_id, start_year)
            else:  # FRED
                series_data = get_fred_data(series_id, start_date)
            
            if series_data is not None and len(series_data) > 0:
                raw_data_dict[series_name] = series_data
            else:
                print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {series_name}")
        
        if len(raw_data_dict) == 0:
            print("âŒ ë¡œë“œëœ ì‹œë¦¬ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # DataFrame ìƒì„±
        raw_data = pd.DataFrame(raw_data_dict)
        
        # íŒŒìƒ ë°ì´í„° ê³„ì‚°
        mom_data = calculate_mom_percent(raw_data)
        mom_change = calculate_mom_change(raw_data)
        yoy_data = calculate_yoy_percent(raw_data)
        yoy_change = calculate_yoy_change(raw_data)
        
        # CSVì— ì €ì¥
        if csv_file_path:
            save_data_to_csv(raw_data, csv_file_path)
        
        print(f"\nâœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ! ì‹œë¦¬ì¦ˆ: {len(raw_data_dict)}ê°œ")
        
        return {
            'raw_data': raw_data,
            'mom_data': mom_data,
            'mom_change': mom_change,
            'yoy_data': yoy_data,
            'yoy_change': yoy_change,
            'load_info': {
                'loaded': True,
                'load_time': dt_datetime.now(),
                'start_date': start_date,
                'series_count': len(raw_data_dict),
                'data_points': len(raw_data),
                'source': f'{data_source} API (ì „ì²´ ë¡œë“œ)',
                'consistency_check': consistency_result
            }
        }
    
    return None

# %%
# === ê·¸ë£¹ë³„ ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ í•¨ìˆ˜ë“¤ ===

def check_group_consistency(existing_data, group_name, main_series_dict, data_source='FRED', tolerance=10.0):
    """
    íŠ¹ì • ê·¸ë£¹ì˜ ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸
    
    Args:
        existing_data: ê¸°ì¡´ ë°ì´í„° DataFrame
        group_name: ê·¸ë£¹ ì´ë¦„ (ì˜ˆ: 'philadelphia', 'chicago')
        main_series_dict: ê·¸ë£¹ì˜ ë©”ì¸ ì‹œë¦¬ì¦ˆ ë”•ì…”ë„ˆë¦¬ {name: fred_id}
        data_source: ë°ì´í„° ì†ŒìŠ¤ ('FRED' ë˜ëŠ” 'BLS')
        tolerance: í—ˆìš© ì˜¤ì°¨
    
    Returns:
        dict: ì¼ì¹˜ì„± í™•ì¸ ê²°ê³¼
    """
    if existing_data.empty:
        return {
            'need_update': True,
            'reason': f'{group_name} ê·¸ë£¹ ê¸°ì¡´ ë°ì´í„° ì—†ìŒ',
            'existing_date': None,
            'api_date': None
        }
    
    # ê·¸ë£¹ì˜ ë©”ì¸ ì§€í‘œ í™•ì¸
    if not main_series_dict:
        return {
            'need_update': True,
            'reason': f'{group_name} ê·¸ë£¹ ë©”ì¸ ì‹œë¦¬ì¦ˆ ì—†ìŒ',
            'existing_date': None,
            'api_date': None
        }
    
    main_series_name = list(main_series_dict.keys())[0]
    main_series_id = list(main_series_dict.values())[0]
    
    print(f"ğŸ” {group_name} ê·¸ë£¹ ì¼ì¹˜ì„± í™•ì¸ ì¤‘...")
    print(f"   ë©”ì¸ ì‹œë¦¬ì¦ˆ: {main_series_name} ({main_series_id})")
    
    # ê¸°ì¡´ ë°ì´í„°ì—ì„œ ê·¸ë£¹ ì‹œë¦¬ì¦ˆ í™•ì¸
    group_columns = [col for col in existing_data.columns if col.startswith(f"{group_name}_")]
    
    if not group_columns:
        print(f"   âš ï¸ ê¸°ì¡´ ë°ì´í„°ì— {group_name} ê·¸ë£¹ ì—†ìŒ")
        return {
            'need_update': True,
            'reason': f'{group_name} ê·¸ë£¹ ê¸°ì¡´ ë°ì´í„° ì—†ìŒ',
            'existing_date': None,
            'api_date': None
        }
    
    # ë©”ì¸ ì‹œë¦¬ì¦ˆ í™•ì¸
    if main_series_name not in existing_data.columns:
        print(f"   âš ï¸ ë©”ì¸ ì‹œë¦¬ì¦ˆ ì—†ìŒ: {main_series_name}")
        return {
            'need_update': True,
            'reason': f'{group_name} ë©”ì¸ ì‹œë¦¬ì¦ˆ ì—†ìŒ',
            'existing_date': None,
            'api_date': None
        }
    
    # ê¸°ì¡´ ë°ì´í„° ìµœì‹  ë‚ ì§œ
    existing_series = existing_data[main_series_name].dropna()
    if existing_series.empty:
        print(f"   âš ï¸ ë©”ì¸ ì‹œë¦¬ì¦ˆ ë°ì´í„° ë¹„ì–´ìˆìŒ")
        return {
            'need_update': True,
            'reason': f'{group_name} ë©”ì¸ ì‹œë¦¬ì¦ˆ ë¹„ì–´ìˆìŒ',
            'existing_date': None,
            'api_date': None
        }
    
    existing_latest_date = existing_series.index[-1]
    print(f"   ê¸°ì¡´ ë°ì´í„° ìµœì‹ : {existing_latest_date.strftime('%Y-%m')}")
    
    # ìµœê·¼ 3ê°œì›” ë°ì´í„°ë§Œ APIì—ì„œ í™•ì¸
    try:
        recent_start = (dt_datetime.now() - timedelta(days=90)).strftime('%Y-%m-%d')
        
        if data_source == 'FRED':
            recent_api_data = get_fred_data(main_series_id, recent_start)
        elif data_source == 'BLS':
            recent_start_year = dt_datetime.now().year - 1
            recent_api_data = get_bls_data(main_series_id, recent_start_year)
        else:
            print(f"   âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° ì†ŒìŠ¤: {data_source}")
            return {
                'need_update': True,
                'reason': f'ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° ì†ŒìŠ¤: {data_source}',
                'existing_date': existing_latest_date,
                'api_date': None
            }
        
        if recent_api_data is None or recent_api_data.empty:
            print(f"   âš ï¸ API ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨")
            return {
                'need_update': True,
                'reason': f'{group_name} API ì¡°íšŒ ì‹¤íŒ¨',
                'existing_date': existing_latest_date,
                'api_date': None
            }
        
        api_latest_date = recent_api_data.index[-1]
        print(f"   API ë°ì´í„° ìµœì‹ : {api_latest_date.strftime('%Y-%m')}")
        
        # ë‚ ì§œ ë¹„êµ (ì›” ë‹¨ìœ„)
        existing_month = existing_latest_date.to_period('M')
        api_month = api_latest_date.to_period('M')
        
        if api_month > existing_month:
            print(f"   ğŸ†• {group_name} ìƒˆë¡œìš´ ë°ì´í„°: {existing_latest_date.strftime('%Y-%m')} â†’ {api_latest_date.strftime('%Y-%m')}")
            return {
                'need_update': True,
                'reason': f'{group_name} ìƒˆë¡œìš´ ë°ì´í„° ({api_latest_date.strftime("%Y-%m")})',
                'existing_date': existing_latest_date,
                'api_date': api_latest_date
            }
        
        # ê°’ ë¹„êµ
        common_dates = existing_series.index.intersection(recent_api_data.index)
        if len(common_dates) > 0:
            for date in common_dates[-3:]:  # ìµœê·¼ 3ê°œ í™•ì¸
                existing_val = existing_series[date]
                api_val = recent_api_data[date]
                
                if pd.notna(existing_val) and pd.notna(api_val):
                    diff = abs(existing_val - api_val)
                    if diff > tolerance:
                        print(f"   ğŸš¨ {group_name} ê°’ ë¶ˆì¼ì¹˜ ({date.strftime('%Y-%m')}): {existing_val:.1f} vs {api_val:.1f}")
                        return {
                            'need_update': True,
                            'reason': f'{group_name} ê°’ ë¶ˆì¼ì¹˜ ({date.strftime("%Y-%m")})',
                            'existing_date': existing_latest_date,
                            'api_date': api_latest_date
                        }
        
        print(f"   âœ… {group_name} ë°ì´í„° ì¼ì¹˜")
        return {
            'need_update': False,
            'reason': f'{group_name} ë°ì´í„° ì¼ì¹˜',
            'existing_date': existing_latest_date,
            'api_date': api_latest_date
        }
        
    except Exception as e:
        print(f"   âŒ {group_name} ì¼ì¹˜ì„± í™•ì¸ ì˜¤ë¥˜: {e}")
        return {
            'need_update': True,
            'reason': f'{group_name} í™•ì¸ ì˜¤ë¥˜: {str(e)}',
            'existing_date': existing_latest_date,
            'api_date': None
        }

def update_group_data(group_name, group_series_dict, existing_data, data_source='FRED', start_date='2020-01-01'):
    """
    íŠ¹ì • ê·¸ë£¹ì˜ ë°ì´í„°ë§Œ ì—…ë°ì´íŠ¸
    
    Args:
        group_name: ê·¸ë£¹ ì´ë¦„
        group_series_dict: ê·¸ë£¹ ì‹œë¦¬ì¦ˆ ë”•ì…”ë„ˆë¦¬ {name: id}
        existing_data: ê¸°ì¡´ ë°ì´í„° DataFrame
        data_source: ë°ì´í„° ì†ŒìŠ¤
        start_date: ì‹œì‘ ë‚ ì§œ
    
    Returns:
        pandas.DataFrame: ì—…ë°ì´íŠ¸ëœ ì „ì²´ ë°ì´í„°
    """
    print(f"ğŸ”„ {group_name} ê·¸ë£¹ ë°ì´í„° ì—…ë°ì´íŠ¸ ì¤‘...")
    
    # ê·¸ë£¹ ë°ì´í„° ìƒˆë¡œ ìˆ˜ì§‘
    new_group_data = {}
    
    for series_name, series_id in group_series_dict.items():
        try:
            if data_source == 'FRED':
                series_data = get_fred_data(series_id, start_date)
            elif data_source == 'BLS':
                start_year = int(start_date[:4])
                series_data = get_bls_data(series_id, start_year)
            else:
                print(f"   âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° ì†ŒìŠ¤: {data_source}")
                continue
                
            if series_data is not None and len(series_data) > 0:
                new_group_data[series_name] = series_data
                print(f"   âœ“ {series_name}: {len(series_data.dropna())}ê°œ í¬ì¸íŠ¸")
            else:
                print(f"   âŒ {series_name}: ë°ì´í„° ì—†ìŒ")
                
        except Exception as e:
            print(f"   âŒ {series_name} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            continue
    
    if not new_group_data:
        print(f"   âŒ {group_name} ê·¸ë£¹ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ - ìƒˆ ë°ì´í„° ì—†ìŒ")
        return existing_data
    
    # ìƒˆ ê·¸ë£¹ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
    new_group_df = pd.DataFrame(new_group_data)
    
    # ê¸°ì¡´ ë°ì´í„°ì—ì„œ í•´ë‹¹ ê·¸ë£¹ì˜ ì‹¤ì œ ì‹œë¦¬ì¦ˆ ì»¬ëŸ¼ ì œê±° (ì¤‘ë³µ ë°©ì§€)
    group_series_names = list(group_series_dict.keys())
    existing_group_columns = [col for col in existing_data.columns if col in group_series_names]
    updated_data = existing_data.drop(columns=existing_group_columns)
    
    # ìƒˆ ê·¸ë£¹ ë°ì´í„° ë³‘í•©
    updated_data = updated_data.join(new_group_df, how='outer')
    
    print(f"   âœ… {group_name} ê·¸ë£¹ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(new_group_data)}ê°œ ì‹œë¦¬ì¦ˆ")
    
    return updated_data

def load_economic_data_grouped(series_groups, data_source='FRED', csv_file_path=None,
                              start_date='2020-01-01', smart_update=True, force_reload=False,
                              tolerance=10.0):
    """
    ê·¸ë£¹ë³„ ê²½ì œ ë°ì´í„° ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ë¡œë“œ í•¨ìˆ˜
    
    Args:
        series_groups: ê·¸ë£¹ë³„ ì‹œë¦¬ì¦ˆ ë”•ì…”ë„ˆë¦¬ 
                      {group_name: {series_name: series_id}}
        data_source: 'BLS' ë˜ëŠ” 'FRED'
        csv_file_path: CSV íŒŒì¼ ê²½ë¡œ
        start_date: ì‹œì‘ ë‚ ì§œ
        smart_update: ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì‚¬ìš© ì—¬ë¶€
        force_reload: ê°•ì œ ì¬ë¡œë“œ ì—¬ë¶€
        tolerance: ì¼ì¹˜ì„± í™•ì¸ í—ˆìš© ì˜¤ì°¨
    
    Returns:
        dict: ë¡œë“œëœ ë°ì´í„°ì™€ ë©”íƒ€ì •ë³´
    """
    print(f"ğŸš€ ê·¸ë£¹ë³„ {data_source} ë°ì´í„° ë¡œë”© ì‹œì‘...")
    print(f"   ê·¸ë£¹ ìˆ˜: {len(series_groups)}")
    print(f"   ê·¸ë£¹ëª…: {list(series_groups.keys())}")
    print("="*50)
    
    # API ì´ˆê¸°í™”
    if data_source == 'BLS':
        if not initialize_bls_api():
            print("âŒ BLS API ì´ˆê¸°í™” ì‹¤íŒ¨")
            return None
    elif data_source == 'FRED':
        if not initialize_fred_api():
            print("âŒ FRED API ì´ˆê¸°í™” ì‹¤íŒ¨")
            return None
    else:
        print("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° ì†ŒìŠ¤")
        return None
    
    # ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ë¡œì§
    if smart_update and not force_reload and csv_file_path:
        print("ğŸ¤– ê·¸ë£¹ë³„ ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ëª¨ë“œ í™œì„±í™”")
        
        # CSVì—ì„œ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
        existing_data = load_data_from_csv(csv_file_path)
        
        if existing_data is not None and not existing_data.empty:
            print("ğŸ“‚ ê¸°ì¡´ CSV ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            
            # ê° ê·¸ë£¹ë³„ ì¼ì¹˜ì„± í™•ì¸
            groups_to_update = []
            group_consistency_results = {}
            
            for group_name, group_series in series_groups.items():
                # ê·¸ë£¹ì˜ ë©”ì¸ ì‹œë¦¬ì¦ˆ ì¶”ì¶œ (ì²« ë²ˆì§¸ ì‹œë¦¬ì¦ˆë¥¼ ë©”ì¸ìœ¼ë¡œ)
                main_series_dict = {
                    list(group_series.keys())[0]: list(group_series.values())[0]
                }
                
                consistency_result = check_group_consistency(
                    existing_data, group_name, main_series_dict, data_source, tolerance
                )
                
                group_consistency_results[group_name] = consistency_result
                
                if consistency_result['need_update']:
                    groups_to_update.append(group_name)
                    print(f"   ğŸ“ {group_name}: ì—…ë°ì´íŠ¸ í•„ìš” - {consistency_result['reason']}")
                else:
                    print(f"   âœ… {group_name}: ë°ì´í„° ì¼ì¹˜")
            
            # ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•œ ê·¸ë£¹ë§Œ ì²˜ë¦¬
            if not groups_to_update:
                print("âœ… ëª¨ë“  ê·¸ë£¹ ë°ì´í„° ì¼ì¹˜ - API í˜¸ì¶œ ê±´ë„ˆë›°ê¸°")
                return {
                    'raw_data': existing_data,
                    'mom_data': calculate_mom_percent(existing_data),
                    'mom_change': calculate_mom_change(existing_data),
                    'yoy_data': calculate_yoy_percent(existing_data),
                    'yoy_change': calculate_yoy_change(existing_data),
                    'load_info': {
                        'loaded': True,
                        'load_time': dt_datetime.now(),
                        'start_date': start_date,
                        'series_count': len(existing_data.columns),
                        'data_points': len(existing_data),
                        'source': f'CSV (ê·¸ë£¹ë³„ ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸)',
                        'groups_checked': list(series_groups.keys()),
                        'groups_updated': [],
                        'consistency_results': group_consistency_results
                    }
                }
            
            # í•„ìš”í•œ ê·¸ë£¹ë§Œ ì—…ë°ì´íŠ¸
            print(f"ğŸ“¡ {len(groups_to_update)}ê°œ ê·¸ë£¹ ê°œë³„ ì—…ë°ì´íŠ¸: {groups_to_update}")
            
            updated_data = existing_data.copy()
            
            for group_name in groups_to_update:
                group_series = series_groups[group_name]
                updated_data = update_group_data(
                    group_name, group_series, updated_data, data_source, start_date
                )
            
            # CSVì— ì €ì¥
            if csv_file_path:
                save_data_to_csv(updated_data, csv_file_path)
            
            print(f"\nâœ… ê·¸ë£¹ë³„ ë¶€ë¶„ ì—…ë°ì´íŠ¸ ì™„ë£Œ! ({len(groups_to_update)}ê°œ ê·¸ë£¹ ì—…ë°ì´íŠ¸)")
            
            return {
                'raw_data': updated_data,
                'mom_data': calculate_mom_percent(updated_data),
                'mom_change': calculate_mom_change(updated_data),
                'yoy_data': calculate_yoy_percent(updated_data),
                'yoy_change': calculate_yoy_change(updated_data),
                'load_info': {
                    'loaded': True,
                    'load_time': dt_datetime.now(),
                    'start_date': start_date,
                    'series_count': len(updated_data.columns),
                    'data_points': len(updated_data),
                    'source': f'{data_source} API (ê·¸ë£¹ë³„ ë¶€ë¶„ ì—…ë°ì´íŠ¸)',
                    'groups_checked': list(series_groups.keys()),
                    'groups_updated': groups_to_update,
                    'consistency_results': group_consistency_results
                }
            }
        else:
            print("âš ï¸ CSV ë¡œë“œ ì‹¤íŒ¨ - ì „ì²´ ë¡œë“œë¡œ ì§„í–‰")
    
    # ì „ì²´ ë¡œë“œ (ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨í•˜ê±°ë‚˜ ë¹„í™œì„±í™”ëœ ê²½ìš°)
    print("ğŸ“Š ì „ì²´ ê·¸ë£¹ ë°ì´í„° ë¡œë“œ ì§„í–‰")
    
    # ëª¨ë“  ì‹œë¦¬ì¦ˆë¥¼ í•˜ë‚˜ì˜ ë”•ì…”ë„ˆë¦¬ë¡œ í†µí•©
    all_series = {}
    for group_name, group_series in series_groups.items():
        for series_name, series_id in group_series.items():
            all_series[series_name] = series_id
    
    # ê¸°ì¡´ load_economic_data í•¨ìˆ˜ í˜¸ì¶œ
    result = load_economic_data(
        series_dict=all_series,
        data_source=data_source,
        csv_file_path=csv_file_path,
        start_date=start_date,
        smart_update=False,  # ì´ë¯¸ ê·¸ë£¹ë³„ ì²´í¬ë¥¼ í–ˆìœ¼ë¯€ë¡œ ë¹„í™œì„±í™”
        force_reload=force_reload,
        tolerance=tolerance
    )
    
    if result:
        result['load_info']['groups_checked'] = list(series_groups.keys())
        result['load_info']['groups_updated'] = list(series_groups.keys())
        result['load_info']['source'] = f'{data_source} API (ì „ì²´ ë¡œë“œ)'
    
    return result

# %%
# === ì‚¬ìš© ì˜ˆì‹œ ===

print("âœ… US Economic Data Utils ë¡œë“œ ì™„ë£Œ!")
print("\n=== ì£¼ìš” í•¨ìˆ˜ë“¤ ===")
print("1. API ì´ˆê¸°í™”:")
print("   - initialize_bls_api(api_key=None)")
print("   - initialize_fred_api(api_key=None)")
print()
print("2. ë°ì´í„° ë¡œë“œ:")
print("   - get_bls_data(series_id, start_year, end_year)")
print("   - get_fred_data(series_id, start_date, end_date)")
print("   - load_economic_data(series_dict, data_source, csv_file_path, ...)")
print()
print("3. ë°ì´í„° ì €ì¥/ë¡œë“œ:")
print("   - save_data_to_csv(data_df, csv_file_path)")
print("   - load_data_from_csv(csv_file_path)")
print()
print("4. ë°ì´í„° ê³„ì‚°:")
print("   - calculate_mom_percent/change(data)")
print("   - calculate_yoy_percent/change(data)")
print()
print("5. ì‹œê°í™” (KPDS í¬ë§·):")
print("   - create_timeseries_chart(data, series_names, chart_type, ...)")
print("   - create_comparison_chart(data, series_names, periods, ...)")
print("   - create_heatmap_chart(data, series_names, months, ...)")
print("   ğŸ”¥ plot_economic_series(data_dict, series_list, chart_type, data_type, ...)")
print("      â””â”€ ê°€ì¥ ê°•ë ¥í•œ ë²”ìš© ì‹œê°í™” í•¨ìˆ˜!")
print("      â””â”€ ì°¨íŠ¸ íƒ€ì…: 'multi_line', 'single_line', 'dual_axis', 'horizontal_bar', 'vertical_bar'")
print("      â””â”€ ë°ì´í„° íƒ€ì…: 'mom', 'raw', 'mom_change', 'yoy', 'yoy_change'")
print("      â””â”€ ê¸°ê°„ ì„¤ì •, íŠ¹ì • ë‚ ì§œ ê¸°ì¤€ ì‹œê°í™” ì§€ì›")
print("   ğŸ”¥ export_economic_data(data_dict, series_list, data_type, ...)")
print("      â””â”€ ì‹œê°í™”ì™€ ë™ì¼í•œ ë°ì´í„°ë¥¼ ì—‘ì…€/CSVë¡œ export!")
print("      â””â”€ í•œêµ­ì–´ ì»¬ëŸ¼ëª…, ìŠ¤íƒ€ì¼ë§, ìë™ ê²½ë¡œ ìƒì„±")
print()
print("6. ë¶„ì„:")
print("   - analyze_latest_trends(data, series_names, korean_names)")
print()
print("7. ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸:")
print("   - check_recent_data_consistency(csv_data, api_data, tolerance)")
print()
print("ğŸ¯ ì‚¬ìš© ì˜ˆì‹œ:")
print("   # ì „ì²´ ë°ì´í„° ì‹œê°í™” (ê¸°ë³¸)")
print("   plot_economic_series(data_dict, ['series1', 'series2'], 'multi_line', 'mom')")
print("   plot_economic_series(data_dict, ['series1', 'series2'], 'dual_axis', 'yoy')")
print("   # ê¸°ê°„ ì œí•œ ì‹œê°í™”")
print("   plot_economic_series(data_dict, ['series1'], 'single_line', 'raw', periods=24)")
print("   # íŠ¹ì • ë‚ ì§œ ê¸°ì¤€")
print("   plot_economic_series(data_dict, ['series1'], 'single_line', 'mom', target_date='2024-06-01')")
print("   # ì‹œê³„ì—´ ì„¸ë¡œ ë°” ì°¨íŠ¸ (ê¸°ì—¬ë„ ë¶„ì„ì— ìµœì )")
print("   plot_economic_series(data_dict, ['consumption', 'investment'], 'vertical_bar', 'mom')")
print("   # ë°ì´í„° export (ì—‘ì…€)")
print("   export_economic_data(data_dict, ['series1', 'series2'], 'mom')")
print("   # ë°ì´í„° export (CSV, ìµœê·¼ 24ê°œì›”)")
print("   export_economic_data(data_dict, ['series1'], 'raw', periods=24, file_format='csv')")
