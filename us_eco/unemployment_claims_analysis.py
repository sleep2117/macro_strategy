"""
ë¯¸êµ­ ì‹¤ì—…ê¸‰ì—¬ ì‹ ì²­ ê±´ìˆ˜ ë°ì´í„° ìˆ˜ì§‘, ë¶„ì„ ë° ì‹œê°í™”
====================================================

ìˆ˜ì§‘ ì‹œë¦¬ì¦ˆ:
- ICSA: Initial Claims (seasonally adjusted) - ì´ˆíšŒì‹ ì²­ ê³„ì ˆì¡°ì •
- ICNSA: Initial Claims (not seasonally adjusted) - ì´ˆíšŒì‹ ì²­ ë¹„ê³„ì ˆì¡°ì •
- CCSA: Continued Claims (seasonally adjusted) - ê³„ì†ì‹ ì²­ ê³„ì ˆì¡°ì •  
- CCNSA: Continued Claims (not seasonally adjusted) - ê³„ì†ì‹ ì²­ ë¹„ê³„ì ˆì¡°ì •

ë¶„ì„ ë°©ë²•:
- ê³„ì ˆì¡°ì • ì‹œë¦¬ì¦ˆ: ì´ì½”ë…¸ë¯¸ìŠ¤íŠ¸/íˆ¬ìì€í–‰ ìŠ¤íƒ€ì¼ ë¶„ì„
- ë¹„ê³„ì ˆì¡°ì • ì‹œë¦¬ì¦ˆ: 5ë…„ ë¹„êµ ì°¨íŠ¸ (create_five_year_comparison_chart)
"""

from typing import Any

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json
import os
import requests
import warnings
warnings.filterwarnings('ignore')

# KPDS ì‹œê°í™” í¬ë§· import
import sys
sys.path.append('/home/jyp0615')
from kpds_fig_format_enhanced import *

from us_eco_utils import load_economic_data

# FRED API í‚¤ ì„¤ì •
FRED_API_KEY = 'f4bd434811e42e42287a0e5ccf400fff'  # FRED API Key
FRED_BASE_URL = 'https://api.stlouisfed.org/fred'

print("=" * 60)
print("ë¯¸êµ­ ì‹¤ì—…ê¸‰ì—¬ ì‹ ì²­ ê±´ìˆ˜ ë°ì´í„° ë¶„ì„ ì‹œì‘")
print("=" * 60)

# í†µí•© ëŒ€ì‹œë³´ë“œìš© ë©”íƒ€ë°ì´í„°
CSV_FILE_PATH = '/home/jyp0615/us_eco/data/unemployment_claims_data.csv'

UNEMPLOYMENT_CLAIMS_SERIES = {
    'ICSA': 'ICSA',
    'ICNSA': 'ICNSA',
    'CCSA': 'CCSA',
    'CCNSA': 'CCNSA',
}

UNEMPLOYMENT_CLAIMS_KOREAN_NAMES = {
    'ICSA': 'ì´ˆíšŒì‹ ì²­(SA)',
    'ICNSA': 'ì´ˆíšŒì‹ ì²­(NSA)',
    'CCSA': 'ê³„ì†ì‹ ì²­(SA)',
    'CCNSA': 'ê³„ì†ì‹ ì²­(NSA)',
}

UNEMPLOYMENT_CLAIMS_DATA: dict[str, Any] = {
    'raw_data': pd.DataFrame(),
    'mom_data': pd.DataFrame(),
    'mom_change': pd.DataFrame(),
    'yoy_data': pd.DataFrame(),
    'yoy_change': pd.DataFrame(),
    'extra_data': pd.DataFrame(),
    'load_info': {
        'loaded': False,
        'load_time': None,
        'start_date': None,
        'series_count': 0,
        'data_points': 0,
        'source': 'cache',
    },
}

ALL_SERIES = UNEMPLOYMENT_CLAIMS_SERIES


def load_unemployment_claims_data(start_date='2000-01-01', smart_update=True, force_reload=False) -> bool:
    """í†µí•© ë¡œë”ì™€ CSV ìºì‹œë¥¼ í™œìš©í•œ ì‹¤ì—…ê¸‰ì—¬ ë°ì´í„° ì ì¬"""

    global UNEMPLOYMENT_CLAIMS_DATA

    result = load_economic_data(
        series_dict=UNEMPLOYMENT_CLAIMS_SERIES,
        data_source='FRED',
        csv_file_path=CSV_FILE_PATH,
        start_date=start_date,
        smart_update=smart_update,
        force_reload=force_reload,
    )

    if result:
        UNEMPLOYMENT_CLAIMS_DATA = result
        return True

    return False

# =============================================================================
# 1. ë°ì´í„° ìˆ˜ì§‘ (FRED API ì‚¬ìš©)
# =============================================================================

def fetch_fred_series(series_id, start_date, end_date):
    """FRED APIì—ì„œ ë‹¨ì¼ ì‹œë¦¬ì¦ˆ ë°ì´í„° ìˆ˜ì§‘"""
    url = f"{FRED_BASE_URL}/series/observations"
    params = {
        'series_id': series_id,
        'api_key': FRED_API_KEY,
        'file_type': 'json',
        'observation_start': start_date,
        'observation_end': end_date
    }
    
    try:
        response = requests.get(url, params=params)
        response.raise_for_status()
        data = response.json()
        
        if 'observations' not in data:
            print(f"âŒ {series_id}: ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ë°ì´í„° íŒŒì‹±
        observations = data['observations']
        dates = []
        values = []
        
        for obs in observations:
            if obs['value'] != '.':  # FREDì—ì„œ ê²°ì¸¡ì¹˜ëŠ” '.'ë¡œ í‘œì‹œ
                dates.append(pd.to_datetime(obs['date']))
                values.append(float(obs['value']))
        
        if len(dates) == 0:
            print(f"âŒ {series_id}: ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        series = pd.Series(values, index=dates, name=series_id)
        print(f"âœ… {series_id}: {len(series)}ê°œ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ì§‘ ì™„ë£Œ")
        return series
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ {series_id} API ìš”ì²­ ì‹¤íŒ¨: {e}")
        return None
    except Exception as e:
        print(f"âŒ {series_id} ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return None

def collect_fred_data():
    """FRED APIì—ì„œ ì‹¤ì—…ê¸‰ì—¬ ì‹ ì²­ ê±´ìˆ˜ ë°ì´í„° ìˆ˜ì§‘"""
    
    # ìˆ˜ì§‘ ê¸°ê°„ ì„¤ì • (2000ë…„ë¶€í„° í˜„ì¬ê¹Œì§€)
    start_date = "2000-01-01"
    end_date = datetime.now().strftime("%Y-%m-%d")
    
    # ì‹œë¦¬ì¦ˆ ì •ë³´
    series_info = {
        'ICSA': 'Initial Claims (Seasonally Adjusted)',
        'ICNSA': 'Initial Claims (Not Seasonally Adjusted)', 
        'CCSA': 'Continued Claims (Seasonally Adjusted)',
        'CCNSA': 'Continued Claims (Not Seasonally Adjusted)'
    }
    
    print("ğŸ”„ FRED APIì—ì„œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    
    # ë°ì´í„° ìˆ˜ì§‘ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
    all_data = {}
    
    try:
        # ê° ì‹œë¦¬ì¦ˆë³„ë¡œ ë°ì´í„° ìˆ˜ì§‘
        for series_key, series_description in series_info.items():
            print(f"ğŸ“Š {series_key} ({series_description}) ë°ì´í„° ìˆ˜ì§‘...")
            
            series_data = fetch_fred_series(series_key, start_date, end_date)
            if series_data is not None:
                all_data[series_key] = series_data
            else:
                print(f"âš ï¸ {series_key} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ - ê±´ë„ˆëœë‹ˆë‹¤.")
        
        if len(all_data) == 0:
            print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None, None
        
        print(f"âœ… {len(all_data)}ê°œ ì‹œë¦¬ì¦ˆ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        
        # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ê²°í•©
        df = pd.DataFrame(all_data)
        
        # ê²°ì¸¡ì¹˜ ì œê±° ë° ì •ë ¬
        df = df.dropna().sort_index()
        
        print(f"ğŸ“Š ìµœì¢… ë°ì´í„°: {len(df)}ê°œ ê´€ì¸¡ì¹˜, ê¸°ê°„: {df.index[0].strftime('%Y-%m-%d')} ~ {df.index[-1].strftime('%Y-%m-%d')}")
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'series': series_info,
            'source': 'Federal Reserve Economic Data (FRED)',
            'collection_date': datetime.now().isoformat(),
            'start_date': start_date,
            'end_date': end_date,
            'frequency': 'Weekly (Thursday)',
            'units': {
                'ICSA': 'Number of people',
                'ICNSA': 'Number of people', 
                'CCSA': 'Number of people',
                'CCNSA': 'Number of people'
            },
            'api_info': {
                'base_url': FRED_BASE_URL,
                'series_collected': list(all_data.keys()),
                'data_points_per_series': {k: len(v) for k, v in all_data.items()}
            }
        }
        
        return df, metadata
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None

# =============================================================================
# 2. ë°ì´í„° ì €ì¥ ë° ë¡œë“œ
# =============================================================================

def save_data(df, metadata, base_path="/home/jyp0615/us_eco/data"):
    """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ CSVì™€ JSONìœ¼ë¡œ ì €ì¥"""
    
    try:
        # CSV ì €ì¥
        csv_path = os.path.join(base_path, "unemployment_claims_data.csv")
        df.to_csv(csv_path)
        print(f"ğŸ“ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {csv_path}")
        
        # ë©”íƒ€ë°ì´í„° JSON ì €ì¥
        json_path = os.path.join(base_path, "unemployment_claims_data_meta.json")
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“ ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {json_path}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        return False

def load_data(base_path="/home/jyp0615/us_eco/data"):
    """ì €ì¥ëœ ë°ì´í„°ë¥¼ ë¡œë“œ"""
    
    try:
        # CSV ë¡œë“œ
        csv_path = os.path.join(base_path, "unemployment_claims_data.csv")
        df = pd.read_csv(csv_path, index_col=0, parse_dates=True)
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        json_path = os.path.join(base_path, "unemployment_claims_data_meta.json")
        with open(json_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        print(f"ğŸ“‚ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ê´€ì¸¡ì¹˜")
        return df, metadata
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None

# =============================================================================
# 3. 5ë…„ ë¹„êµ ë°ì´í„° í¬ë§· ìƒì„± (ë¹„ê³„ì ˆì¡°ì • ì‹œë¦¬ì¦ˆìš©)
# =============================================================================

def create_five_year_format(df, column):
    """
    5ë…„ ë¹„êµ ì°¨íŠ¸ìš© ë°ì´í„° í¬ë§· ìƒì„± (ì£¼ê°„ ê¸°ì¤€)
    ì£¼ê°„ ë°ì´í„°ë¥¼ ì—°ë„ë³„ë¡œ ì£¼ì°¨ë³„(1~52ì£¼)ë¡œ ë¹„êµ ê°€ëŠ¥í•˜ê²Œ ë³€í™˜
    """
    
    print(f"ğŸ”„ {column} 5ë…„ ë¹„êµ ë°ì´í„° í¬ë§· ìƒì„± ì¤‘ (ì£¼ê°„ ê¸°ì¤€)...")
    
    try:
        # ì›ë³¸ ì£¼ê°„ ë°ì´í„° ì‚¬ìš©
        series = df[column].copy()
        
        # ì—°ë„ì™€ ì£¼ì°¨ ì¶”ì¶œ
        series_with_period = series.copy()
        series_with_period.index = pd.to_datetime(series_with_period.index)
        
        # ìµœê·¼ 5ë…„ ë°ì´í„°ë§Œ ì„ íƒ
        current_year = datetime.datetime.now().year
        start_year = current_year - 4
        mask = series_with_period.index.year >= start_year
        recent_data = series_with_period[mask]
        
        # ì£¼ì°¨ë³„ë¡œ pivot (1~52ì£¼)
        weekly_data = []
        for year in range(start_year, current_year + 1):
            year_data = recent_data[recent_data.index.year == year]
            year_series = pd.Series(index=range(1, 53), name=str(year))  # 1~52ì£¼
            
            # ê° ì£¼ì°¨ë³„ë¡œ ë°ì´í„° ë§¤í•‘
            for i, (date, value) in enumerate(year_data.items()):
                week_of_year = date.isocalendar()[1]  # ISO ì£¼ì°¨ (1~53)
                if week_of_year <= 52:  # 52ì£¼ê¹Œì§€ë§Œ
                    year_series.loc[week_of_year] = value
            
            weekly_data.append(year_series)
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        five_year_df = pd.concat(weekly_data, axis=1)
        
        # í†µê³„ ê³„ì‚° (5ë…„ í‰ê· , ìµœì†Œ, ìµœëŒ€)
        five_year_df['5ë…„í‰ê· '] = five_year_df.mean(axis=1, skipna=True)
        five_year_df['Min'] = five_year_df.iloc[:, :-1].min(axis=1, skipna=True)
        five_year_df['Min~Max'] = five_year_df.iloc[:, :-2].max(axis=1, skipna=True)
        
        print(f"âœ… {column} 5ë…„ ë¹„êµ ë°ì´í„° í¬ë§· ìƒì„± ì™„ë£Œ (ì£¼ê°„ ê¸°ì¤€)")
        return five_year_df
        
    except Exception as e:
        print(f"âŒ {column} 5ë…„ ë¹„êµ ë°ì´í„° í¬ë§· ìƒì„± ì‹¤íŒ¨: {e}")
        return None

# =============================================================================
# 4. ê²½ì œ ë¶„ì„ í•¨ìˆ˜ë“¤
# =============================================================================

def calculate_economic_indicators(df):
    """ì£¼ìš” ê²½ì œ ì§€í‘œ ê³„ì‚°"""
    
    print("ğŸ“ˆ ê²½ì œ ì§€í‘œ ê³„ì‚° ì¤‘...")
    
    indicators = {}
    
    try:
        # ìµœì‹  ë°ì´í„° í¬ì¸íŠ¸
        latest_date = df.index[-1]
        latest_data = df.iloc[-1]
        
        # 4ì£¼ ì´ë™í‰ê·  (ë…¸ì´ì¦ˆ ì œê±°)
        ma4_data = df.rolling(window=4).mean().iloc[-1]
        
        # ì „ì£¼ ëŒ€ë¹„ ë³€í™”
        wow_change = df.iloc[-1] - df.iloc[-2]
        wow_pct = (wow_change / df.iloc[-2] * 100)
        
        # ì „ë…„ ë™ê¸° ëŒ€ë¹„ (52ì£¼ ì „)
        if len(df) >= 52:
            yoy_change = df.iloc[-1] - df.iloc[-53]
            yoy_pct = (yoy_change / df.iloc[-53] * 100)
        else:
            yoy_change = pd.Series([np.nan] * len(df.columns), index=df.columns)
            yoy_pct = pd.Series([np.nan] * len(df.columns), index=df.columns)
        
        # ì½”ë¡œë‚˜19 ì´ì „ í‰ê·  ëŒ€ë¹„ (2019ë…„ í‰ê· )
        pre_covid_avg = df[(df.index.year == 2019)].mean()
        vs_precovid = latest_data - pre_covid_avg
        vs_precovid_pct = (vs_precovid / pre_covid_avg * 100)
        
        indicators = {
            'latest_date': latest_date,
            'latest_values': latest_data,
            'ma4_values': ma4_data,
            'wow_change': wow_change,
            'wow_pct': wow_pct,
            'yoy_change': yoy_change, 
            'yoy_pct': yoy_pct,
            'vs_precovid': vs_precovid,
            'vs_precovid_pct': vs_precovid_pct
        }
        
        print("âœ… ê²½ì œ ì§€í‘œ ê³„ì‚° ì™„ë£Œ")
        return indicators
        
    except Exception as e:
        print(f"âŒ ê²½ì œ ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return None

def analyze_trends(df):
    """íŠ¸ë Œë“œ ë¶„ì„"""
    
    print("ğŸ“Š íŠ¸ë Œë“œ ë¶„ì„ ì¤‘...")
    
    trends = {}
    
    try:
        for column in df.columns:
            series = df[column].dropna()
            
            # ìµœê·¼ 3ê°œì›” íŠ¸ë Œë“œ (12ì£¼)
            recent_12w = series.tail(12)
            if len(recent_12w) >= 2:
                # ì„ í˜• íšŒê·€ë¡œ íŠ¸ë Œë“œ ê³„ì‚°
                x = np.arange(len(recent_12w))
                coeffs = np.polyfit(x, recent_12w.values, 1)
                trend_slope = coeffs[0]
                
                if trend_slope > 500:
                    trend_direction = "ê°•í•œ ìƒìŠ¹"
                elif trend_slope > 100:
                    trend_direction = "ìƒìŠ¹"
                elif trend_slope > -100:
                    trend_direction = "ë³´í•©"
                elif trend_slope > -500:
                    trend_direction = "í•˜ë½"
                else:
                    trend_direction = "ê°•í•œ í•˜ë½"
            else:
                trend_slope = 0
                trend_direction = "ë¶„ì„ë¶ˆê°€"
            
            # ë³€ë™ì„± ê³„ì‚° (ìµœê·¼ 12ì£¼ í‘œì¤€í¸ì°¨)
            volatility = recent_12w.std() if len(recent_12w) > 1 else 0
            
            trends[column] = {
                'trend_slope': trend_slope,
                'trend_direction': trend_direction,
                'volatility': volatility,
                'recent_12w_avg': recent_12w.mean(),
                'recent_12w_min': recent_12w.min(),
                'recent_12w_max': recent_12w.max()
            }
        
        print("âœ… íŠ¸ë Œë“œ ë¶„ì„ ì™„ë£Œ")
        return trends
        
    except Exception as e:
        print(f"âŒ íŠ¸ë Œë“œ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return None

# =============================================================================
# 5. ì‹œê°í™” í•¨ìˆ˜ë“¤
# =============================================================================

def create_sa_analysis_charts(df):
    """ê³„ì ˆì¡°ì • ì‹œë¦¬ì¦ˆ ë¶„ì„ ì°¨íŠ¸ ìƒì„± (ì´ì½”ë…¸ë¯¸ìŠ¤íŠ¸/íˆ¬ìì€í–‰ ìŠ¤íƒ€ì¼)"""
    
    print("ğŸ“Š ê³„ì ˆì¡°ì • ì‹œë¦¬ì¦ˆ ì°¨íŠ¸ ìƒì„± ì¤‘...")
    
    try:
        # 1. ì´ˆíšŒì‹ ì²­ê³¼ ê³„ì†ì‹ ì²­ ì´ì¤‘ì¶• ì°¨íŠ¸
        print("1ï¸âƒ£ ì´ˆíšŒì‹ ì²­ vs ê³„ì†ì‹ ì²­ ì´ì¤‘ì¶• ì°¨íŠ¸")
        print("ë¯¸êµ­ ì‹¤ì—…ê¸‰ì—¬ ì‹ ì²­ ê±´ìˆ˜ (ê³„ì ˆì¡°ì •)")
        df_dual_axis_chart(
            df, 
            left_cols=['ICSA'], 
            right_cols=['CCSA'],
            left_labels=['ì´ˆíšŒì‹ ì²­(SA)'], 
            right_labels=['ê³„ì†ì‹ ì²­(SA)'],
            left_title="ëª…", 
            right_title="ëª…",
            xtitle=None
        )
        
        # 2. 4ì£¼ ì´ë™í‰ê·  ë¹„êµ (ë…¸ì´ì¦ˆ ì œê±°) - ì´ì¤‘ì¶•
        print("2ï¸âƒ£ 4ì£¼ ì´ë™í‰ê·  íŠ¸ë Œë“œ ì°¨íŠ¸ (ì´ì¤‘ì¶•)")
        print("ì‹¤ì—…ê¸‰ì—¬ ì‹ ì²­ ê±´ìˆ˜ 4ì£¼ ì´ë™í‰ê·  (ë…¸ì´ì¦ˆ ì œê±°)")
        df_ma4 = df[['ICSA', 'CCSA']].rolling(window=4).mean()
        df_dual_axis_chart(
            df_ma4,
            left_cols=['ICSA'],
            right_cols=['CCSA'],
            left_labels=['ì´ˆíšŒì‹ ì²­ 4ì£¼MA'],
            right_labels=['ê³„ì†ì‹ ì²­ 4ì£¼MA'],
            left_title="ëª…",
            right_title="ëª…"
        )
        
        # 3. ì „ë…„ë™ê¸°ëŒ€ë¹„ ë³€í™”ìœ¨
        print("3ï¸âƒ£ ì „ë…„ë™ê¸°ëŒ€ë¹„ ë³€í™”ìœ¨ ì°¨íŠ¸")
        print("ì‹¤ì—…ê¸‰ì—¬ ì‹ ì²­ ê±´ìˆ˜ ì „ë…„ë™ê¸°ëŒ€ë¹„ ë³€í™”ìœ¨")
        df_yoy = df[['ICSA', 'CCSA']].pct_change(periods=52) * 100
        df_multi_line_chart(
            df_yoy,
            columns=['ICSA', 'CCSA'], 
            labels={'ICSA': 'ì´ˆíšŒì‹ ì²­ YoY', 'CCSA': 'ê³„ì†ì‹ ì²­ YoY'},
            ytitle="%"
        )
        
        # 4. ìµœê·¼ 2ë…„ ìƒì„¸ íŠ¸ë Œë“œ
        print("4ï¸âƒ£ ìµœê·¼ 2ë…„ ìƒì„¸ íŠ¸ë Œë“œ")
        print("ìµœê·¼ 2ë…„ ì‹¤ì—…ê¸‰ì—¬ ì‹ ì²­ ê±´ìˆ˜ ìƒì„¸ íŠ¸ë Œë“œ")
        recent_2y = df[df.index >= (datetime.datetime.now() - timedelta(days=730))]
        df_dual_axis_chart(
            recent_2y,
            left_cols=['ICSA'],
            right_cols=['CCSA'], 
            left_labels=['ì´ˆíšŒì‹ ì²­'],
            right_labels=['ê³„ì†ì‹ ì²­'],
            left_title="ëª…",
            right_title="ëª…"
        )
        
        print("âœ… ê³„ì ˆì¡°ì • ì‹œë¦¬ì¦ˆ ì°¨íŠ¸ ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ ê³„ì ˆì¡°ì • ì‹œë¦¬ì¦ˆ ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")

def create_nsa_comparison_charts(df):
    """ë¹„ê³„ì ˆì¡°ì • ì‹œë¦¬ì¦ˆ 5ë…„ ë¹„êµ ì°¨íŠ¸ ìƒì„±"""
    
    print("ğŸ“Š ë¹„ê³„ì ˆì¡°ì • ì‹œë¦¬ì¦ˆ 5ë…„ ë¹„êµ ì°¨íŠ¸ ìƒì„± ì¤‘...")
    
    try:
        # ICNSA 5ë…„ ë¹„êµ
        print("1ï¸âƒ£ ì´ˆíšŒì‹ ì²­(ë¹„ê³„ì ˆì¡°ì •) 5ë…„ ë¹„êµ")
        print("ì´ˆíšŒì‹ ì²­ ì‹¤ì—…ê¸‰ì—¬ 5ë…„ ë¹„êµ (ë¹„ê³„ì ˆì¡°ì •)")
        icnsa_five_year = create_five_year_format(df, 'ICNSA')
        if icnsa_five_year is not None:
            create_five_year_comparison_chart(
                icnsa_five_year,
                y_title="ëª…",
                x_axis_type='week',
                recent_years=3
            )
        
        # CCNSA 5ë…„ ë¹„êµ  
        print("2ï¸âƒ£ ê³„ì†ì‹ ì²­(ë¹„ê³„ì ˆì¡°ì •) 5ë…„ ë¹„êµ")
        print("ê³„ì†ì‹ ì²­ ì‹¤ì—…ê¸‰ì—¬ 5ë…„ ë¹„êµ (ë¹„ê³„ì ˆì¡°ì •)")
        ccnsa_five_year = create_five_year_format(df, 'CCNSA')
        if ccnsa_five_year is not None:
            create_five_year_comparison_chart(
                ccnsa_five_year,
                y_title="ëª…", 
                x_axis_type='week',
                recent_years=3
            )
        
        print("âœ… ë¹„ê³„ì ˆì¡°ì • ì‹œë¦¬ì¦ˆ 5ë…„ ë¹„êµ ì°¨íŠ¸ ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ ë¹„ê³„ì ˆì¡°ì • ì‹œë¦¬ì¦ˆ ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")

def create_comparative_analysis_charts(df):
    """ë¹„êµ ë¶„ì„ ì°¨íŠ¸ ìƒì„±"""
    
    print("ğŸ“Š ë¹„êµ ë¶„ì„ ì°¨íŠ¸ ìƒì„± ì¤‘...")
    
    try:
        # 1. ê³„ì ˆì¡°ì • vs ë¹„ê³„ì ˆì¡°ì • ë¹„êµ (ì´ˆíšŒì‹ ì²­)
        print("1ï¸âƒ£ ì´ˆíšŒì‹ ì²­: ê³„ì ˆì¡°ì • vs ë¹„ê³„ì ˆì¡°ì •")
        print("ì´ˆíšŒì‹ ì²­ ì‹¤ì—…ê¸‰ì—¬: ê³„ì ˆì¡°ì • vs ë¹„ê³„ì ˆì¡°ì •")
        df_multi_line_chart(
            df,
            columns=['ICSA', 'ICNSA'],
            labels={'ICSA': 'ê³„ì ˆì¡°ì •', 'ICNSA': 'ë¹„ê³„ì ˆì¡°ì •'},
            ytitle="ëª…"
        )
        
        # 2. ê³„ì ˆì¡°ì • vs ë¹„ê³„ì ˆì¡°ì • ë¹„êµ (ê³„ì†ì‹ ì²­)
        print("2ï¸âƒ£ ê³„ì†ì‹ ì²­: ê³„ì ˆì¡°ì • vs ë¹„ê³„ì ˆì¡°ì •")
        print("ê³„ì†ì‹ ì²­ ì‹¤ì—…ê¸‰ì—¬: ê³„ì ˆì¡°ì • vs ë¹„ê³„ì ˆì¡°ì •")
        df_multi_line_chart(
            df,
            columns=['CCSA', 'CCNSA'], 
            labels={'CCSA': 'ê³„ì ˆì¡°ì •', 'CCNSA': 'ë¹„ê³„ì ˆì¡°ì •'},
            ytitle="ëª…"
        )
        
        # 3. ê³„ì ˆì„± ë¶„ì„ (ì°¨ì´ ì‹œê°í™”)
        print("3ï¸âƒ£ ê³„ì ˆì„± ë¶„ì„")
        print("ì‹¤ì—…ê¸‰ì—¬ ì‹ ì²­ì˜ ê³„ì ˆì„± (NSA - SA)")
        df_seasonal = pd.DataFrame()
        df_seasonal['ì´ˆíšŒì‹ ì²­_ê³„ì ˆì„±'] = df['ICNSA'] - df['ICSA']
        df_seasonal['ê³„ì†ì‹ ì²­_ê³„ì ˆì„±'] = df['CCNSA'] - df['CCSA']
        
        df_multi_line_chart(
            df_seasonal,
            columns=['ì´ˆíšŒì‹ ì²­_ê³„ì ˆì„±', 'ê³„ì†ì‹ ì²­_ê³„ì ˆì„±'],
            ytitle="ëª…"
        )
        
        print("âœ… ë¹„êµ ë¶„ì„ ì°¨íŠ¸ ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ ë¹„êµ ë¶„ì„ ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")

# =============================================================================
# 6. ë³´ê³ ì„œ ìƒì„±
# =============================================================================

def generate_analysis_report(df, indicators, trends):
    """ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
    
    print("\n" + "="*60)
    print("ğŸ“‹ ë¯¸êµ­ ì‹¤ì—…ê¸‰ì—¬ ì‹ ì²­ ê±´ìˆ˜ ë¶„ì„ ë³´ê³ ì„œ")
    print("="*60)
    
    if indicators is None or trends is None:
        print("âŒ ë¶„ì„ ë°ì´í„°ê°€ ì—†ì–´ ë³´ê³ ì„œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # 1. ìµœì‹  í˜„í™©
    print(f"\nğŸ“Š ìµœì‹  í˜„í™© ({indicators['latest_date'].strftime('%Y-%m-%d')})")
    print("-" * 40)
    for series in ['ICSA', 'ICNSA', 'CCSA', 'CCNSA']:
        latest_val = indicators['latest_values'][series]
        wow_change = indicators['wow_change'][series]
        wow_pct = indicators['wow_pct'][series]
        
        series_name = {
            'ICSA': 'ì´ˆíšŒì‹ ì²­(SA)', 
            'ICNSA': 'ì´ˆíšŒì‹ ì²­(NSA)',
            'CCSA': 'ê³„ì†ì‹ ì²­(SA)',
            'CCNSA': 'ê³„ì†ì‹ ì²­(NSA)'
        }[series]
        
        print(f"{series_name:12}: {latest_val:>8,.0f}ëª… "
              f"(ì „ì£¼ëŒ€ë¹„ {wow_change:+6,.0f}ëª…, {wow_pct:+5.1f}%)")
    
    # 2. íŠ¸ë Œë“œ ë¶„ì„
    print(f"\nğŸ“ˆ íŠ¸ë Œë“œ ë¶„ì„ (ìµœê·¼ 12ì£¼)")
    print("-" * 40)
    for series in ['ICSA', 'ICNSA', 'CCSA', 'CCNSA']:
        trend_info = trends[series]
        series_name = {
            'ICSA': 'ì´ˆíšŒì‹ ì²­(SA)', 
            'ICNSA': 'ì´ˆíšŒì‹ ì²­(NSA)',
            'CCSA': 'ê³„ì†ì‹ ì²­(SA)',
            'CCNSA': 'ê³„ì†ì‹ ì²­(NSA)'
        }[series]
        
        print(f"{series_name:12}: {trend_info['trend_direction']:8} "
              f"(ê¸°ìš¸ê¸°: {trend_info['trend_slope']:+6.0f})")
    
    # 3. ì£¼ìš” í¬ì¸íŠ¸
    print(f"\nğŸ¯ ì£¼ìš” í¬ì¸íŠ¸")
    print("-" * 40)
    
    # ì´ˆíšŒì‹ ì²­ vs ê³„ì†ì‹ ì²­ ë¹„êµ
    icsa_latest = indicators['latest_values']['ICSA']
    ccsa_latest = indicators['latest_values']['CCSA']
    claims_ratio = ccsa_latest / icsa_latest
    
    print(f"â€¢ ê³„ì†ì‹ ì²­/ì´ˆíšŒì‹ ì²­ ë¹„ìœ¨: {claims_ratio:.1f}ë°°")
    print(f"â€¢ ê³„ì†ì‹ ì²­ ìˆ˜ì¤€: {'ë†’ìŒ' if claims_ratio > 7 else 'ë³´í†µ' if claims_ratio > 5 else 'ë‚®ìŒ'}")
    
    # ì „ë…„ ë™ê¸° ëŒ€ë¹„
    if not np.isnan(indicators['yoy_pct']['ICSA']):
        yoy_icsa = indicators['yoy_pct']['ICSA']
        yoy_ccsa = indicators['yoy_pct']['CCSA']
        print(f"â€¢ ì´ˆíšŒì‹ ì²­ ì „ë…„ëŒ€ë¹„: {yoy_icsa:+.1f}%")
        print(f"â€¢ ê³„ì†ì‹ ì²­ ì „ë…„ëŒ€ë¹„: {yoy_ccsa:+.1f}%")
    
    # ê³„ì ˆì„± ë¶„ì„
    icsa_vs_icnsa = abs(indicators['latest_values']['ICNSA'] - indicators['latest_values']['ICSA'])
    seasonality_impact = icsa_vs_icnsa / indicators['latest_values']['ICSA'] * 100
    print(f"â€¢ í˜„ì¬ ê³„ì ˆì„± ì˜í–¥: {seasonality_impact:.1f}%")
    
    # 4. ê²½ì œì  í•´ì„
    print(f"\nğŸ’¡ ê²½ì œì  í•´ì„")
    print("-" * 40)
    
    # ì´ˆíšŒì‹ ì²­ ìˆ˜ì¤€ í‰ê°€
    if icsa_latest < 300000:
        claims_assessment = "ì–‘í˜¸ - ë…¸ë™ì‹œì¥ì´ ê±´ê°•í•œ ìƒíƒœ"
    elif icsa_latest < 400000:
        claims_assessment = "ë³´í†µ - ë…¸ë™ì‹œì¥ì´ ì•ˆì •ì "
    elif icsa_latest < 500000:
        claims_assessment = "ì£¼ì˜ - ë…¸ë™ì‹œì¥ì— ì••ë ¥ ì¦ê°€"
    else:
        claims_assessment = "ìš°ë ¤ - ë…¸ë™ì‹œì¥ ì•…í™” ì‹ í˜¸"
    
    print(f"â€¢ ì´ˆíšŒì‹ ì²­ ìˆ˜ì¤€ í‰ê°€: {claims_assessment}")
    
    # íŠ¸ë Œë“œ ì¢…í•© í‰ê°€
    icsa_trend = trends['ICSA']['trend_direction']
    ccsa_trend = trends['CCSA']['trend_direction']
    
    if 'í•˜ë½' in icsa_trend and 'í•˜ë½' in ccsa_trend:
        trend_assessment = "ê¸ì •ì  - ì‹¤ì—…ê¸‰ì—¬ ì‹ ì²­ì´ ê°ì†Œ ì¶”ì„¸"
    elif 'ìƒìŠ¹' in icsa_trend or 'ìƒìŠ¹' in ccsa_trend:
        trend_assessment = "ë¶€ì •ì  - ì‹¤ì—…ê¸‰ì—¬ ì‹ ì²­ì´ ì¦ê°€ ì¶”ì„¸"
    else:
        trend_assessment = "ì¤‘ë¦½ì  - ì‹¤ì—…ê¸‰ì—¬ ì‹ ì²­ì´ ë³´í•© ìƒíƒœ"
    
    print(f"â€¢ íŠ¸ë Œë“œ ì¢…í•© í‰ê°€: {trend_assessment}")
    
    print(f"\nğŸ“… ë³´ê³ ì„œ ìƒì„± ì‹œê°„: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)

# =============================================================================
# 7. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# =============================================================================

def main():
    """ë©”ì¸ ë¶„ì„ ì‹¤í–‰"""
    
    # ë°ì´í„° ìˆ˜ì§‘ ë˜ëŠ” ë¡œë“œ
    df, metadata = load_data()
    
    if df is None:
        print("ğŸ’¾ ê¸°ì¡´ ë°ì´í„°ê°€ ì—†ì–´ ìƒˆë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤...")
        df, metadata = collect_fred_data()
        
        if df is not None:
            save_data(df, metadata)
        else:
            print("âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ë¡œ ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return
    
    print(f"\nğŸ“Š ë°ì´í„° í™•ì¸")
    print(f"ê¸°ê°„: {df.index[0].strftime('%Y-%m-%d')} ~ {df.index[-1].strftime('%Y-%m-%d')}")
    print(f"ê´€ì¸¡ì¹˜: {len(df)}ê°œ")
    print(f"ì‹œë¦¬ì¦ˆ: {', '.join(df.columns)}")
    
    # ê²½ì œ ì§€í‘œ ê³„ì‚°
    indicators = calculate_economic_indicators(df)
    trends = analyze_trends(df)
    
    # ë¶„ì„ ë³´ê³ ì„œ ìƒì„±
    generate_analysis_report(df, indicators, trends)
    
    # ì‹œê°í™”
    print(f"\nğŸ¨ ì‹œê°í™” ìƒì„± ì¤‘...")
    
    # 1. ê³„ì ˆì¡°ì • ì‹œë¦¬ì¦ˆ ë¶„ì„
    create_sa_analysis_charts(df)
    
    # 2. ë¹„ê³„ì ˆì¡°ì • ì‹œë¦¬ì¦ˆ 5ë…„ ë¹„êµ
    create_nsa_comparison_charts(df)
    
    # 3. ë¹„êµ ë¶„ì„
    create_comparative_analysis_charts(df)
    
    print(f"\nâœ… ëª¨ë“  ë¶„ì„ ì™„ë£Œ!")
    print("="*60)

# ì‹¤í–‰
if __name__ == "__main__":
    main()
