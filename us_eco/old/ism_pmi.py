# %%
import requests
import pandas as pd
from urllib.parse import urlencode
import dbnomics
import sys
import warnings
import os
warnings.filterwarnings('ignore')

# KPDS ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸° (í•„ìˆ˜)
sys.path.append('/home/jyp0615')
from kpds_fig_format_enhanced import *

print("âœ“ KPDS ì‹œê°í™” í¬ë§· ë¡œë“œë¨")

# %%

def fetch_all_ism_data():
    """
    ëª¨ë“  ISM PMI êµ¬ì„±ìš”ì†Œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ í†µí•© ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë°˜í™˜
    
    ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì‹œë¦¬ì¦ˆ ìœ í˜•ì´ ë‹¤ë¦„:
    - pmi: pm (ì œì¡°ì—… ì¢…í•©ì§€ìˆ˜)
    - ì¼ë°˜: hi, in, lo, ne, sa (% Higher, Index, % Lower, Net, % Same)
    - supdel: fa, in, sl, ne, sa (% Faster, Index, % Slower, Net, % Same)  
    - cusinv: abri, in, tohi, tolo, ne, re (% About Right, Index, % Too High, % Too Low, Net, % Reporting)
    - buypol: 21ê°œì˜ íŠ¹ë³„í•œ ì‹œë¦¬ì¦ˆë“¤
    """
    
    # ì¹´í…Œê³ ë¦¬ë³„ ì‹œë¦¬ì¦ˆ ìœ í˜• ì •ì˜
    category_series = {
        'pmi': ['pm'],  # ì œì¡°ì—… PMI ì¢…í•©ì§€ìˆ˜
        'neword': ['hi', 'in', 'lo', 'ne', 'sa'],
        'production': ['hi', 'in', 'lo', 'ne', 'sa'],
        'employment': ['hi', 'in', 'lo', 'ne', 'sa'],
        'supdel': ['fa', 'in', 'sl', 'ne', 'sa'],  # Faster/Slower ëŒ€ì‹  Higher/Lower
        'inventories': ['hi', 'in', 'lo', 'ne', 'sa'],
        'cusinv': ['abri', 'in', 'tohi', 'tolo', 'ne', 're'],  # About Right, Too High, Too Low, Reporting
        'prices': ['hi', 'in', 'lo', 'ne', 'sa'],
        'bacord': ['hi', 'in', 'lo', 'ne', 'sa'],
        'newexpord': ['hi', 'in', 'lo', 'ne', 'sa'],
        'imports': ['hi', 'in', 'lo', 'ne', 'sa'],
        'buypol': [  # Buying Policy - ì›¹ì‚¬ì´íŠ¸ì—ì„œ í™•ì¸ëœ ì‹¤ì œ ì‹œë¦¬ì¦ˆë“¤
            'caex-1ye', 'caex-30da', 'caex-60da', 'caex-6mo', 'caex-90da', 'caex-avda', 'caex-hamo',
            'mrsu-1ye', 'mrsu-30da', 'mrsu-60da'
        ]
    }
    
    # ëª¨ë“  ë°ì´í„°ë¥¼ ì €ì¥í•  ë°ì´í„°í”„ë ˆì„
    all_data = pd.DataFrame()
    
    print("ISM PMI ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
    
    for category, series_types in category_series.items():
        print(f"\n{category} ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        
        for series_type in series_types:
            try:
                # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                data = dbnomics.fetch_series('ISM', category, series_type)[['period', 'value']]
                
                # ì»¬ëŸ¼ëª… ì„¤ì •
                column_name = f"{category}_{series_type}"
                data.columns = ['date', column_name]
                
                # ë‚ ì§œ ë³€í™˜
                data['date'] = pd.to_datetime(data['date'])
                data = data.set_index('date')
                
                # ê¸°ì¡´ ë°ì´í„°í”„ë ˆì„ê³¼ ë³‘í•©
                if all_data.empty:
                    all_data = data
                else:
                    all_data = all_data.join(data, how='outer')
                
                print(f"  {column_name}: {len(data)} í–‰ ìˆ˜ì§‘ì™„ë£Œ")
                
            except Exception as e:
                print(f"  {category}_{series_type} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
                continue
    
    print(f"\nì´ {len(all_data.columns)}ê°œ ì‹œë¦¬ì¦ˆ, {len(all_data)} í–‰ ìˆ˜ì§‘ì™„ë£Œ")
    print(f"ë°ì´í„° ê¸°ê°„: {all_data.index.min()} ~ {all_data.index.max()}")
    
    return all_data

# %%
def fetch_all_nm_ism_data():
    """
    ëª¨ë“  ISM ë¹„ì œì¡°ì—…(Non-Manufacturing) PMI êµ¬ì„±ìš”ì†Œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ í†µí•© ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë°˜í™˜
    
    ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì‹œë¦¬ì¦ˆ ìœ í˜•ì´ ë‹¤ë¦„:
    - nm-pmi: pm (PMI ì¢…í•©ì§€ìˆ˜)
    - ì¼ë°˜(8ê°œ): hi, in, lo, sa (% Higher, Index, % Lower, % Same)
    - nm-supdel: fa, in, sa, sl (% Faster, Index, % Same, % Slower)  
    - nm-invsen: abri, in, tohi, tolo (% About Right, Index, % Too High, % Too Low)
    """
    
    # ë¹„ì œì¡°ì—… ì¹´í…Œê³ ë¦¬ë³„ ì‹œë¦¬ì¦ˆ ìœ í˜• ì •ì˜
    nm_category_series = {
        'nm-pmi': ['pm'],  # PMI ì¢…í•©ì§€ìˆ˜
        'nm-busact': ['hi', 'in', 'lo', 'sa'],  # Business Activity
        'nm-neword': ['hi', 'in', 'lo', 'sa'],  # New Orders
        'nm-employment': ['hi', 'in', 'lo', 'sa'],  # Employment
        'nm-supdel': ['fa', 'in', 'sa', 'sl'],  # Supplier Deliveries - Faster/Slower
        'nm-inventories': ['hi', 'in', 'lo', 'sa'],  # Inventories
        'nm-prices': ['hi', 'in', 'lo', 'sa'],  # Prices
        'nm-invsen': ['abri', 'in', 'tohi', 'tolo'],  # Inventory Sentiment
        'nm-bacord': ['hi', 'in', 'lo', 'sa'],  # Backlog of Orders
        'nm-newexpord': ['hi', 'in', 'lo', 'sa'],  # New Export Orders
        'nm-imports': ['hi', 'in', 'lo', 'sa'],  # Imports
    }
    
    # ëª¨ë“  ë°ì´í„°ë¥¼ ì €ì¥í•  ë°ì´í„°í”„ë ˆì„
    all_nm_data = pd.DataFrame()
    
    print("ISM ë¹„ì œì¡°ì—… PMI ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
    
    for category, series_types in nm_category_series.items():
        print(f"\n{category} ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        
        for series_type in series_types:
            try:
                # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                data = dbnomics.fetch_series('ISM', category, series_type)[['period', 'value']]
                
                # ì»¬ëŸ¼ëª… ì„¤ì •
                column_name = f"{category}_{series_type}"
                data.columns = ['date', column_name]
                
                # ë‚ ì§œ ë³€í™˜
                data['date'] = pd.to_datetime(data['date'])
                data = data.set_index('date')
                
                # ê¸°ì¡´ ë°ì´í„°í”„ë ˆì„ê³¼ ë³‘í•©
                if all_nm_data.empty:
                    all_nm_data = data
                else:
                    all_nm_data = all_nm_data.join(data, how='outer')
                
                print(f"  {column_name}: {len(data)} í–‰ ìˆ˜ì§‘ì™„ë£Œ")
                
            except Exception as e:
                print(f"  {category}_{series_type} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
                continue
    
    print(f"\nì´ {len(all_nm_data.columns)}ê°œ ë¹„ì œì¡°ì—… ì‹œë¦¬ì¦ˆ, {len(all_nm_data)} í–‰ ìˆ˜ì§‘ì™„ë£Œ")
    print(f"ë°ì´í„° ê¸°ê°„: {all_nm_data.index.min()} ~ {all_nm_data.index.max()}")
    
    return all_nm_data


# %%
# === Enhanced ISM PMI Analysis System ===
"""
ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ë° íˆ¬ìì€í–‰ ìŠ¤íƒ€ì¼ ë¶„ì„ ê¸°ëŠ¥ ì¶”ê°€
- CSV ì €ì¥/ë¡œë“œ ë° ìë™ ì¤‘ë³µ ì²´í¬
- KPDS í¬ë§· ì‹œê°í™”
- ê²½ì œí•™ì/íˆ¬ìì€í–‰ ìŠ¤íƒ€ì¼ ë¶„ì„ ë¦¬í¬íŠ¸
"""
# ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ importëŠ” í•„ìš”ì‹œì—ë§Œ
# import numpy as np
# import plotly.graph_objects as go  
# from plotly.subplots import make_subplots
from datetime import datetime
import sys
import warnings
import os
import json
warnings.filterwarnings('ignore')

# ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
sys.path.append('/home/jyp0615')
from kpds_fig_format_enhanced import *

# %%
# === ISM PMI ì‹œë¦¬ì¦ˆ IDì™€ ì´ë¦„ ë§¤í•‘ ===

# ì œì¡°ì—… PMI í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘ (ëª…í™•í•œ êµ¬ë¶„)
ISM_KOREAN_NAMES = {
    'pmi_pm': 'PMI ì¢…í•©ì§€ìˆ˜ (ì œì¡°ì—…)',
    'neword_in': 'ì‹ ê·œì£¼ë¬¸ (ì œì¡°ì—…)',
    'production_in': 'ìƒì‚° (ì œì¡°ì—…)',
    'employment_in': 'ê³ ìš© (ì œì¡°ì—…)',
    'supdel_in': 'ê³µê¸‰ì—…ì²´ ë°°ì†¡ (ì œì¡°ì—…)',
    'inventories_in': 'ì¬ê³  (ì œì¡°ì—…)',
    'prices_in': 'ê°€ê²© (ì œì¡°ì—…)',
    'bacord_in': 'ìˆ˜ì£¼ì”ê³  (ì œì¡°ì—…)',
    'newexpord_in': 'ì‹ ê·œ ìˆ˜ì¶œì£¼ë¬¸ (ì œì¡°ì—…)',
    'imports_in': 'ìˆ˜ì… (ì œì¡°ì—…)',
    'cusinv_in': 'ê³ ê° ì¬ê³  (ì œì¡°ì—…)'
}

# ë¹„ì œì¡°ì—… PMI í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘ (ëª…í™•í•œ êµ¬ë¶„)
NM_ISM_KOREAN_NAMES = {
    'nm-pmi_pm': 'PMI ì¢…í•©ì§€ìˆ˜ (ë¹„ì œì¡°ì—…)',
    'nm-busact_in': 'ì‚¬ì—…í™œë™ (ë¹„ì œì¡°ì—…)',
    'nm-neword_in': 'ì‹ ê·œì£¼ë¬¸ (ë¹„ì œì¡°ì—…)',
    'nm-employment_in': 'ê³ ìš© (ë¹„ì œì¡°ì—…)',
    'nm-supdel_in': 'ê³µê¸‰ì—…ì²´ ë°°ì†¡ (ë¹„ì œì¡°ì—…)',
    'nm-inventories_in': 'ì¬ê³  (ë¹„ì œì¡°ì—…)',
    'nm-prices_in': 'ê°€ê²© (ë¹„ì œì¡°ì—…)',
    'nm-bacord_in': 'ìˆ˜ì£¼ì”ê³  (ë¹„ì œì¡°ì—…)',
    'nm-newexpord_in': 'ì‹ ê·œ ìˆ˜ì¶œì£¼ë¬¸ (ë¹„ì œì¡°ì—…)',
    'nm-imports_in': 'ìˆ˜ì… (ë¹„ì œì¡°ì—…)',
    'nm-invsen_in': 'ì¬ê³  ê°ì • (ë¹„ì œì¡°ì—…)'
}

# PMI ê³„ì¸µ êµ¬ì¡°
ISM_HIERARCHY = {
    'ì£¼ìš” ì§€í‘œ': {
        'Manufacturing': ['pmi_pm', 'neword_in', 'production_in'],
        'Non-Manufacturing': ['nm-pmi_pm', 'nm-busact_in', 'nm-neword_in']
    },
    'ì„¸ë¶€ êµ¬ì„±': {
        'Labor': ['employment_in', 'nm-employment_in'],
        'Supply Chain': ['supdel_in', 'nm-supdel_in', 'inventories_in', 'nm-inventories_in'],
        'Pricing': ['prices_in', 'nm-prices_in'],
        'Trade': ['newexpord_in', 'nm-newexpord_in', 'imports_in', 'nm-imports_in']
    }
}

# %%
# === ì „ì—­ ë°ì´í„° ì €ì¥ì†Œ ===

# ì „ì—­ ë°ì´í„° ì €ì¥ì†Œ
ISM_DATA = {
    'raw_data': pd.DataFrame(),          # ì›ë³¸ ë ˆë²¨ ë°ì´í„°
    'yoy_data': pd.DataFrame(),          # ì „ë…„ë™ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ë°ì´í„°
    'mom_data': pd.DataFrame(),          # ì „ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ë°ì´í„°
    'diffusion_data': pd.DataFrame(),    # í™•ì‚°ì§€ìˆ˜ (50 ê¸°ì¤€ì„  ëŒ€ë¹„)
    'latest_values': {},                 # ìµœì‹  ê°’ë“¤
    'load_info': {
        'loaded': False,
        'load_time': None,
        'start_date': None,
        'series_count': 0,
        'data_points': 0
    }
}

# %%
# === ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ë° CSV ê´€ë¦¬ í•¨ìˆ˜ë“¤ ===

def save_ism_data_to_csv(file_path='/home/jyp0615/us_eco/ism_pmi_data.csv'):
    """
    í˜„ì¬ ë¡œë“œëœ ISM PMI ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
    
    Args:
        file_path: ì €ì¥í•  CSV íŒŒì¼ ê²½ë¡œ
    """
    if not ISM_DATA['load_info']['loaded']:
        print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return False
    
    try:
        # raw_dataì™€ ë©”íƒ€ë°ì´í„°ë¥¼ í•¨ê»˜ ì €ì¥
        raw_data = ISM_DATA['raw_data']
        
        # ì €ì¥í•  ë°ì´í„° ì¤€ë¹„
        save_data = {
            'timestamp': raw_data.index.tolist(),
            **{col: raw_data[col].tolist() for col in raw_data.columns}
        }
        
        # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
        save_df = pd.DataFrame(save_data)
        save_df.to_csv(file_path, index=False, encoding='utf-8')
        
        # ë©”íƒ€ë°ì´í„°ë„ ë³„ë„ ì €ì¥
        meta_file = file_path.replace('.csv', '_meta.json')
        with open(meta_file, 'w', encoding='utf-8') as f:
            meta_data = {
                'load_time': ISM_DATA['load_info']['load_time'].isoformat() if ISM_DATA['load_info']['load_time'] else None,
                'start_date': ISM_DATA['load_info']['start_date'],
                'series_count': ISM_DATA['load_info']['series_count'],
                'data_points': ISM_DATA['load_info']['data_points'],
                'latest_values': ISM_DATA['latest_values']
            }
            json.dump(meta_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ISM PMI ë°ì´í„° ì €ì¥ ì™„ë£Œ: {file_path}")
        print(f"âœ… ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {meta_file}")
        return True
        
    except Exception as e:
        print(f"âŒ CSV ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def load_ism_data_from_csv(file_path='/home/jyp0615/us_eco/ism_pmi_data.csv'):
    """
    CSV íŒŒì¼ì—ì„œ ISM PMI ë°ì´í„° ë¡œë“œ
    
    Args:
        file_path: ë¡œë“œí•  CSV íŒŒì¼ ê²½ë¡œ
    
    Returns:
        bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
    """
    global ISM_DATA
    
    if not os.path.exists(file_path):
        print(f"âš ï¸ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return False
    
    try:
        # CSV ë°ì´í„° ë¡œë“œ
        df = pd.read_csv(file_path, encoding='utf-8')
        
        # timestamp ì»¬ëŸ¼ì„ ë‚ ì§œ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df.set_index('timestamp', inplace=True)
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        meta_file = file_path.replace('.csv', '_meta.json')
        latest_values = {}
        if os.path.exists(meta_file):
            with open(meta_file, 'r', encoding='utf-8') as f:
                meta_data = json.load(f)
                latest_values = meta_data.get('latest_values', {})
        
        # ì „ì—­ ì €ì¥ì†Œì— ì €ì¥
        ISM_DATA['raw_data'] = df
        ISM_DATA['yoy_data'] = df.apply(calculate_yoy_change)
        ISM_DATA['mom_data'] = df.apply(calculate_mom_change)
        ISM_DATA['diffusion_data'] = df.apply(calculate_diffusion_index)
        ISM_DATA['latest_values'] = latest_values
        ISM_DATA['load_info'] = {
            'loaded': True,
            'load_time': datetime.datetime.now(),
            'start_date': df.index[0].strftime('%Y-%m-%d') if len(df) > 0 else None,
            'series_count': len(df.columns),
            'data_points': len(df)
        }
        
        print(f"âœ… CSVì—ì„œ ISM PMI ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {file_path}")
        print_load_info()
        return True
        
    except Exception as e:
        print(f"âŒ CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

def check_recent_data_consistency_lightweight():
    """
    ê²½ëŸ‰í™”ëœ ì¼ì¹˜ì„± í™•ì¸ í•¨ìˆ˜ - ì£¼ìš” ì§€í‘œë§Œ ìµœì†Œ API í˜¸ì¶œ
    
    Returns:
        dict: ì¼ì¹˜ì„± í™•ì¸ ê²°ê³¼ (need_update, reason)
    """
    if not ISM_DATA['load_info']['loaded']:
        return {'need_update': True, 'reason': 'ê¸°ì¡´ ë°ì´í„° ì—†ìŒ'}
    
    print("ğŸ” ê²½ëŸ‰í™”ëœ ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸ ì¤‘...")
    
    try:
        existing_data = ISM_DATA['raw_data']
        
        # ê¸°ì¡´ ë°ì´í„°ì˜ ìµœì‹  ë‚ ì§œ í™•ì¸
        if 'pmi_pm' not in existing_data.columns:
            return {'need_update': True, 'reason': 'ì£¼ìš” ì§€í‘œ ì—†ìŒ'}
        
        existing_latest_date = existing_data['pmi_pm'].dropna().index[-1]
        print(f"   ê¸°ì¡´ ë°ì´í„° ìµœì‹  ë‚ ì§œ: {existing_latest_date.strftime('%Y-%m')}")
        
        # ì£¼ìš” ì§€í‘œ(PMI ì¢…í•©ì§€ìˆ˜)ë§Œ ê°€ì ¸ì™€ì„œ í™•ì¸ - ê²½ëŸ‰í™”!
        recent_api_data = dbnomics.fetch_series('ISM', 'pmi', 'pm')[['period', 'value']]
        recent_api_data['period'] = pd.to_datetime(recent_api_data['period'])
        recent_api_data = recent_api_data.set_index('period').sort_index()
        
        # ìµœì‹  API ë‚ ì§œ í™•ì¸
        api_latest_date = recent_api_data.index[-1]
        print(f"   API ë°ì´í„° ìµœì‹  ë‚ ì§œ: {api_latest_date.strftime('%Y-%m')}")
        
        # ë‚ ì§œ ë¹„êµ
        if api_latest_date > existing_latest_date:
            print(f"ğŸ†• ìƒˆë¡œìš´ ë°ì´í„° ë°œê²¬: {existing_latest_date.strftime('%Y-%m')} â†’ {api_latest_date.strftime('%Y-%m')}")
            return {'need_update': True, 'reason': f'ìƒˆë¡œìš´ ë°ì´í„° ({api_latest_date.strftime("%Y-%m")})'}
        else:
            print("âœ… ìµœì‹  ë°ì´í„°ê°€ ì¼ì¹˜í•¨")
            return {'need_update': False, 'reason': 'ë°ì´í„° ì¼ì¹˜'}
    
    except Exception as e:
        print(f"âš ï¸ ì¼ì¹˜ì„± í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return {'need_update': True, 'reason': f'í™•ì¸ ì˜¤ë¥˜: {str(e)}'}

# %%
# === ë¶„ì„ ê³„ì‚° í•¨ìˆ˜ë“¤ ===

def calculate_yoy_change(data):
    """ì „ë…„ë™ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ê³„ì‚°"""
    return ((data / data.shift(12)) - 1) * 100

def calculate_mom_change(data):
    """ì „ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ê³„ì‚°"""
    return ((data / data.shift(1)) - 1) * 100

def calculate_diffusion_index(data):
    """í™•ì‚°ì§€ìˆ˜ ê³„ì‚° (50 ê¸°ì¤€ì„  ëŒ€ë¹„)"""
    return data - 50

# %%
# === Enhanced ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ===

def load_all_ism_data_enhanced(start_date='2020-01-01', force_reload=False, smart_update=True, csv_file='/home/jyp0615/us_eco/ism_pmi_data.csv'):
    """
    ëª¨ë“  ISM PMI ë°ì´í„° ë¡œë“œ (ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì§€ì›)
    
    Args:
        start_date: ì‹œì‘ ë‚ ì§œ
        force_reload: ê°•ì œ ì¬ë¡œë“œ ì—¬ë¶€
        smart_update: ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        csv_file: CSV íŒŒì¼ ê²½ë¡œ
    
    Returns:
        bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
    """
    global ISM_DATA
    
    # ì´ë¯¸ ë¡œë“œëœ ê²½ìš° ìŠ¤í‚µ (ê°•ì œ ì¬ë¡œë“œê°€ ì•„ë‹Œ ê²½ìš°)
    if ISM_DATA['load_info']['loaded'] and not force_reload and not smart_update:
        print("ğŸ’¾ ì´ë¯¸ ë¡œë“œëœ ë°ì´í„° ì‚¬ìš© ì¤‘")
        print_load_info()
        return True
    
    # ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ë¡œì§
    needs_api_call = True
    consistency_result = None
    
    if smart_update and not force_reload:
        print("ğŸ¤– ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ëª¨ë“œ í™œì„±í™”")
        
        # ë¨¼ì € CSVì—ì„œ ë°ì´í„° ë¡œë“œ ì‹œë„
        csv_loaded = load_ism_data_from_csv(csv_file)
        
        if csv_loaded and not ISM_DATA['raw_data'].empty:
            # CSV ë°ì´í„°ê°€ ì´ë¯¸ ì „ì—­ ì €ì¥ì†Œì— ë¡œë“œë¨ (load_ism_data_from_csv í•¨ìˆ˜ì—ì„œ)
            
            # ê²½ëŸ‰í™”ëœ ì¼ì¹˜ì„± í™•ì¸
            consistency_result = check_recent_data_consistency_lightweight()
            
            # ì¼ì¹˜ì„± ê²°ê³¼ ì¶œë ¥
            print(f"ğŸ” ì¼ì¹˜ì„± í™•ì¸ ê²°ê³¼: {consistency_result.get('reason', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
            
            needs_api_call = consistency_result.get('need_update', True)
            
            if not needs_api_call:
                print("âœ… ìµœê·¼ ë°ì´í„°ê°€ ì¼ì¹˜í•¨ - API í˜¸ì¶œ ê±´ë„ˆë›°ê¸°")
                # CSV ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© 
                # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
                latest_values = {}
                for col in ISM_DATA['raw_data'].columns:
                    if not ISM_DATA['raw_data'][col].isna().all():
                        latest_values[col] = ISM_DATA['raw_data'][col].dropna().iloc[-1]
                
                ISM_DATA['latest_values'] = latest_values
                ISM_DATA['load_info'] = {
                    'loaded': True,
                    'load_time': datetime.datetime.now(),
                    'start_date': start_date,
                    'series_count': len(ISM_DATA['raw_data'].columns),
                    'data_points': len(ISM_DATA['raw_data']),
                    'source': 'CSV (ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸)',
                    'consistency_check': consistency_result
                }
                
                print("ğŸ’¾ CSV ë°ì´í„° ì‚¬ìš© (ì¼ì¹˜ì„± í™•ì¸ë¨)")
                print_load_info()
                return True
            else:
                print("ğŸ“¡ ë°ì´í„° ë¶ˆì¼ì¹˜ ê°ì§€ - ì „ì²´ API í˜¸ì¶œ ì§„í–‰")
    
    # APIë¥¼ í†µí•œ ì „ì²´ ë°ì´í„° ë¡œë“œ
    if needs_api_call:
        print("ğŸš€ ISM PMI ë°ì´í„° ë¡œë”© ì‹œì‘... (DBnomics API)")
        print("="*50)
        
        try:
            # ì œì¡°ì—… ë°ì´í„° ìˆ˜ì§‘
            print("1ï¸âƒ£ ì œì¡°ì—… PMI ë°ì´í„° ìˆ˜ì§‘...")
            manu_data = fetch_all_ism_data()
            
            # ë¹„ì œì¡°ì—… ë°ì´í„° ìˆ˜ì§‘
            print("\n2ï¸âƒ£ ë¹„ì œì¡°ì—… PMI ë°ì´í„° ìˆ˜ì§‘...")
            nm_data = fetch_all_nm_ism_data()
            
            # ë°ì´í„° í†µí•©
            print("\n3ï¸âƒ£ ë°ì´í„° í†µí•©...")
            if not manu_data.empty and not nm_data.empty:
                combined_data = manu_data.join(nm_data, how='outer')
            elif not manu_data.empty:
                combined_data = manu_data
            elif not nm_data.empty:
                combined_data = nm_data
            else:
                print("âŒ ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            if len(combined_data.columns) < 5:  # ìµœì†Œ 5ê°œ ì‹œë¦¬ì¦ˆëŠ” ìˆì–´ì•¼ í•¨
                error_msg = f"âŒ ë¡œë“œëœ ì‹œë¦¬ì¦ˆê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤: {len(combined_data.columns)}ê°œ"
                print(error_msg)
                return False
            
            # ë‚ ì§œ í•„í„°ë§
            if start_date:
                combined_data = combined_data[combined_data.index >= start_date]
            
            # ì „ì—­ ì €ì¥ì†Œì— ì €ì¥
            ISM_DATA['raw_data'] = combined_data
            ISM_DATA['yoy_data'] = combined_data.apply(calculate_yoy_change)
            ISM_DATA['mom_data'] = combined_data.apply(calculate_mom_change)
            ISM_DATA['diffusion_data'] = combined_data.apply(calculate_diffusion_index)
            
            # ìµœì‹  ê°’ ì €ì¥
            latest_values = {}
            for col in combined_data.columns:
                if not combined_data[col].isna().all():
                    latest_values[col] = combined_data[col].dropna().iloc[-1]
            ISM_DATA['latest_values'] = latest_values
            
            ISM_DATA['load_info'] = {
                'loaded': True,
                'load_time': datetime.datetime.now(),
                'start_date': start_date,
                'series_count': len(combined_data.columns),
                'data_points': len(combined_data),
                'source': 'API (ì „ì²´ ë¡œë“œ)'
            }
            
            if consistency_result:
                ISM_DATA['load_info']['consistency_check'] = consistency_result
            
            # CSVì— ì €ì¥
            save_ism_data_to_csv(csv_file)
            
            print("\nâœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
            print_load_info()
            
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
            return False
    
    return False

def update_ism_data_from_api_enhanced(smart_update=True):
    """
    APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸ (ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì§€ì›)
    
    Args:
        smart_update: ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì‚¬ìš© ì—¬ë¶€ (ìµœê·¼ 3ê°œ ë°ì´í„° ë¹„êµ)
    
    Returns:
        bool: ì—…ë°ì´íŠ¸ ì„±ê³µ ì—¬ë¶€
    """
    global ISM_DATA
    
    if not ISM_DATA['load_info']['loaded']:
        print("âš ï¸ ê¸°ì¡´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ë¡œë“œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
        return load_all_ism_data_enhanced()
    
    # ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ í™œì„±í™”ì‹œ ìµœê·¼ ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸
    if smart_update:
        consistency_check = check_recent_data_consistency_lightweight()
        
        # ì—…ë°ì´íŠ¸ í•„ìš” ì—†ìœ¼ë©´ ë°”ë¡œ ì¢…ë£Œ
        if not consistency_check.get('need_update', True):
            print("ğŸ¯ ë°ì´í„°ê°€ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤. API í˜¸ì¶œì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return True
        
        print(f"ğŸ”„ ì—…ë°ì´íŠ¸ ì§„í–‰: {consistency_check['reason']}")
    
    print(f"ğŸ”„ ISM PMI ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘")
    print("="*50)
    
    try:
        # ìƒˆë¡œìš´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        print("ğŸ“Š ìµœì‹  ì œì¡°ì—… PMI ë°ì´í„° ê°€ì ¸ì˜¤ê¸°...")
        new_manu_data = fetch_all_ism_data()
        
        print("ğŸ“Š ìµœì‹  ë¹„ì œì¡°ì—… PMI ë°ì´í„° ê°€ì ¸ì˜¤ê¸°...")
        new_nm_data = fetch_all_nm_ism_data()
        
        # ë°ì´í„° í†µí•©
        if not new_manu_data.empty and not new_nm_data.empty:
            new_combined_data = new_manu_data.join(new_nm_data, how='outer')
        elif not new_manu_data.empty:
            new_combined_data = new_manu_data
        elif not new_nm_data.empty:
            new_combined_data = new_nm_data
        else:
            print("âš ï¸ ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©
        existing_data = ISM_DATA['raw_data']
        all_dates = existing_data.index.union(new_combined_data.index).sort_values()
        
        # ê° ì‹œë¦¬ì¦ˆë³„ ì—…ë°ì´íŠ¸
        updated_data = {}
        for col in existing_data.columns:
            if col in new_combined_data.columns:
                combined_series = existing_data[col].reindex(all_dates)
                # ìƒˆ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ê°’ ë®ì–´ì“°ê¸°)
                for date, value in new_combined_data[col].items():
                    combined_series.loc[date] = value
                updated_data[col] = combined_series
            else:
                updated_data[col] = existing_data[col].reindex(all_dates)
        
        # ìƒˆë¡œìš´ ì‹œë¦¬ì¦ˆ ì¶”ê°€
        for col in new_combined_data.columns:
            if col not in existing_data.columns:
                updated_data[col] = new_combined_data[col].reindex(all_dates)
        
        # ì „ì—­ ì €ì¥ì†Œ ì—…ë°ì´íŠ¸
        updated_df = pd.DataFrame(updated_data)
        ISM_DATA['raw_data'] = updated_df
        ISM_DATA['yoy_data'] = updated_df.apply(calculate_yoy_change)
        ISM_DATA['mom_data'] = updated_df.apply(calculate_mom_change)
        ISM_DATA['diffusion_data'] = updated_df.apply(calculate_diffusion_index)
        
        # ìµœì‹  ê°’ ì—…ë°ì´íŠ¸
        latest_values = {}
        for col in updated_df.columns:
            if not updated_df[col].isna().all():
                latest_values[col] = updated_df[col].dropna().iloc[-1]
        ISM_DATA['latest_values'] = latest_values
        
        # ë¡œë“œ ì •ë³´ ì—…ë°ì´íŠ¸
        ISM_DATA['load_info']['load_time'] = datetime.datetime.now()
        ISM_DATA['load_info']['series_count'] = len(updated_df.columns)
        ISM_DATA['load_info']['data_points'] = len(updated_df)
        
        print(f"\nâœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
        print_load_info()
        
        # ìë™ìœ¼ë¡œ CSVì— ì €ì¥
        save_ism_data_to_csv()
        
        return True
        
    except Exception as e:
        print(f"âŒ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def print_load_info():
    """ë¡œë“œ ì •ë³´ ì¶œë ¥"""
    info = ISM_DATA['load_info']
    if not info['loaded']:
        print("âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ")
        return
    
    print(f"ğŸ“Š ë¡œë“œëœ ë°ì´í„° ì •ë³´:")
    print(f"   ì‹œë¦¬ì¦ˆ ê°œìˆ˜: {info['series_count']}")
    print(f"   ë°ì´í„° í¬ì¸íŠ¸: {info['data_points']}")
    print(f"   ì‹œì‘ ë‚ ì§œ: {info['start_date']}")
    print(f"   ë¡œë“œ ì‹œê°„: {info['load_time'].strftime('%Y-%m-%d %H:%M:%S')}")
    
    if not ISM_DATA['raw_data'].empty:
        date_range = f"{ISM_DATA['raw_data'].index[0].strftime('%Y-%m')} ~ {ISM_DATA['raw_data'].index[-1].strftime('%Y-%m')}"
        print(f"   ë°ì´í„° ê¸°ê°„: {date_range}")

# %%
# === ë°ì´í„° ì ‘ê·¼ í•¨ìˆ˜ë“¤ ===

def get_raw_data(series_names=None):
    """ì›ë³¸ ë ˆë²¨ ë°ì´í„° ë°˜í™˜"""
    if not ISM_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_ism_data_enhanced()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return pd.DataFrame()
    
    if series_names is None:
        return ISM_DATA['raw_data'].copy()
    
    available_series = [s for s in series_names if s in ISM_DATA['raw_data'].columns]
    if not available_series:
        print(f"âš ï¸ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤: {series_names}")
        return pd.DataFrame()
    
    return ISM_DATA['raw_data'][available_series].copy()

def get_diffusion_data(series_names=None):
    """í™•ì‚°ì§€ìˆ˜ ë°ì´í„° ë°˜í™˜ (50 ê¸°ì¤€ì„  ëŒ€ë¹„)"""
    if not ISM_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_ism_data_enhanced()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return pd.DataFrame()
    
    if series_names is None:
        return ISM_DATA['diffusion_data'].copy()
    
    available_series = [s for s in series_names if s in ISM_DATA['diffusion_data'].columns]
    if not available_series:
        print(f"âš ï¸ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤: {series_names}")
        return pd.DataFrame()
    
    return ISM_DATA['diffusion_data'][available_series].copy()

# %%
# === íˆ¬ìì€í–‰/ì´ì½”ë…¸ë¯¸ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ ì‹œê°í™” í•¨ìˆ˜ë“¤ ===

def create_ism_timeseries_chart(series_names=None, chart_type='diffusion', start_date=None):
    """
    ì €ì¥ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ISM PMI ì‹œê³„ì—´ ì°¨íŠ¸ ìƒì„±
    
    Args:
        series_names: ì°¨íŠ¸ì— í‘œì‹œí•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸
        chart_type: 'diffusion' (í™•ì‚°ì§€ìˆ˜), 'raw' (ì›ë³¸ ìˆ˜ì¤€)
        title: ì°¨íŠ¸ ì œëª©
        start_date: ì‹œì‘ ë‚ ì§œ (ì˜ˆ: '2021-01-01')
    """
    if not ISM_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_ism_data_enhanced()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    if series_names is None:
        series_names = ['pmi_pm', 'nm-pmi_pm', 'neword_in', 'nm-neword_in']  # ì£¼ìš” ì§€í‘œë“¤
    
    # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    if chart_type == 'diffusion':
        df = get_diffusion_data(series_names)
        ytitle = "í¬ì¸íŠ¸ (50 ê¸°ì¤€ì„  ëŒ€ë¹„)"
        print("ISM PMI í™•ì‚°ì§€ìˆ˜ - 50 ê¸°ì¤€ì„  ëŒ€ë¹„")
    else:  # raw
        df = get_raw_data(series_names)
        ytitle = "ì§€ìˆ˜"
        print("ISM PMI ì§€ìˆ˜")
    
    if df.empty:
        print("âš ï¸ ìš”ì²­í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ì‹œì‘ ë‚ ì§œ í•„í„°ë§
    if start_date:
        df = df[df.index >= start_date]
    
    # ë¼ë²¨ ë§¤í•‘
    label_mapping = {**ISM_KOREAN_NAMES, **NM_ISM_KOREAN_NAMES}
    chart_data = {}
    for col in df.columns:
        label = label_mapping.get(col, col)
        chart_data[label] = df[col].dropna()
    
    # KPDS í¬ë§· ì‚¬ìš©í•˜ì—¬ ì°¨íŠ¸ ìƒì„±
    chart_df = pd.DataFrame(chart_data)
    
    # ë¼ë²¨ ë§¤í•‘ ì ìš©
    labels = {col: col for col in chart_df.columns}  # ì´ë¯¸ í•œêµ­ì–´ë¡œ ë³€í™˜ëœ ì»¬ëŸ¼ëª…
    
    fig = df_multi_line_chart(chart_df, chart_df.columns.tolist(), ytitle=ytitle, labels=labels)
    
    if chart_type == 'diffusion':
        fig.add_hline(y=0, line_width=2, line_color="black", opacity=0.8)
    else:
        # PMI 50 ê¸°ì¤€ì„  ì¶”ê°€
        fig.add_hline(y=50, line_width=2, line_color="red", opacity=0.7, 
                      annotation_text="50 ê¸°ì¤€ì„  (í™•ì¥/ìˆ˜ì¶•)")
    
    return fig

def create_ism_horizontal_bar_chart(chart_type='diffusion'):
    """
    ISM PMI êµ¬ì„±ìš”ì†Œë³„ í˜„ì¬ ìƒíƒœë¥¼ ë³´ì—¬ì£¼ëŠ” ê°€ë¡œ ë°” ì°¨íŠ¸ ìƒì„±
    
    Args:
        chart_type: 'diffusion', 'raw'
        title: ì°¨íŠ¸ ì œëª©
    
    Returns:
        plotly figure
    """
    if not ISM_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_ism_data_enhanced()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ìµœì‹  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    if chart_type == 'diffusion':
        data = get_diffusion_data()
        default_title = "ISM PMI í™•ì‚°ì§€ìˆ˜ - 50 ê¸°ì¤€ì„  ëŒ€ë¹„ (ìµœì‹ )"
        unit = "í¬ì¸íŠ¸"
        print(default_title)
    else:  # raw
        data = get_raw_data()
        default_title = "ISM PMI ì§€ìˆ˜ (ìµœì‹ )"
        unit = "ì§€ìˆ˜"
        print(default_title)
    
    # ì£¼ìš” Index ì‹œë¦¬ì¦ˆë§Œ ì„ íƒ
    index_columns = [col for col in data.columns if col.endswith('_in') or col.endswith('_pm')]
    latest_data = data[index_columns].iloc[-1].dropna()
    
    # ë°ì´í„° ì •ë ¬
    sorted_data = latest_data.sort_values(ascending=True)
    
    # ë¼ë²¨ ì ìš©
    label_mapping = {**ISM_KOREAN_NAMES, **NM_ISM_KOREAN_NAMES}
    categories = []
    values = []
    colors = []
    
    for series_id, value in sorted_data.items():
        label = label_mapping.get(series_id, series_id)
        categories.append(label)
        values.append(value)
        
        # ì£¼ìš” ì§€í‘œëŠ” íŠ¹ë³„ ìƒ‰ìƒ
        if series_id in ['pmi_pm', 'nm-pmi_pm']:
            colors.append('#FFA500')  # ì£¼í™©ìƒ‰
        elif value >= 0:
            colors.append(deepred_pds)  # ìƒìŠ¹: deepred_pds
        else:
            colors.append(deepblue_pds)  # í•˜ë½: deepblue_pds
    
    # ê°€ë¡œ ë°” ì°¨íŠ¸ ìƒì„± (KPDS ìƒ‰ìƒ ì‚¬ìš©)
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        y=categories,
        x=values,
        orientation='h',
        marker_color=colors,
        text=[f'{v:.1f}' for v in values],
        textposition='outside' if all(v >= 0 for v in values) else 'auto',
        showlegend=False,
        textfont=dict(family='NanumGothic', size=FONT_SIZE_GENERAL-1)
    ))
    
    # ìµœì‹  ë‚ ì§œ ê°€ì ¸ì˜¤ê¸°
    latest_date = ISM_DATA['raw_data'].index[-1].strftime('%B %Y')
    
    # ë ˆì´ì•„ì›ƒ ì„¤ì • (KPDS í¬ë§· ì¤€ìˆ˜)
    fig.update_layout(
        paper_bgcolor='white',
        plot_bgcolor='white',
        width=686,  # KPDS í‘œì¤€ ë„ˆë¹„
        height=max(400, len(categories) * 30),
        font=dict(family='NanumGothic', size=FONT_SIZE_GENERAL, color="black"),
        xaxis=dict(
            title=dict(text="", font=dict(family='NanumGothic', size=FONT_SIZE_AXIS_TITLE)),
            showline=True, linewidth=1.3, linecolor='lightgrey',
            tickwidth=1.3, tickcolor='lightgrey',
            ticks='outside',
            tickformat='.1f',
            range=[min(values) * 1.2 if min(values) < 0 else -abs(max(values)) * 0.1, max(values) * 1.2],
            showgrid=True, gridwidth=1, gridcolor="lightgrey"
        ),
        yaxis=dict(
            title=dict(text="", font=dict(family='NanumGothic', size=FONT_SIZE_AXIS_TITLE)),
            showline=False,
            tickcolor='white',
            showgrid=False
        ),
        margin=dict(l=200, r=80, t=80, b=60),
        legend=dict(
            font=dict(family='NanumGothic', size=FONT_SIZE_LEGEND),
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )
    
    # 0ì„  ì¶”ê°€
    fig.add_vline(x=0, line_width=2, line_color="black")
    
    # Yì¶• ë‹¨ìœ„ annotation
    fig.add_annotation(
        text=unit,
        xref="paper", yref="paper",
        x=-0.02, y=1.1,  # ì™¼ìª½ ìœ„ì¹˜ë¡œ ê³ ì •
        showarrow=False,
        font=dict(size=FONT_SIZE_ANNOTATION, family='NanumGothic', color="black"),
        align='left'
    )
    
    return fig

def create_ism_mom_bar_chart(sector='both'):
    """
    ISM PMI êµ¬ì„±ìš”ì†Œë³„ MoM ë³€í™”ë¥¼ ë³´ì—¬ì£¼ëŠ” ê°€ë¡œ ë°” ì°¨íŠ¸ ìƒì„±
    
    Args:
        sector: 'manufacturing', 'services', 'both' 
        title: ì°¨íŠ¸ ì œëª©
    
    Returns:
        plotly figure
    """
    if not ISM_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_ism_data_enhanced()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ì „ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ê³„ì‚°ì´ í•„ìš”í•˜ë©´ ì¶”ê°€
    if 'mom_data' not in ISM_DATA or ISM_DATA['mom_data'].empty:
        ISM_DATA['mom_data'] = ISM_DATA['raw_data'].apply(calculate_mom_change)
    
    # ìµœì‹  MoM ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    latest_mom = ISM_DATA['mom_data'].iloc[-1]
    
    # ì„¹í„°ë³„ ì‹œë¦¬ì¦ˆ ì„ íƒ
    if sector == 'manufacturing':
        index_columns = [col for col in latest_mom.index if col.endswith('_in') or col.endswith('_pm')]
        index_columns = [col for col in index_columns if not col.startswith('nm-')]
        default_title = "ì œì¡°ì—… PMI êµ¬ì„±ìš”ì†Œ MoM ë³€í™”ìœ¨"
        print(default_title)
    elif sector == 'services':
        index_columns = [col for col in latest_mom.index if col.startswith('nm-') and (col.endswith('_in') or col.endswith('_pm'))]
        default_title = "ë¹„ì œì¡°ì—… PMI êµ¬ì„±ìš”ì†Œ MoM ë³€í™”ìœ¨"
        print(default_title)
    else:  # both
        index_columns = [col for col in latest_mom.index if col.endswith('_in') or col.endswith('_pm')]
        default_title = "ISM PMI êµ¬ì„±ìš”ì†Œ MoM ë³€í™”ìœ¨ (ì œì¡°ì—… vs ë¹„ì œì¡°ì—…)"
        print(default_title)
    
    # ë°ì´í„° í•„í„°ë§ ë° ì •ë ¬
    valid_data = latest_mom[index_columns].dropna()
    sorted_data = valid_data.sort_values(ascending=True)
    
    # ë¼ë²¨ ì ìš©
    label_mapping = {**ISM_KOREAN_NAMES, **NM_ISM_KOREAN_NAMES}
    categories = []
    values = []
    colors = []
    
    for series_id, value in sorted_data.items():
        label = label_mapping.get(series_id, series_id)
        categories.append(label)
        values.append(value)
        
        # ìƒ‰ìƒ êµ¬ë¶„: ì œì¡°ì—… vs ë¹„ì œì¡°ì—…
        if series_id.startswith('nm-'):
            if value >= 0:
                colors.append(deepblue_pds)  # ë¹„ì œì¡°ì—… ìƒìŠ¹
            else:
                colors.append(blue_pds)  # ë¹„ì œì¡°ì—… í•˜ë½
        else:
            if value >= 0:
                colors.append(deepred_pds)  # ì œì¡°ì—… ìƒìŠ¹
            else:
                colors.append(red_pds)  # ì œì¡°ì—… í•˜ë½
    
    # ê°€ë¡œ ë°” ì°¨íŠ¸ ìƒì„± (KPDS í¬ë§·)
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        y=categories,
        x=values,
        orientation='h',
        marker_color=colors,
        text=[f'{v:+.2f}%' for v in values],
        textposition='outside' if all(v >= 0 for v in values) else 'auto',
        showlegend=False,
        textfont=dict(family='NanumGothic', size=FONT_SIZE_GENERAL-1)
    ))
    
    # ìµœì‹  ë‚ ì§œ ê°€ì ¸ì˜¤ê¸°
    latest_date = ISM_DATA['raw_data'].index[-1].strftime('%Yë…„ %mì›”')
    
    # ë ˆì´ì•„ì›ƒ ì„¤ì • (KPDS í¬ë§· ì¤€ìˆ˜)
    fig.update_layout(
        paper_bgcolor='white',
        plot_bgcolor='white',
        width=686,  # KPDS í‘œì¤€ ë„ˆë¹„
        height=max(400, len(categories) * 30),
        font=dict(family='NanumGothic', size=FONT_SIZE_GENERAL, color="black"),
        xaxis=dict(
            title=dict(text="MoM ë³€í™”ìœ¨ (%)", font=dict(family='NanumGothic', size=FONT_SIZE_AXIS_TITLE)),
            showline=True, linewidth=1.3, linecolor='lightgrey',
            tickwidth=1.3, tickcolor='lightgrey',
            ticks='outside',
            tickformat='+.1f',
            range=[min(values) * 1.2 if min(values) < 0 else -abs(max(values)) * 0.1, max(values) * 1.2],
            showgrid=True, gridwidth=1, gridcolor="lightgrey"
        ),
        yaxis=dict(
            title=dict(text="", font=dict(family='NanumGothic', size=FONT_SIZE_AXIS_TITLE)),
            showline=False,
            tickcolor='white',
            showgrid=False
        ),
        margin=dict(l=250, r=100, t=80, b=60),  # ê¸´ ë¼ë²¨ì„ ìœ„í•´ ì™¼ìª½ ì—¬ë°± ì¦ê°€
    )
    
    # 0ì„  ì¶”ê°€
    fig.add_vline(x=0, line_width=2, line_color="black")
    
    return fig

def create_manufacturing_vs_services_chart(chart_type='raw', start_date=None):
    """
    ì œì¡°ì—… vs ë¹„ì œì¡°ì—… PMI ë¹„êµ ì°¨íŠ¸
    
    Args:
        chart_type: 'diffusion', 'raw'
        title: ì°¨íŠ¸ ì œëª©
        start_date: ì‹œì‘ ë‚ ì§œ
    """
    if not ISM_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_ism_data_enhanced()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ì œì¡°ì—… vs ë¹„ì œì¡°ì—… ì£¼ìš” ì§€í‘œ ì„ íƒ
    series_names = ['pmi_pm', 'nm-pmi_pm', 'neword_in', 'nm-neword_in', 'production_in', 'nm-busact_in']
    
    print("ì œì¡°ì—… vs ë¹„ì œì¡°ì—… PMI ë¹„êµ")
    
    return create_ism_timeseries_chart(series_names, chart_type, start_date)

def create_ism_economic_dashboard(start_date='2022-01-01'):
    """
    ISM PMI ê²½ì œ ëŒ€ì‹œë³´ë“œ - íˆ¬ìì€í–‰ ìŠ¤íƒ€ì¼
    ì—¬ëŸ¬ ì°¨íŠ¸ë¥¼ í•œ ë²ˆì— ìƒì„±í•˜ì—¬ ê²½ì œ ìƒí™©ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„
    
    Args:
        start_date: ë¶„ì„ ì‹œì‘ ë‚ ì§œ
    
    Returns:
        dict: ìƒì„±ëœ ì°¨íŠ¸ë“¤
    """
    if not ISM_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_ism_data_enhanced()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    print("ğŸ¦ ISM PMI ê²½ì œ ëŒ€ì‹œë³´ë“œ ìƒì„± ì¤‘...")
    print("="*50)
    
    results = {}
    
    try:
        # 1. ì œì¡°ì—… vs ë¹„ì œì¡°ì—… PMI ì¢…í•©ì§€ìˆ˜
        print("ğŸ“Š 1. ì œì¡°ì—… vs ë¹„ì œì¡°ì—… PMI ì¢…í•©ì§€ìˆ˜...")
        results['main_pmi_comparison'] = create_manufacturing_vs_services_chart('raw', 
                                                                               "ì œì¡°ì—… vs ë¹„ì œì¡°ì—… PMI ì¢…í•©ì§€ìˆ˜", start_date)
        
        # 2. í™•ì‚°ì§€ìˆ˜ ì°¨íŠ¸ (50 ê¸°ì¤€ì„  ëŒ€ë¹„)
        print("ğŸ“Š 2. PMI í™•ì‚°ì§€ìˆ˜ (50 ê¸°ì¤€ì„  ëŒ€ë¹„)...")
        results['diffusion_index'] = create_ism_timeseries_chart(['pmi_pm', 'nm-pmi_pm'], 'diffusion', 
                                                                "ISM PMI í™•ì‚°ì§€ìˆ˜ - 50 ê¸°ì¤€ì„  ëŒ€ë¹„", start_date)
        
        # 3. í˜„ì¬ ìƒíƒœ ê°€ë¡œ ë°” ì°¨íŠ¸
        print("ğŸ“Š 3. í˜„ì¬ PMI ìƒíƒœ...")
        results['current_status'] = create_ism_horizontal_bar_chart('diffusion')
        
        # 4. MoM ë³€í™”ìœ¨ ê°€ë¡œ ë°” ì°¨íŠ¸ (ì œì¡°ì—… vs ë¹„ì œì¡°ì—…)
        print("ğŸ“Š 4. MoM ë³€í™”ìœ¨ ë¹„êµ...")
        results['mom_comparison'] = create_ism_mom_bar_chart('both')
        
        # 5. ì œì¡°ì—… ì„¸ë¶€ MoM ë¶„ì„
        print("ğŸ“Š 5. ì œì¡°ì—… ì„¸ë¶€ MoM ë¶„ì„...")
        results['manufacturing_mom'] = create_ism_mom_bar_chart('manufacturing')
        
        # 6. ë¹„ì œì¡°ì—… ì„¸ë¶€ MoM ë¶„ì„
        print("ğŸ“Š 6. ë¹„ì œì¡°ì—… ì„¸ë¶€ MoM ë¶„ì„...")
        results['services_mom'] = create_ism_mom_bar_chart('services')
        
        # 7. ê³µê¸‰ë§ ê´€ë ¨ ì§€í‘œë“¤
        print("ğŸ“Š 7. ê³µê¸‰ë§ ê´€ë ¨ ì§€í‘œ...")
        supply_series = ['supdel_in', 'nm-supdel_in', 'inventories_in', 'nm-inventories_in', 'prices_in', 'nm-prices_in']
        results['supply_chain'] = create_ism_timeseries_chart(supply_series, 'raw', "ê³µê¸‰ë§ ê´€ë ¨ PMI ì§€í‘œ", start_date)
        
        # 8. ê³ ìš© ê´€ë ¨ ì§€í‘œ
        print("ğŸ“Š 8. ê³ ìš© ê´€ë ¨ ì§€í‘œ...")
        employment_series = ['employment_in', 'nm-employment_in']
        results['employment'] = create_ism_timeseries_chart(employment_series, 'raw', "ê³ ìš© ê´€ë ¨ PMI ì§€í‘œ", start_date)
        
    except Exception as e:
        print(f"âš ï¸ ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
    
    print(f"\nâœ… ê²½ì œ ëŒ€ì‹œë³´ë“œ ì™„ë£Œ! ìƒì„±ëœ ì°¨íŠ¸: {len(results)}ê°œ")
    return results

# %%
# === ê²½ì œ ë¶„ì„ ë¦¬í¬íŠ¸ í•¨ìˆ˜ ===

def generate_ism_economic_report():
    """
    íˆ¬ìì€í–‰ ìŠ¤íƒ€ì¼ì˜ ISM PMI ê²½ì œ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
    """
    if not ISM_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_ism_data_enhanced()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    print("ğŸ“ ISM PMI ê²½ì œ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±")
    print("="*50)
    
    # ìµœì‹  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    latest_date = ISM_DATA['raw_data'].index[-1]
    latest_raw = ISM_DATA['raw_data'].iloc[-1]
    latest_diffusion = ISM_DATA['diffusion_data'].iloc[-1]
    
    print(f"ğŸ“… ë¶„ì„ ê¸°ì¤€ì¼: {latest_date.strftime('%Yë…„ %mì›”')}")
    print()
    
    # 1. ì£¼ìš” ì§€í‘œ ìš”ì•½
    print("ğŸ“Š ì£¼ìš” ì§€í‘œ í˜„í™©:")
    key_indicators = ['pmi_pm', 'nm-pmi_pm', 'neword_in', 'nm-neword_in', 'employment_in', 'nm-employment_in']
    
    for indicator in key_indicators:
        if indicator in latest_raw.index:
            value = latest_raw[indicator]
            diffusion = latest_diffusion[indicator] if indicator in latest_diffusion.index else None
            korean_name = {**ISM_KOREAN_NAMES, **NM_ISM_KOREAN_NAMES}.get(indicator, indicator)
            
            # ìƒíƒœ íŒì •
            if indicator.endswith('_pm'):  # PMI ì¢…í•©ì§€ìˆ˜
                status = "í™•ì¥" if value > 50 else "ìˆ˜ì¶•"
                status_emoji = "ğŸŸ¢" if value > 50 else "ğŸ”´"
            else:
                status = "ê°œì„ " if diffusion > 0 else "ì•…í™”"
                status_emoji = "ğŸŸ¢" if diffusion > 0 else "ğŸ”´"
            
            print(f"  {status_emoji} {korean_name}: {value:.1f} ({status})")
    
    print()
    
    # 2. ì œì¡°ì—… vs ë¹„ì œì¡°ì—… ë¹„êµ
    print("ğŸ­ ì œì¡°ì—… vs ë¹„ì œì¡°ì—… ë¹„êµ:")
    manu_pmi = latest_raw.get('pmi_pm', 0)
    services_pmi = latest_raw.get('nm-pmi_pm', 0)
    
    print(f"  ì œì¡°ì—… PMI: {manu_pmi:.1f}")
    print(f"  ë¹„ì œì¡°ì—… PMI: {services_pmi:.1f}")
    
    if manu_pmi > 0 and services_pmi > 0:
        gap = manu_pmi - services_pmi
        if abs(gap) < 1:
            print(f"  â†’ ì œì¡°ì—…ê³¼ ë¹„ì œì¡°ì—…ì´ ê· í˜•ì¡íŒ ìƒíƒœ (ê²©ì°¨: {gap:+.1f}p)")
        elif gap > 0:
            print(f"  â†’ ì œì¡°ì—…ì´ ë¹„ì œì¡°ì—…ë³´ë‹¤ ê°•ì„¸ (+{gap:.1f}p)")
        else:
            print(f"  â†’ ë¹„ì œì¡°ì—…ì´ ì œì¡°ì—…ë³´ë‹¤ ê°•ì„¸ ({gap:.1f}p)")
    
    print()
    
    # 3. ê³µê¸‰ë§ ë° ì¸í”Œë ˆì´ì…˜ ì••ë ¥
    print("ğŸš› ê³µê¸‰ë§ ë° ê°€ê²© ë™í–¥:")
    supply_indicators = {
        'supdel_in': 'ì œì¡°ì—… ê³µê¸‰ì—…ì²´ ë°°ì†¡',
        'nm-supdel_in': 'ë¹„ì œì¡°ì—… ê³µê¸‰ì—…ì²´ ë°°ì†¡', 
        'prices_in': 'ì œì¡°ì—… ê°€ê²©',
        'nm-prices_in': 'ë¹„ì œì¡°ì—… ê°€ê²©'
    }
    
    for indicator, name in supply_indicators.items():
        if indicator in latest_raw.index:
            value = latest_raw[indicator]
            if 'supdel' in indicator:
                # ê³µê¸‰ì—…ì²´ ë°°ì†¡: ë†’ì„ìˆ˜ë¡ ë°°ì†¡ ì§€ì—° (ì¸í”Œë ˆì´ì…˜ ì••ë ¥)
                pressure = "ë†’ìŒ" if value > 50 else "ë‚®ìŒ"
                emoji = "ğŸ”´" if value > 55 else "ğŸŸ¡" if value > 45 else "ğŸŸ¢"
            else:
                # ê°€ê²©: ë†’ì„ìˆ˜ë¡ ê°€ê²© ìƒìŠ¹ ì••ë ¥
                pressure = "ë†’ìŒ" if value > 60 else "ë³´í†µ" if value > 40 else "ë‚®ìŒ"
                emoji = "ğŸ”´" if value > 60 else "ğŸŸ¡" if value > 40 else "ğŸŸ¢"
            
            print(f"  {emoji} {name}: {value:.1f} (ì••ë ¥ {pressure})")
    
    print()
    
    # 4. ê²½ì œ ì „ë§ ì¢…í•©
    print("ğŸ”® ê²½ì œ ì „ë§ ì¢…í•©:")
    
    # PMI ê¸°ë°˜ ê²½ê¸° íŒë‹¨
    if manu_pmi > 50 and services_pmi > 50:
        outlook = "ê²½ê¸° í™•ì¥ ì§€ì†"
        outlook_emoji = "ğŸŸ¢"
    elif manu_pmi > 50 or services_pmi > 50:
        outlook = "ê²½ê¸° í˜¼ì¡°, ì£¼ì˜ í•„ìš”"
        outlook_emoji = "ğŸŸ¡"
    else:
        outlook = "ê²½ê¸° ìˆ˜ì¶•, ê²½ê³„ í•„ìš”"
        outlook_emoji = "ğŸ”´"
    
    print(f"  {outlook_emoji} ê¸°ë³¸ ì‹œë‚˜ë¦¬ì˜¤: {outlook}")
    
    # ë¦¬ìŠ¤í¬ ìš”ì¸
    risks = []
    if latest_raw.get('prices_in', 0) > 60 or latest_raw.get('nm-prices_in', 0) > 60:
        risks.append("ì¸í”Œë ˆì´ì…˜ ì••ë ¥")
    if latest_raw.get('supdel_in', 0) > 55 or latest_raw.get('nm-supdel_in', 0) > 55:
        risks.append("ê³µê¸‰ë§ ë³‘ëª©")
    if latest_raw.get('employment_in', 0) < 45 or latest_raw.get('nm-employment_in', 0) < 45:
        risks.append("ê³ ìš© ë‘”í™”")
    
    if risks:
        print(f"  âš ï¸ ì£¼ìš” ë¦¬ìŠ¤í¬: {', '.join(risks)}")
    else:
        print(f"  âœ… ì£¼ìš” ë¦¬ìŠ¤í¬ ìš”ì¸ ì œí•œì ")
    
    print()
    print("="*50)
    print("ğŸ’¡ ë³¸ ë¶„ì„ì€ ISM PMI ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ê¸°ê³„ì  í•´ì„ì…ë‹ˆë‹¤.")
    print("   íˆ¬ì ê²°ì •ì‹œì—ëŠ” ì¶”ê°€ì ì¸ ê²½ì œì§€í‘œì™€ ì „ë¬¸ê°€ ë¶„ì„ì„ ì°¸ê³ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")

# %%
# === í†µí•© ë¶„ì„ í•¨ìˆ˜ ===

def run_complete_ism_analysis_enhanced(start_date='2020-01-01', force_reload=False, smart_update=True):
    """
    ì™„ì „í•œ ISM PMI ë¶„ì„ ì‹¤í–‰ - ë°ì´í„° ë¡œë“œ í›„ ëª¨ë“  ì°¨íŠ¸ ìƒì„± (ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì§€ì›)
    
    Args:
        start_date: ë°ì´í„° ì‹œì‘ ë‚ ì§œ
        force_reload: ê°•ì œ ì¬ë¡œë“œ ì—¬ë¶€
        smart_update: ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
    
    Returns:
        dict: ìƒì„±ëœ ì°¨íŠ¸ë“¤
    """
    print("ğŸš€ ì™„ì „í•œ ISM PMI ë¶„ì„ ì‹œì‘ (ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì§€ì›)")
    print("="*50)
    
    # 1. ë°ì´í„° ë¡œë“œ (ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸!)
    print("\n1ï¸âƒ£ ë°ì´í„° ë¡œë”© (ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸)")
    success = load_all_ism_data_enhanced(start_date=start_date, force_reload=force_reload, smart_update=smart_update)
    
    if not success:
        print("âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨")
        return None
    
    # 2. ê²½ì œ ëŒ€ì‹œë³´ë“œ ìƒì„±
    print("\n2ï¸âƒ£ ê²½ì œ ëŒ€ì‹œë³´ë“œ ìƒì„±")
    results = create_ism_economic_dashboard(start_date='2022-01-01')
    
    # 3. ê²½ì œ ë¶„ì„ ë¦¬í¬íŠ¸
    print("\n3ï¸âƒ£ ê²½ì œ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±")
    generate_ism_economic_report()
    
    return results

# %%
# === ì‚¬ìš© ì˜ˆì‹œ ===

print("\n" + "="*80)
print("ğŸ¯ ê¶Œì¥ ì‚¬ìš©ë²•:")
print("   ğŸ† run_complete_ism_analysis_enhanced(smart_update=True)  # ì´ê²ƒë§Œ ì‹¤í–‰í•˜ë©´ ë¨!")
print()
print("ğŸ“Š ê°œë³„ í•¨ìˆ˜ ì‚¬ìš©ë²•:")
print("1. ë°ì´í„° ë¡œë“œ (ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸):")
print("   load_all_ism_data_enhanced(smart_update=True)  # ê¸°ë³¸ê°’, ì¼ì¹˜ ì‹œ API ê±´ë„ˆë›°ê¸°")
print("   load_all_ism_data_enhanced(force_reload=True)  # ê°•ì œ ì „ì²´ ì¬ë¡œë“œ")
print("   load_ism_data_from_csv()  # CSVì—ì„œë§Œ ë¡œë“œ")
print("   update_ism_data_from_api_enhanced(smart_update=True)  # ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸")
print()
print("2. ğŸ’¾ ë°ì´í„° ì €ì¥:")
print("   save_ism_data_to_csv()  # í˜„ì¬ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥ (ìë™ í˜¸ì¶œë¨)")
print()
print("3. ğŸ¤– ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ê¸°ëŠ¥:")
print("   check_recent_data_consistency()  # ìµœê·¼ 3ê°œì›” ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸")
print("   print_consistency_results()  # ì¼ì¹˜ì„± ê²°ê³¼ ìƒì„¸ ì¶œë ¥")
print("   - í—ˆìš© ì˜¤ì°¨: 5.0ì  (PMI ì§€ìˆ˜ ê¸°ì¤€)")
print("   - CSV ë°ì´í„°ì™€ API ë°ì´í„° ë¹„êµ")
print("   - ë¶ˆì¼ì¹˜ ì‹œì—ë§Œ ì „ì²´ API í˜¸ì¶œ")
print()
print("4. ğŸ“ˆ ì°¨íŠ¸ ìƒì„±:")
print("   create_ism_timeseries_chart(['pmi_pm', 'nm-pmi_pm'], 'diffusion')  # í™•ì‚°ì§€ìˆ˜")
print("   create_ism_timeseries_chart(['pmi_pm', 'nm-pmi_pm'], 'raw')  # ì›ë³¸ ë ˆë²¨")
print("   create_ism_horizontal_bar_chart('diffusion')  # í™•ì‚°ì§€ìˆ˜")
print("   create_ism_mom_bar_chart('both')  # MoM ë³€í™”ìœ¨ (ì œì¡°ì—… vs ë¹„ì œì¡°ì—…)")
print("   create_ism_mom_bar_chart('manufacturing')  # ì œì¡°ì—… MoM ë¶„ì„")
print("   create_ism_mom_bar_chart('services')  # ë¹„ì œì¡°ì—… MoM ë¶„ì„")
print("   create_manufacturing_vs_services_chart('raw')  # ì„¹í„° ë¹„êµ")
print()
print("5. ğŸ¯ í†µí•© ë¶„ì„:")
print("   run_complete_ism_analysis_enhanced(smart_update=True)  # ì „ì²´ ë¶„ì„ (ê¸°ë³¸ê°’)")
print("   create_ism_economic_dashboard()  # ê²½ì œ ëŒ€ì‹œë³´ë“œ")
print("   generate_ism_economic_report()  # ê²½ì œ ë¶„ì„ ë¦¬í¬íŠ¸")
print("="*80)

# %%
run_complete_ism_analysis_enhanced(smart_update=True)

# %%
create_ism_mom_bar_chart('services')
# %%
create_ism_mom_bar_chart('manufacturing')
# %%
create_ism_timeseries_chart(['pmi_pm', 'nm-pmi_pm'], 'raw')  # ì›ë³¸ ë ˆë²¨")
# %%
