# %%
"""
BLS API ì „ìš© Import Prices ë¶„ì„ ë° ì‹œê°í™” ë„êµ¬
- BLS APIë§Œ ì‚¬ìš©í•˜ì—¬ Import Prices ë°ì´í„° ìˆ˜ì§‘
- CSV ì €ì¥/ë¡œë“œ ë° ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸
- YoY/MoM ê¸°ì¤€ ì‹œê°í™” ì§€ì›
"""
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import sys
import warnings
warnings.filterwarnings('ignore')

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    import requests
    import json
    BLS_API_AVAILABLE = True
    print("âœ“ BLS API ì—°ë™ ê°€ëŠ¥ (requests ë¼ì´ë¸ŒëŸ¬ë¦¬)")
except ImportError:
    print("âš ï¸ requests ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜í•˜ì„¸ìš”: pip install requests")
    BLS_API_AVAILABLE = False

# BLS API í‚¤ ì„¤ì • (PPIì™€ ë™ì¼)
BLS_API_KEY = '56b193612b614cdc9416359fd1c73a74'
BLS_API_KEY2 = '0450ef37363c48b5bedd2ae6fc92dd6e'
BLS_API_KEY3 = 'daf1ca7970b74e81b6a5c7a80a8b8a7f'
CURRENT_API_KEY = BLS_API_KEY

# ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
sys.path.append('/home/jyp0615')
from kpds_fig_format_enhanced import *

# %%
# === Import Prices ì‹œë¦¬ì¦ˆ IDì™€ ì´ë¦„ ë§¤í•‘ ===

# Import Prices ì‹œë¦¬ì¦ˆ IDì™€ ì˜ì–´ ì´ë¦„ ë§¤í•‘
IMPORT_SERIES = {
    'EIUIR': 'Imports - All Commodities',
    'EIUIR10': 'Imports - Fuels and Lubricants',
    'EIUIREXFUELS': 'All Imports Excluding Fuels',
    'EIUIR0': 'Imports - Foods, Feeds, and Beverages',
    'EIUIR1': 'Imports - Industrial Supplies and Materials',
    'EIUIR2': 'Imports - Capital Goods',
    'EIUIR3': 'Imports - Automotive Vehicles',
    'EIUIR4': 'Imports - Consumer Goods',
    'EIUIV131': 'Import Air Freight'
}

# í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘
IMPORT_KOREAN_NAMES = {
    'EIUIR': 'ìˆ˜ì…í’ˆ - ì „ì²´',
    'EIUIR10': 'ìˆ˜ì…í’ˆ - ì—°ë£Œ ë° ìœ¤í™œìœ ',
    'EIUIREXFUELS': 'ìˆ˜ì…í’ˆ - ì—°ë£Œ ì œì™¸ ì „ì²´',
    'EIUIR0': 'ìˆ˜ì…í’ˆ - ì‹í’ˆ, ì‚¬ë£Œ ë° ìŒë£Œ',
    'EIUIR1': 'ìˆ˜ì…í’ˆ - ì‚°ì—…ìš© ì›ìì¬',
    'EIUIR2': 'ìˆ˜ì…í’ˆ - ìë³¸ì¬',
    'EIUIR3': 'ìˆ˜ì…í’ˆ - ìë™ì°¨',
    'EIUIR4': 'ìˆ˜ì…í’ˆ - ì†Œë¹„ì¬',
    'EIUIV131': 'ìˆ˜ì… í•­ê³µ í™”ë¬¼'
}

# Import Prices ê³„ì¸µ êµ¬ì¡°
IMPORT_HIERARCHY = {
    'ì£¼ìš” ì§€í‘œ': {
        'Total': ['EIUIR', 'EIUIREXFUELS'],
        'Energy': ['EIUIR10']
    },
    'ì„¸ë¶€ í’ˆëª©': {
        'Consumer': ['EIUIR0', 'EIUIR4'],
        'Industrial': ['EIUIR1', 'EIUIR2'],
        'Transportation': ['EIUIR3', 'EIUIV131']
    }
}

# %%
# === ì „ì—­ ë°ì´í„° ì €ì¥ì†Œ ===

# API ì„¤ì •
BLS_SESSION = None
API_INITIALIZED = False

# ì „ì—­ ë°ì´í„° ì €ì¥ì†Œ
IMPORT_DATA = {
    'raw_data': pd.DataFrame(),      # ì›ë³¸ ë ˆë²¨ ë°ì´í„°
    'yoy_data': pd.DataFrame(),      # ì „ë…„ë™ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ë°ì´í„°
    'mom_data': pd.DataFrame(),      # ì „ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ë°ì´í„°
    'latest_values': {},             # ìµœì‹  YoY ê°’ë“¤
    'load_info': {
        'loaded': False,
        'load_time': None,
        'start_date': None,
        'series_count': 0,
        'data_points': 0
    }
}

# %%
# === API ì´ˆê¸°í™” í•¨ìˆ˜ ===

def initialize_bls_api():
    """BLS API ì„¸ì…˜ ì´ˆê¸°í™”"""
    global BLS_SESSION
    
    if not BLS_API_AVAILABLE:
        print("âš ï¸ BLS API ì‚¬ìš© ë¶ˆê°€ (requests ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ)")
        return False
    
    try:
        BLS_SESSION = requests.Session()
        print("âœ“ BLS API ì„¸ì…˜ ì´ˆê¸°í™” ì„±ê³µ")
        return True
    except Exception as e:
        print(f"âš ï¸ BLS API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def switch_api_key():
    """API í‚¤ë¥¼ ì „í™˜í•˜ëŠ” í•¨ìˆ˜"""
    global CURRENT_API_KEY
    if CURRENT_API_KEY == BLS_API_KEY:
        CURRENT_API_KEY = BLS_API_KEY2
        print("ğŸ”„ BLS API í‚¤ë¥¼ BLS_API_KEY2ë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.")
    elif CURRENT_API_KEY == BLS_API_KEY2:
        CURRENT_API_KEY = BLS_API_KEY3
        print("ğŸ”„ BLS API í‚¤ë¥¼ BLS_API_KEY3ë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.")
    else:
        CURRENT_API_KEY = BLS_API_KEY
        print("ğŸ”„ BLS API í‚¤ë¥¼ BLS_API_KEYë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.")

def get_bls_data(series_id, start_year=2020, end_year=None):
    """
    BLS APIì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (API í‚¤ ì´ì¤‘í™” ì§€ì›)
    
    Args:
        series_id: BLS ì‹œë¦¬ì¦ˆ ID
        start_year: ì‹œì‘ ì—°ë„
        end_year: ì¢…ë£Œ ì—°ë„ (Noneì´ë©´ í˜„ì¬ ì—°ë„)
    
    Returns:
        pandas.Series: ë‚ ì§œë¥¼ ì¸ë±ìŠ¤ë¡œ í•˜ëŠ” ì‹œë¦¬ì¦ˆ ë°ì´í„°
    """
    global CURRENT_API_KEY
    
    if not BLS_API_AVAILABLE or BLS_SESSION is None:
        print(f"âŒ BLS API ì‚¬ìš© ë¶ˆê°€ - {series_id}")
        return None
    
    if end_year is None:
        end_year = datetime.datetime.now().year
    
    # BLS API ìš”ì²­ ë°ì´í„°
    data = {
        'seriesid': [series_id],
        'startyear': str(start_year),
        'endyear': str(end_year),
        'catalog': False,
        'calculations': False,
        'annualaverage': False
    }
    
    # í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ API í‚¤ ì¶”ê°€
    if CURRENT_API_KEY:
        data['registrationkey'] = CURRENT_API_KEY
    
    url = 'https://api.bls.gov/publicAPI/v2/timeseries/data/'
    headers = {'Content-type': 'application/json'}
    
    try:
        current_key_name = "ì£¼ìš”" if CURRENT_API_KEY == BLS_API_KEY else "ë°±ì—…"
        print(f"ğŸ“Š BLSì—ì„œ ë¡œë”© ({current_key_name}): {series_id}")
        response = BLS_SESSION.post(url, data=json.dumps(data), headers=headers, timeout=30)
        response.raise_for_status()
        
        json_data = response.json()
        
        if json_data.get('status') == 'REQUEST_SUCCEEDED':
            series_data = json_data['Results']['series'][0]['data']
            
            # ë°ì´í„° ì •ë¦¬
            dates = []
            values = []
            
            for item in series_data:
                try:
                    year = int(item['year'])
                    period = item['period']
                    if period.startswith('M'):
                        month = int(period[1:])
                        date = pd.Timestamp(year, month, 1)
                        value = float(item['value'])
                        
                        dates.append(date)
                        values.append(value)
                except (ValueError, KeyError):
                    continue
            
            if dates and values:
                # ë‚ ì§œìˆœ ì •ë ¬
                df = pd.DataFrame({'date': dates, 'value': values})
                df = df.sort_values('date')
                series = pd.Series(df['value'].values, index=df['date'], name=series_id)
                
                print(f"âœ“ BLS ì„±ê³µ: {series_id} ({len(series)}ê°œ í¬ì¸íŠ¸)")
                return series
            else:
                print(f"âŒ BLS ë°ì´í„° ì—†ìŒ: {series_id}")
                return None
        else:
            error_msg = json_data.get('message', 'Unknown error')
            print(f"âš ï¸ BLS API ì˜¤ë¥˜: {error_msg}")
            
            # Daily threshold ì´ˆê³¼ì¸ ê²½ìš° API í‚¤ ì „í™˜ ì‹œë„
            if 'daily threshold' in error_msg.lower() or 'daily quota' in error_msg.lower():
                print("ğŸ“ˆ Daily threshold ì´ˆê³¼ ê°ì§€ - API í‚¤ ì „í™˜ ì‹œë„")
                switch_api_key()
                
                # ìƒˆë¡œìš´ API í‚¤ë¡œ ì¬ì‹œë„
                data['registrationkey'] = CURRENT_API_KEY
                try:
                    print(f"ğŸ”„ ìƒˆ API í‚¤ë¡œ ì¬ì‹œë„: {series_id}")
                    response = BLS_SESSION.post(url, data=json.dumps(data), headers=headers, timeout=30)
                    response.raise_for_status()
                    
                    json_data = response.json()
                    if json_data.get('status') == 'REQUEST_SUCCEEDED':
                        series_data = json_data['Results']['series'][0]['data']
                        
                        dates = []
                        values = []
                        
                        for item in series_data:
                            try:
                                year = int(item['year'])
                                period = item['period']
                                if period.startswith('M'):
                                    month = int(period[1:])
                                    date = pd.Timestamp(year, month, 1)
                                    value = float(item['value'])
                                    
                                    dates.append(date)
                                    values.append(value)
                            except (ValueError, KeyError):
                                continue
                        
                        if dates and values:
                            df = pd.DataFrame({'date': dates, 'value': values})
                            df = df.sort_values('date')
                            series = pd.Series(df['value'].values, index=df['date'], name=series_id)
                            
                            print(f"âœ… ë°±ì—… API í‚¤ë¡œ ì„±ê³µ: {series_id} ({len(series)}ê°œ í¬ì¸íŠ¸)")
                            return series
                    
                    print(f"âŒ ë°±ì—… API í‚¤ë¡œë„ ì‹¤íŒ¨: {series_id}")
                    return None
                except Exception as e:
                    print(f"âŒ ë°±ì—… API í‚¤ ìš”ì²­ ì‹¤íŒ¨: {series_id} - {e}")
                    return None
            else:
                return None
            
    except Exception as e:
        print(f"âŒ BLS ìš”ì²­ ì‹¤íŒ¨: {series_id} - {e}")
        return None

# %%
# === ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ë“¤ ===

def get_series_data(series_id, start_date='2020-01-01', end_date=None, min_points=12, is_update=False):
    """BLS APIë¥¼ ì‚¬ìš©í•œ ê°œë³„ ì‹œë¦¬ì¦ˆ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    if not BLS_SESSION:
        print(f"âŒ BLS ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ: {series_id}")
        return None
    
    try:
        start_year = pd.to_datetime(start_date).year
        end_year = pd.to_datetime(end_date).year if end_date else None
        data = get_bls_data(series_id, start_year, end_year)
        
        if data is None or len(data) == 0:
            print(f"âŒ ë°ì´í„° ì—†ìŒ: {series_id}")
            return None
        
        # ë‚ ì§œ í•„í„°ë§
        if start_date:
            data = data[data.index >= start_date]
        if end_date:
            data = data[data.index <= end_date]
        
        # NaN ì œê±°
        data = data.dropna()
        
        # ì—…ë°ì´íŠ¸ ëª¨ë“œì¼ ë•ŒëŠ” ìµœì†Œ ë°ì´í„° í¬ì¸íŠ¸ ìš”êµ¬ëŸ‰ì„ ë‚®ì¶¤
        if is_update:
            min_required = 1  # ì—…ë°ì´íŠ¸ ì‹œì—ëŠ” 1ê°œ í¬ì¸íŠ¸ë§Œ ìˆì–´ë„ í—ˆìš©
        else:
            min_required = min_points
        
        if len(data) < min_required:
            print(f"âŒ ë°ì´í„° ë¶€ì¡±: {series_id} ({len(data)}ê°œ)")
            return None
        
        print(f"âœ“ ì„±ê³µ: {series_id} ({len(data)}ê°œ í¬ì¸íŠ¸)")
        return data
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {series_id} - {e}")
        return None

def calculate_yoy_change(data):
    """ì „ë…„ë™ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ê³„ì‚°"""
    return ((data / data.shift(12)) - 1) * 100

def calculate_mom_change(data):
    """ì „ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ê³„ì‚°"""
    return ((data / data.shift(1)) - 1) * 100

# %%
# === CSV ì €ì¥/ë¡œë“œ í•¨ìˆ˜ë“¤ ===

def save_import_data_to_csv(file_path='/home/jyp0615/us_eco/import_prices_data.csv'):
    """
    í˜„ì¬ ë¡œë“œëœ Import Prices ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
    
    Args:
        file_path: ì €ì¥í•  CSV íŒŒì¼ ê²½ë¡œ
    """
    if not IMPORT_DATA['load_info']['loaded']:
        print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return False
    
    try:
        # raw_dataì™€ ë©”íƒ€ë°ì´í„°ë¥¼ í•¨ê»˜ ì €ì¥
        raw_data = IMPORT_DATA['raw_data']
        
        # ì €ì¥í•  ë°ì´í„° ì¤€ë¹„
        save_data = {
            'timestamp': raw_data.index.tolist(),
            **{col: raw_data[col].tolist() for col in raw_data.columns}
        }
        
        # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
        save_df = pd.DataFrame(save_data)
        save_df.to_csv(file_path, index=False, encoding='utf-8')
        
        # ë©”íƒ€ë°ì´í„°ë„ ë³„ë„ ì €ì¥
        meta_file = file_path.replace('.csv', '_meta.json')
        import json
        with open(meta_file, 'w', encoding='utf-8') as f:
            meta_data = {
                'load_time': IMPORT_DATA['load_info']['load_time'].isoformat() if IMPORT_DATA['load_info']['load_time'] else None,
                'start_date': IMPORT_DATA['load_info']['start_date'],
                'series_count': IMPORT_DATA['load_info']['series_count'],
                'data_points': IMPORT_DATA['load_info']['data_points'],
                'latest_values': IMPORT_DATA['latest_values']
            }
            json.dump(meta_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… Import Prices ë°ì´í„° ì €ì¥ ì™„ë£Œ: {file_path}")
        print(f"âœ… ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {meta_file}")
        return True
        
    except Exception as e:
        print(f"âŒ CSV ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def load_import_data_from_csv(file_path='/home/jyp0615/us_eco/import_prices_data.csv'):
    """
    CSV íŒŒì¼ì—ì„œ Import Prices ë°ì´í„° ë¡œë“œ
    
    Args:
        file_path: ë¡œë“œí•  CSV íŒŒì¼ ê²½ë¡œ
    
    Returns:
        bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
    """
    global IMPORT_DATA
    
    import os
    if not os.path.exists(file_path):
        print(f"âš ï¸ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return False
    
    try:
        # CSV ë°ì´í„° ë¡œë“œ
        df = pd.read_csv(file_path, encoding='utf-8')
        
        # timestamp ì»¬ëŸ¼ì„ ë‚ ì§œ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df.set_index('timestamp', inplace=True)
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        meta_file = file_path.replace('.csv', '_meta.json')
        latest_values = {}
        if os.path.exists(meta_file):
            import json
            with open(meta_file, 'r', encoding='utf-8') as f:
                meta_data = json.load(f)
                latest_values = meta_data.get('latest_values', {})
        
        # ì „ì—­ ì €ì¥ì†Œì— ì €ì¥
        IMPORT_DATA['raw_data'] = df
        IMPORT_DATA['yoy_data'] = df.apply(calculate_yoy_change)
        IMPORT_DATA['mom_data'] = df.apply(calculate_mom_change)
        IMPORT_DATA['latest_values'] = latest_values
        IMPORT_DATA['load_info'] = {
            'loaded': True,
            'load_time': datetime.datetime.now(),
            'start_date': df.index[0].strftime('%Y-%m-%d') if len(df) > 0 else None,
            'series_count': len(df.columns),
            'data_points': len(df)
        }
        
        print(f"âœ… CSVì—ì„œ Import Prices ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {file_path}")
        print_load_info()
        return True
        
    except Exception as e:
        print(f"âŒ CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

def check_recent_data_consistency(series_list=None, check_count=3):
    """
    ìµœê·¼ Nê°œ ë°ì´í„°ì˜ ì¼ì¹˜ì„±ì„ í™•ì¸í•˜ëŠ” í•¨ìˆ˜ (ê°œì„ ëœ ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸)
    
    Args:
        series_list: í™•ì¸í•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ì£¼ìš” ì‹œë¦¬ì¦ˆë§Œ)
        check_count: í™•ì¸í•  ìµœê·¼ ë°ì´í„° ê°œìˆ˜
    
    Returns:
        dict: ì¼ì¹˜ì„± í™•ì¸ ê²°ê³¼ (need_update, reason, mismatches)
    """
    if not IMPORT_DATA['load_info']['loaded']:
        return {'need_update': True, 'reason': 'ê¸°ì¡´ ë°ì´í„° ì—†ìŒ'}
    
    if series_list is None:
        # ì£¼ìš” ì‹œë¦¬ì¦ˆë§Œ ì²´í¬ (ì†ë„ í–¥ìƒ)
        series_list = ['EIUIR', 'EIUIREXFUELS', 'EIUIR10']
    
    # BLS API ì´ˆê¸°í™”
    if not initialize_bls_api():
        return {'need_update': True, 'reason': 'API ì´ˆê¸°í™” ì‹¤íŒ¨'}
    
    print(f"ğŸ“Š ìµœê·¼ {check_count}ê°œ ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸ ì¤‘...")
    
    mismatches = []
    new_data_available = False
    all_data_identical = True
    
    for series_id in series_list:
        if series_id not in IMPORT_DATA['raw_data'].columns:
            continue
        
        existing_data = IMPORT_DATA['raw_data'][series_id].dropna()
        if len(existing_data) == 0:
            continue
        
        # ìµœê·¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        current_year = datetime.datetime.now().year
        api_data = get_bls_data(series_id, current_year - 1, current_year)
        
        if api_data is None or len(api_data) == 0:
            mismatches.append({
                'series': series_id,
                'reason': 'API ë°ì´í„° ì—†ìŒ'
            })
            all_data_identical = False
            continue
        
        # ë¨¼ì € ìƒˆë¡œìš´ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        latest_existing = existing_data.index[-1]
        latest_api = api_data.index[-1]
        
        if latest_api > latest_existing:
            new_data_available = True
            mismatches.append({
                'series': series_id,
                'reason': 'ìƒˆë¡œìš´ ë°ì´í„° ì¡´ì¬',
                'existing_latest': latest_existing,
                'api_latest': latest_api
            })
            all_data_identical = False
            continue  # ìƒˆ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë‹¤ë¥¸ ì²´í¬ëŠ” ê±´ë„ˆëœ€
        
        # ìµœê·¼ Nê°œ ë°ì´í„° ë¹„êµ (ìƒˆ ë°ì´í„°ê°€ ì—†ì„ ë•Œë§Œ)
        existing_recent = existing_data.tail(check_count)
        api_recent = api_data.tail(check_count)
        
        # ë‚ ì§œì™€ ê°’ ëª¨ë‘ ë¹„êµ
        for date in existing_recent.index[-check_count:]:
            if date in api_recent.index:
                existing_val = existing_recent.loc[date]
                api_val = api_recent.loc[date]
                
                # ê°’ì´ ë‹¤ë¥´ë©´ ë¶ˆì¼ì¹˜
                if abs(existing_val - api_val) > 0.01:  # 0.01 ì´ìƒ ì°¨ì´
                    mismatches.append({
                        'series': series_id,
                        'date': date,
                        'existing': existing_val,
                        'api': api_val,
                        'diff': abs(existing_val - api_val)
                    })
                    all_data_identical = False
            else:
                mismatches.append({
                    'series': series_id,
                    'date': date,
                    'existing': existing_recent.loc[date],
                    'api': None,
                    'reason': 'ë‚ ì§œ ì—†ìŒ'
                })
                all_data_identical = False
    
    # ê²°ê³¼ íŒì • ë¡œì§ ê°œì„ 
    if new_data_available:
        print(f"ğŸ†• ìƒˆë¡œìš´ ë°ì´í„° ê°ì§€: ì—…ë°ì´íŠ¸ í•„ìš”")
        for mismatch in mismatches[:3]:
            if 'reason' in mismatch and mismatch['reason'] == 'ìƒˆë¡œìš´ ë°ì´í„° ì¡´ì¬':
                print(f"   - {mismatch['series']}: {mismatch['existing_latest']} â†’ {mismatch['api_latest']}")
        return {'need_update': True, 'reason': 'ìƒˆë¡œìš´ ë°ì´í„°', 'mismatches': mismatches}
    elif not all_data_identical:
        # ê°’ ë¶ˆì¼ì¹˜ê°€ ìˆëŠ” ê²½ìš°
        value_mismatches = [m for m in mismatches if m.get('reason') != 'ìƒˆë¡œìš´ ë°ì´í„° ì¡´ì¬']
        print(f"âš ï¸ ë°ì´í„° ë¶ˆì¼ì¹˜ ë°œê²¬: {len(value_mismatches)}ê°œ")
        for mismatch in value_mismatches[:3]:
            print(f"   - {mismatch}")
        return {'need_update': True, 'reason': 'ë°ì´í„° ë¶ˆì¼ì¹˜', 'mismatches': mismatches}
    else:
        print("âœ… ìµœê·¼ ë°ì´í„°ê°€ ì™„ì „íˆ ì¼ì¹˜í•©ë‹ˆë‹¤. ì—…ë°ì´íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return {'need_update': False, 'reason': 'ë°ì´í„° ì¼ì¹˜', 'mismatches': []}

def update_import_data_from_api(start_date=None, series_list=None, smart_update=True):
    """
    APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸ (ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì§€ì›)
    
    Args:
        start_date: ì—…ë°ì´íŠ¸ ì‹œì‘ ë‚ ì§œ (Noneì´ë©´ ë§ˆì§€ë§‰ ë°ì´í„° ì´í›„ë¶€í„°)
        series_list: ì—…ë°ì´íŠ¸í•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  ì‹œë¦¬ì¦ˆ)
        smart_update: ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì‚¬ìš© ì—¬ë¶€ (ìµœê·¼ 3ê°œ ë°ì´í„° ë¹„êµ)
    
    Returns:
        bool: ì—…ë°ì´íŠ¸ ì„±ê³µ ì—¬ë¶€
    """
    global IMPORT_DATA
    
    if not IMPORT_DATA['load_info']['loaded']:
        print("âš ï¸ ê¸°ì¡´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ë¡œë“œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
        return load_all_import_data()
    
    # ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ í™œì„±í™”ì‹œ ìµœê·¼ ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸
    if smart_update:
        consistency_check = check_recent_data_consistency()
        
        # ì—…ë°ì´íŠ¸ í•„ìš” ì—†ìœ¼ë©´ ë°”ë¡œ ì¢…ë£Œ
        if not consistency_check['need_update']:
            print("ğŸ¯ ë°ì´í„°ê°€ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤. API í˜¸ì¶œì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return True
        
        # ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•œ ê²½ìš° ì²˜ë¦¬
        if consistency_check['reason'] == 'ë°ì´í„° ë¶ˆì¼ì¹˜':
            print("âš ï¸ ìµœê·¼ 3ê°œ ë°ì´í„° ë¶ˆì¼ì¹˜ë¡œ ì¸í•œ ì „ì²´ ì¬ë¡œë“œ")
            # ìµœê·¼ 3ê°œì›” ë°ì´í„°ë¶€í„° ë‹¤ì‹œ ë¡œë“œ
            last_date = IMPORT_DATA['raw_data'].index[-1]
            start_date = (last_date - pd.DateOffset(months=3)).strftime('%Y-%m-01')
        elif consistency_check['reason'] == 'ê¸°ì¡´ ë°ì´í„° ì—†ìŒ':
            # ì „ì²´ ì¬ë¡œë“œ
            return load_all_import_data(force_reload=True)
        else:
            print(f"ğŸ”„ ì—…ë°ì´íŠ¸ ì§„í–‰: {consistency_check['reason']}")
    
    # BLS API ì´ˆê¸°í™”
    if not initialize_bls_api():
        print("âŒ BLS API ì´ˆê¸°í™” ì‹¤íŒ¨")
        return False
    
    # ì—…ë°ì´íŠ¸ ì‹œì‘ ë‚ ì§œ ê²°ì •
    if start_date is None:
        last_date = IMPORT_DATA['raw_data'].index[-1]
        # ë§ˆì§€ë§‰ ë‚ ì§œì˜ ë‹¤ìŒ ë‹¬ë¶€í„° ì—…ë°ì´íŠ¸
        start_date = (last_date + pd.DateOffset(months=1)).strftime('%Y-%m-01')
    
    print(f"ğŸ”„ Import Prices ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ ({start_date}ë¶€í„°)")
    print("="*50)
    
    if series_list is None:
        series_list = list(IMPORT_SERIES.keys())
    
    updated_data = {}
    new_count = 0
    
    for series_id in series_list:
        if series_id not in IMPORT_SERIES:
            continue
        
        # ìƒˆë¡œìš´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        start_year = pd.to_datetime(start_date).year
        new_data = get_bls_data(series_id, start_year)
        
        if new_data is not None and len(new_data) > 0:
            # ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©
            if series_id in IMPORT_DATA['raw_data'].columns:
                existing_data = IMPORT_DATA['raw_data'][series_id]
                original_count = existing_data.notna().sum()
                
                # ê°œì„ ëœ ë³‘í•© ë°©ì‹: ì¸ë±ìŠ¤ ë¨¼ì € í™•ì¥ í›„ ê°’ í• ë‹¹
                all_dates = existing_data.index.union(new_data.index).sort_values()
                combined_data = existing_data.reindex(all_dates)
                
                # ìƒˆ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ê°’ ë®ì–´ì“°ê¸°)
                for date, value in new_data.items():
                    combined_data.loc[date] = value
                
                updated_data[series_id] = combined_data
                
                # ì‹¤ì œ ì¶”ê°€ëœ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ ê³„ì‚°
                final_count = combined_data.notna().sum()
                new_points = final_count - original_count
                new_count += new_points
                
                if new_points > 0:
                    print(f"âœ… ì—…ë°ì´íŠ¸: {series_id} (ê¸°ì¡´ {original_count}ê°œ + ì‹ ê·œ {len(new_data)}ê°œ â†’ ì´ {final_count}ê°œ, ì‹¤ì œ ì¶”ê°€: {new_points}ê°œ)")
                else:
                    print(f"â„¹ï¸  ìµœì‹  ìƒíƒœ: {series_id}")
            else:
                updated_data[series_id] = new_data
                new_count += len(new_data)
                print(f"âœ… ì‹ ê·œ ì¶”ê°€: {series_id} ({len(new_data)}ê°œ í¬ì¸íŠ¸)")
    
    if updated_data:
        # ì „ì—­ ì €ì¥ì†Œ ì—…ë°ì´íŠ¸
        updated_df = pd.DataFrame(updated_data)
        IMPORT_DATA['raw_data'] = updated_df
        IMPORT_DATA['yoy_data'] = updated_df.apply(calculate_yoy_change)
        IMPORT_DATA['mom_data'] = updated_df.apply(calculate_mom_change)
        
        # ìµœì‹  ê°’ ì—…ë°ì´íŠ¸
        for series_id in updated_data.keys():
            if series_id in IMPORT_DATA['yoy_data'].columns:
                yoy_data = IMPORT_DATA['yoy_data'][series_id].dropna()
                if len(yoy_data) > 0:
                    IMPORT_DATA['latest_values'][series_id] = yoy_data.iloc[-1]
        
        # ë¡œë“œ ì •ë³´ ì—…ë°ì´íŠ¸
        IMPORT_DATA['load_info']['load_time'] = datetime.datetime.now()
        IMPORT_DATA['load_info']['series_count'] = len(updated_df.columns)
        IMPORT_DATA['load_info']['data_points'] = len(updated_df)
        
        print(f"\nâœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ! ìƒˆë¡œ ì¶”ê°€ëœ ë°ì´í„°: {new_count}ê°œ í¬ì¸íŠ¸")
        print_load_info()
        
        # ìë™ìœ¼ë¡œ CSVì— ì €ì¥
        save_import_data_to_csv()
        
        return True
    else:
        print("\nâš ï¸ ì—…ë°ì´íŠ¸í•  ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False

# === ë©”ì¸ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ===

def load_all_import_data(start_date='2020-01-01', series_list=None, force_reload=False, csv_file='/home/jyp0615/us_eco/import_prices_data.csv'):
    """
    Import Prices ë°ì´í„° ë¡œë“œ (CSV ìš°ì„ , API ë°±ì—… ë°©ì‹)
    
    Args:
        start_date: ì‹œì‘ ë‚ ì§œ
        series_list: ë¡œë“œí•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  ì‹œë¦¬ì¦ˆ)
        force_reload: ê°•ì œ ì¬ë¡œë“œ ì—¬ë¶€
        csv_file: CSV íŒŒì¼ ê²½ë¡œ
    
    Returns:
        bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
    """
    global IMPORT_DATA
    
    # ì´ë¯¸ ë¡œë“œëœ ê²½ìš° ìŠ¤í‚µ
    if IMPORT_DATA['load_info']['loaded'] and not force_reload:
        print("ğŸ’¾ ì´ë¯¸ ë¡œë“œëœ ë°ì´í„° ì‚¬ìš© ì¤‘")
        print_load_info()
        return True
    
    # CSV íŒŒì¼ì´ ìˆìœ¼ë©´ ìš°ì„  ë¡œë“œ ì‹œë„
    import os
    if not force_reload and os.path.exists(csv_file):
        print("ğŸ“‚ ê¸°ì¡´ CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ ì‹œë„...")
        if load_import_data_from_csv(csv_file):
            print("ğŸ”„ CSV ë¡œë“œ í›„ ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì‹œë„...")
            # CSV ë¡œë“œ ì„±ê³µ í›„ ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸
            update_import_data_from_api(smart_update=True)
            return True
        else:
            print("âš ï¸ CSV ë¡œë“œ ì‹¤íŒ¨, APIì—ì„œ ì „ì²´ ë¡œë“œ ì‹œë„...")
    
    print("ğŸš€ Import Prices ë°ì´í„° ë¡œë”© ì‹œì‘... (BLS API ì „ìš©)")
    print("="*50)
    
    # BLS API ì´ˆê¸°í™”
    if not initialize_bls_api():
        print("âŒ BLS API ì´ˆê¸°í™” ì‹¤íŒ¨")
        return False
    
    if series_list is None:
        series_list = list(IMPORT_SERIES.keys())
    
    # ë°ì´í„° ìˆ˜ì§‘
    raw_data_dict = {}
    yoy_data_dict = {}
    mom_data_dict = {}
    latest_values = {}
    
    for series_id in series_list:
        if series_id not in IMPORT_SERIES:
            print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì‹œë¦¬ì¦ˆ: {series_id}")
            continue
        
        # ì›ë³¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        series_data = get_series_data(series_id, start_date)
        
        if series_data is not None and len(series_data) > 0:
            # ì›ë³¸ ë°ì´í„° ì €ì¥
            raw_data_dict[series_id] = series_data
            
            # YoY ê³„ì‚°
            yoy_data = calculate_yoy_change(series_data)
            yoy_data_dict[series_id] = yoy_data
            
            # MoM ê³„ì‚°
            mom_data = calculate_mom_change(series_data)
            mom_data_dict[series_id] = mom_data
            
            # ìµœì‹  ê°’ ì €ì¥
            if len(yoy_data.dropna()) > 0:
                latest_yoy = yoy_data.dropna().iloc[-1]
                latest_values[series_id] = latest_yoy
            else:
                print(f"âš ï¸ YoY ë°ì´í„° ì—†ìŒ: {series_id}")
        else:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {series_id}")
    
    # ë¡œë“œëœ ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì˜¤ë¥˜ ë°œìƒ
    if len(raw_data_dict) < 3:  # ìµœì†Œ 3ê°œ ì‹œë¦¬ì¦ˆëŠ” ìˆì–´ì•¼ í•¨
        error_msg = f"âŒ ë¡œë“œëœ ì‹œë¦¬ì¦ˆê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤: {len(raw_data_dict)}ê°œ (ìµœì†Œ 3ê°œ í•„ìš”)"
        print(error_msg)
        raise ValueError(error_msg)
    
    # ì „ì—­ ì €ì¥ì†Œì— ì €ì¥
    IMPORT_DATA['raw_data'] = pd.DataFrame(raw_data_dict)
    IMPORT_DATA['yoy_data'] = pd.DataFrame(yoy_data_dict)
    IMPORT_DATA['mom_data'] = pd.DataFrame(mom_data_dict)
    IMPORT_DATA['latest_values'] = latest_values
    IMPORT_DATA['load_info'] = {
        'loaded': True,
        'load_time': datetime.datetime.now(),
        'start_date': start_date,
        'series_count': len(raw_data_dict),
        'data_points': len(IMPORT_DATA['raw_data']) if not IMPORT_DATA['raw_data'].empty else 0
    }
    
    print("\nâœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
    print_load_info()
    
    # ìë™ìœ¼ë¡œ CSVì— ì €ì¥
    save_import_data_to_csv(csv_file)
    
    return True

def print_load_info():
    """ë¡œë“œ ì •ë³´ ì¶œë ¥"""
    info = IMPORT_DATA['load_info']
    if not info['loaded']:
        print("âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ")
        return
    
    print(f"ğŸ“Š ë¡œë“œëœ ë°ì´í„° ì •ë³´:")
    print(f"   ì‹œë¦¬ì¦ˆ ê°œìˆ˜: {info['series_count']}")
    print(f"   ë°ì´í„° í¬ì¸íŠ¸: {info['data_points']}")
    print(f"   ì‹œì‘ ë‚ ì§œ: {info['start_date']}")
    print(f"   ë¡œë“œ ì‹œê°„: {info['load_time'].strftime('%Y-%m-%d %H:%M:%S')}")
    
    if not IMPORT_DATA['raw_data'].empty:
        date_range = f"{IMPORT_DATA['raw_data'].index[0].strftime('%Y-%m')} ~ {IMPORT_DATA['raw_data'].index[-1].strftime('%Y-%m')}"
        print(f"   ë°ì´í„° ê¸°ê°„: {date_range}")

def clear_data():
    """ë°ì´í„° ì´ˆê¸°í™”"""
    global IMPORT_DATA
    IMPORT_DATA = {
        'raw_data': pd.DataFrame(),
        'yoy_data': pd.DataFrame(),
        'mom_data': pd.DataFrame(),
        'latest_values': {},
        'load_info': {'loaded': False, 'load_time': None, 'start_date': None, 'series_count': 0, 'data_points': 0}
    }
    print("ğŸ—‘ï¸ ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤")

# %%
# === ë°ì´í„° ì ‘ê·¼ í•¨ìˆ˜ë“¤ ===

def get_raw_data(series_names=None):
    """ì›ë³¸ ë ˆë²¨ ë°ì´í„° ë°˜í™˜"""
    if not IMPORT_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_import_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return pd.DataFrame()
    
    if series_names is None:
        return IMPORT_DATA['raw_data'].copy()
    
    available_series = [s for s in series_names if s in IMPORT_DATA['raw_data'].columns]
    if not available_series:
        print(f"âš ï¸ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤: {series_names}")
        return pd.DataFrame()
    
    return IMPORT_DATA['raw_data'][available_series].copy()

def get_yoy_data(series_names=None):
    """YoY ë³€í™”ìœ¨ ë°ì´í„° ë°˜í™˜"""
    if not IMPORT_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_import_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return pd.DataFrame()
    
    if series_names is None:
        return IMPORT_DATA['yoy_data'].copy()
    
    available_series = [s for s in series_names if s in IMPORT_DATA['yoy_data'].columns]
    if not available_series:
        print(f"âš ï¸ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤: {series_names}")
        return pd.DataFrame()
    
    return IMPORT_DATA['yoy_data'][available_series].copy()

def get_mom_data(series_names=None):
    """ì „ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ë°ì´í„° ë°˜í™˜"""
    if not IMPORT_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_import_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return pd.DataFrame()
    
    if series_names is None:
        return IMPORT_DATA['mom_data'].copy()
    
    available_series = [s for s in series_names if s in IMPORT_DATA['mom_data'].columns]
    if not available_series:
        print(f"âš ï¸ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤: {series_names}")
        return pd.DataFrame()
    
    return IMPORT_DATA['mom_data'][available_series].copy()

def get_latest_values(series_names=None):
    """ìµœì‹  YoY ê°’ë“¤ ë°˜í™˜"""
    if not IMPORT_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_import_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return {}
    
    if series_names is None:
        return IMPORT_DATA['latest_values'].copy()
    
    return {name: IMPORT_DATA['latest_values'].get(name, 0) for name in series_names if name in IMPORT_DATA['latest_values']}

def list_available_series():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œë¦¬ì¦ˆ ëª©ë¡ ë°˜í™˜"""
    if not IMPORT_DATA['load_info']['loaded']:
        return []
    return list(IMPORT_DATA['raw_data'].columns)

# %%
# === ì‹œê°í™” í•¨ìˆ˜ë“¤ ===

def create_import_timeseries_chart(series_names=None, chart_type='yoy', start_date=None):
    """
    ì €ì¥ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ Import Prices ì‹œê³„ì—´ ì°¨íŠ¸ ìƒì„±
    
    Args:
        series_names: ì°¨íŠ¸ì— í‘œì‹œí•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸ (ì›í•˜ëŠ” ë§Œí¼ ì¶”ê°€ ê°€ëŠ¥)
        chart_type: 'yoy' (ì „ë…„ë™ê¸°ëŒ€ë¹„), 'mom' (ì „ì›”ëŒ€ë¹„), ë˜ëŠ” 'raw' (ì›ë³¸ ìˆ˜ì¤€)
        title: ì°¨íŠ¸ ì œëª©
        start_date: ì‹œì‘ ë‚ ì§œ (ì˜ˆ: '2021-01-01')
    """
    if not IMPORT_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_import_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    if series_names is None:
        series_names = ['EIUIR', 'EIUIREXFUELS']  # ì „ì²´, ì—°ë£Œ ì œì™¸
    
    # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    if chart_type == 'yoy':
        df = get_yoy_data(series_names)
        ytitle = "Percent change from year ago"
    elif chart_type == 'mom':
        df = get_mom_data(series_names)
        ytitle = "Percent change from month ago"
    else:  # raw
        df = get_raw_data(series_names)
        ytitle = "Index Level"
    
    if df.empty:
        print("âš ï¸ ìš”ì²­í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ì‹œì‘ ë‚ ì§œ í•„í„°ë§
    if start_date:
        df = df[df.index >= start_date]
    
    # ë¼ë²¨ ë§¤í•‘ (í•œêµ­ì–´)
    label_mapping = {}
    for series_id in series_names:
        label_mapping[series_id] = IMPORT_KOREAN_NAMES.get(series_id, IMPORT_SERIES.get(series_id, series_id))
    
    # ë°ì´í„° ì¤€ë¹„
    chart_data = {}
    for col in df.columns:
        label = label_mapping.get(col, col)
        chart_data[label] = df[col].dropna()
    
    # íƒ€ì´í‹€ ì¶œë ¥
    if chart_type == 'yoy':
        print("Import Price Index - Year-over-Year Change")
    elif chart_type == 'mom':
        print("Import Price Index - Month-over-Month Change")
    else:
        print("Import Price Index - Level")
    
    # KPDS í¬ë§· ì‚¬ìš©í•˜ì—¬ ì°¨íŠ¸ ìƒì„±
    chart_df = pd.DataFrame(chart_data)
    
    if chart_type in ['yoy', 'mom']:
        fig = df_multi_line_chart(chart_df, ytitle=ytitle)
        fig.add_hline(y=0, line_width=1, line_color="black", opacity=0.5)
    else:
        fig = df_multi_line_chart(chart_df, ytitle=ytitle)
    
    return fig

def create_import_horizontal_bar_chart(chart_type='yoy'):
    """
    í•­ëª©ë³„ ë³€í™”ìœ¨ì„ ë³´ì—¬ì£¼ëŠ” ê°€ë¡œ ë°” ì°¨íŠ¸ ìƒì„±
    
    Args:
        chart_type: 'yoy' ë˜ëŠ” 'mom'
        title: ì°¨íŠ¸ ì œëª©
    
    Returns:
        plotly figure
    """
    if not IMPORT_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_import_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ìµœì‹  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    if chart_type == 'yoy':
        data = get_yoy_data()
    else:  # mom
        data = get_mom_data()
    
    latest_data = data.iloc[-1].dropna()
    
    # ë°ì´í„° ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
    sorted_data = latest_data.sort_values(ascending=True)  # ê°€ë¡œ ë°”ì°¨íŠ¸ì´ë¯€ë¡œ ascending=True
    
    # ë¼ë²¨ ì ìš©
    categories = []
    values = []
    colors = []
    
    for series_id, value in sorted_data.items():
        label = IMPORT_KOREAN_NAMES.get(series_id, IMPORT_SERIES.get(series_id, series_id))
        categories.append(label)
        values.append(value)
        
        # ì£¼ìš” ì§€í‘œëŠ” íŠ¹ë³„ ìƒ‰ìƒ
        if series_id in ['EIUIR', 'EIUIREXFUELS']:
            colors.append('#FFA500')  # ì£¼í™©ìƒ‰
        elif value >= 0:
            colors.append(deepred_pds)  # ìƒìŠ¹: deepred_pds
        else:
            colors.append(deepblue_pds)  # í•˜ë½: deepblue_pds
    
    # ê°€ë¡œ ë°” ì°¨íŠ¸ ìƒì„±
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        y=categories,
        x=values,
        orientation='h',
        marker_color=colors,
        text=[f'{v:.1f}%' for v in values],
        textposition='outside' if all(v >= 0 for v in values) else 'auto',
        showlegend=False
    ))
    
    # íƒ€ì´í‹€ ì¶œë ¥
    if chart_type == 'yoy':
        print("Import Prices - Year-over-Year % Change (Latest)")
    else:
        print("Import Prices - Month-over-Month % Change (Latest)")
    
    # ìµœì‹  ë‚ ì§œ ê°€ì ¸ì˜¤ê¸°
    latest_date = IMPORT_DATA['raw_data'].index[-1].strftime('%B %Y')
    
    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    fig.update_layout(
        paper_bgcolor='white',
        plot_bgcolor='white',
        width=800,
        height=max(400, len(categories) * 40),
        font=dict(family='NanumGothic', size=FONT_SIZE_GENERAL-1, color="black"),
        xaxis=dict(
            showline=True, linewidth=1.3, linecolor='lightgrey',
            tickwidth=1.3, tickcolor='lightgrey',
            ticks='outside',
            tickformat='.1f',
            range=[min(values) * 1.2 if min(values) < 0 else -1, max(values) * 1.2]
        ),
        yaxis=dict(
            showline=False,
            tickcolor='white'
        ),
        margin=dict(l=250, r=80, t=80, b=60)
    )
    
    # ê²©ìì„  ë° 0ì„ 
    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor="lightgrey")
    fig.update_yaxes(showgrid=False)
    fig.add_vline(x=0, line_width=2, line_color="black")
    
    fig.show()
    return fig

def create_import_component_comparison(category='ì£¼ìš” ì§€í‘œ', chart_type='yoy'):
    """
    Import Prices êµ¬ì„±ìš”ì†Œ ë¹„êµ ì°¨íŠ¸
    
    Args:
        category: IMPORT_HIERARCHYì˜ ì¹´í…Œê³ ë¦¬ ('ì£¼ìš” ì§€í‘œ', 'ì„¸ë¶€ í’ˆëª©')
        chart_type: ì°¨íŠ¸ íƒ€ì… ('yoy', 'mom', 'raw')
        title: ì°¨íŠ¸ ì œëª©
    """
    if not IMPORT_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_import_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    if category not in IMPORT_HIERARCHY:
        print(f"âš ï¸ ì˜ëª»ëœ ì¹´í…Œê³ ë¦¬: {category}")
        return None
    
    # ëª¨ë“  ì‹œë¦¬ì¦ˆ ìˆ˜ì§‘
    all_series = []
    for group in IMPORT_HIERARCHY[category].values():
        all_series.extend(group)
    
    # íƒ€ì´í‹€ ì¶œë ¥
    print(f"Import Prices {category} - {chart_type.upper()}")
    
    # ì‹œê³„ì—´ ì°¨íŠ¸ ìƒì„±
    return create_import_timeseries_chart(all_series, chart_type)

# %%
# === í†µí•© ë¶„ì„ í•¨ìˆ˜ ===

def run_complete_import_analysis(start_date='2020-01-01', force_reload=False):
    """
    ì™„ì „í•œ Import Prices ë¶„ì„ ì‹¤í–‰ - ë°ì´í„° ë¡œë“œ í›„ ëª¨ë“  ì°¨íŠ¸ ìƒì„±
    
    Args:
        start_date: ë°ì´í„° ì‹œì‘ ë‚ ì§œ
        force_reload: ê°•ì œ ì¬ë¡œë“œ ì—¬ë¶€
    
    Returns:
        dict: ìƒì„±ëœ ì°¨íŠ¸ë“¤
    """
    print("ğŸš€ ì™„ì „í•œ Import Prices ë¶„ì„ ì‹œì‘")
    print("="*50)
    
    # 1. ë°ì´í„° ë¡œë“œ (í•œ ë²ˆë§Œ!)
    print("\n1ï¸âƒ£ ë°ì´í„° ë¡œë”©")
    success = load_all_import_data(start_date=start_date, force_reload=force_reload)
    
    if not success:
        print("âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨")
        return None
    
    # 2. ì‹œê°í™” ìƒì„± (ì €ì¥ëœ ë°ì´í„° ì‚¬ìš©)
    print("\n2ï¸âƒ£ ì‹œê°í™” ìƒì„±")
    
    results = {}
    
    try:
        # ì£¼ìš” ì§€í‘œ ì‹œê³„ì—´ (YoY)
        print("   ğŸ“ˆ ì£¼ìš” Import Price ì§€í‘œ ì‹œê³„ì—´ (YoY)...")
        results['main_timeseries_yoy'] = create_import_timeseries_chart(['EIUIR', 'EIUIREXFUELS', 'EIUIR10'], 'yoy')
        
        # ì£¼ìš” ì§€í‘œ ì‹œê³„ì—´ (MoM)
        print("   ğŸ“ˆ ì£¼ìš” Import Price ì§€í‘œ ì‹œê³„ì—´ (MoM)...")
        results['main_timeseries_mom'] = create_import_timeseries_chart(['EIUIR', 'EIUIREXFUELS', 'EIUIR10'], 'mom')
        
        # ì„¸ë¶€ í’ˆëª© ë¹„êµ
        print("   ğŸ” ì„¸ë¶€ í’ˆëª© ë¹„êµ...")
        results['detail_comparison'] = create_import_component_comparison('ì„¸ë¶€ í’ˆëª©', 'yoy')
        
        # YoY ê°€ë¡œ ë°” ì°¨íŠ¸
        print("   ğŸ“Š YoY ë³€í™”ìœ¨ ê°€ë¡œ ë°” ì°¨íŠ¸...")
        results['horizontal_bar_yoy'] = create_import_horizontal_bar_chart('yoy')
        
        # MoM ê°€ë¡œ ë°” ì°¨íŠ¸
        print("   ğŸ“Š MoM ë³€í™”ìœ¨ ê°€ë¡œ ë°” ì°¨íŠ¸...")
        results['horizontal_bar_mom'] = create_import_horizontal_bar_chart('mom')
        
    except Exception as e:
        print(f"âš ï¸ ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
    
    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ! ìƒì„±ëœ ì°¨íŠ¸: {len(results)}ê°œ")
    return results

# %%
# === ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ===

def show_available_components():
    """ì‚¬ìš© ê°€ëŠ¥í•œ Import Prices êµ¬ì„±ìš”ì†Œ í‘œì‹œ"""
    print("=== ì‚¬ìš© ê°€ëŠ¥í•œ Import Prices êµ¬ì„±ìš”ì†Œ ===")
    
    for series_id, description in IMPORT_SERIES.items():
        korean_name = IMPORT_KOREAN_NAMES.get(series_id, description)
        print(f"  '{series_id}': {korean_name} ({description})")

def get_data_status():
    """í˜„ì¬ ë°ì´í„° ìƒíƒœ ë°˜í™˜"""
    return {
        'loaded': IMPORT_DATA['load_info']['loaded'],
        'series_count': IMPORT_DATA['load_info']['series_count'],
        'available_series': list_available_series(),
        'load_info': IMPORT_DATA['load_info']
    }

def show_import_hierarchy():
    """Import Prices ê³„ì¸µ êµ¬ì¡° í‘œì‹œ"""
    print("=== Import Prices ê³„ì¸µ êµ¬ì¡° ===\n")
    
    for level, groups in IMPORT_HIERARCHY.items():
        print(f"### {level} ###")
        for group_name, series_list in groups.items():
            print(f"  {group_name}:")
            for series_id in series_list:
                korean_name = IMPORT_KOREAN_NAMES.get(series_id, IMPORT_SERIES.get(series_id, series_id))
                print(f"    - {series_id}: {korean_name}")
        print()

# %%
# === ì‚¬ìš© ì˜ˆì‹œ ===

print("\n=== Import Prices ë¶„ì„ ë„êµ¬ ì‚¬ìš©ë²• ===")
print("1. ë°ì´í„° ë¡œë“œ (CSV ìš°ì„ , API ë°±ì—…):")
print("   load_all_import_data()  # CSVê°€ ìˆìœ¼ë©´ ë¡œë“œ í›„ ì—…ë°ì´íŠ¸")
print("   load_import_data_from_csv()  # CSVì—ì„œë§Œ ë¡œë“œ")
print("   update_import_data_from_api()  # ìµœì‹  ë°ì´í„°ë§Œ APIë¡œ ì—…ë°ì´íŠ¸")
print()
print("2. ë°ì´í„° ì €ì¥:")
print("   save_import_data_to_csv()  # í˜„ì¬ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥")
print()
print("3. API í‚¤ ê´€ë¦¬:")
print("   switch_api_key()  # API í‚¤ ìˆ˜ë™ ì „í™˜")
print()
print("4. ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸:")
print("   check_recent_data_consistency()  # ìµœê·¼ 3ê°œ ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸")
print("   update_import_data_from_api(smart_update=True)  # ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸")
print("   update_import_data_from_api(smart_update=False)  # ê°•ì œ ì—…ë°ì´íŠ¸")
print()
print("5. ì°¨íŠ¸ ìƒì„±:")
print("   # ì‹œê³„ì—´ ì°¨íŠ¸ (ì›í•˜ëŠ” ì‹œë¦¬ì¦ˆë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ê°€ ê°€ëŠ¥)")
print("   create_import_timeseries_chart(['EIUIR', 'EIUIR10'], 'yoy')  # YoY")
print("   create_import_timeseries_chart(['EIUIR', 'EIUIR10'], 'mom')  # MoM")
print("   create_import_timeseries_chart(['EIUIR', 'EIUIR10'], 'raw')  # ì›ë³¸ ë ˆë²¨")
print()
print("   # ê°€ë¡œ ë°” ì°¨íŠ¸")
print("   create_import_horizontal_bar_chart('yoy')  # YoY ë³€í™”ìœ¨")
print("   create_import_horizontal_bar_chart('mom')  # MoM ë³€í™”ìœ¨")
print()
print("   # êµ¬ì„±ìš”ì†Œ ë¹„êµ")
print("   create_import_component_comparison('ì£¼ìš” ì§€í‘œ', 'yoy')")
print("   create_import_component_comparison('ì„¸ë¶€ í’ˆëª©', 'mom')")
print()
print("6. í†µí•© ë¶„ì„:")
print("   run_complete_import_analysis()")
print()
print("7. ë°ì´í„° ìƒíƒœ í™•ì¸:")
print("   get_data_status()")
print("   show_available_components()")
print("   show_import_hierarchy()")

# %%
# ì‚¬ìš© ê°€ëŠ¥í•œ êµ¬ì„±ìš”ì†Œ í‘œì‹œ
show_available_components()

# %%
# Import Prices ê³„ì¸µ êµ¬ì¡° í‘œì‹œ
show_import_hierarchy()

# %%
# ê¸°ë³¸ Import Prices ë¶„ì„ ì‹¤í–‰ (ì£¼ì„ ì²˜ë¦¬ë¨ - í•„ìš”ì‹œ í™œì„±í™”)
run_complete_import_analysis()

# %%
# ì˜ˆì‹œ: íŠ¹ì • ì‹œë¦¬ì¦ˆë“¤ì˜ ì‹œê³„ì—´ ì°¨íŠ¸ ìƒì„±
# create_import_timeseries_chart(['EIUIR', 'EIUIR10', 'EIUIREXFUELS'], 'yoy', start_date='2022-01-01')

# %%
# ì˜ˆì‹œ: MoM ê°€ë¡œ ë°” ì°¨íŠ¸
create_import_horizontal_bar_chart('mom')