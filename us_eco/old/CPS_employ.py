# %%
"""
BLS API ì „ìš© CPS(Current Population Survey) ë¶„ì„ ë° ì‹œê°í™” ë„êµ¬
- BLS APIë§Œ ì‚¬ìš©í•˜ì—¬ CPS ë…¸ë™ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘
- ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ë¡œ API í˜¸ì¶œ ìµœì†Œí™”
- CSV ì €ì¥/ë¡œë“œ ë° ìë™ ì—…ë°ì´íŠ¸
- íˆ¬ìì€í–‰/ì´ì½”ë…¸ë¯¸ìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì „ë¬¸ ë¶„ì„ ê¸°ëŠ¥
"""
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import sys
import warnings
warnings.filterwarnings('ignore')

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    import requests
    import json
    BLS_API_AVAILABLE = True
    print("âœ“ BLS API ì—°ë™ ê°€ëŠ¥ (requests ë¼ì´ë¸ŒëŸ¬ë¦¬)")
except ImportError:
    print("âš ï¸ requests ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜í•˜ì„¸ìš”: pip install requests")
    BLS_API_AVAILABLE = False

# BLS API í‚¤ ì„¤ì •
BLS_API_KEY = '56b193612b614cdc9416359fd1c73a74'
BLS_API_KEY2 = '0450ef37363c48b5bedd2ae6fc92dd6e'
BLS_API_KEY3 = 'daf1ca7970b74e81b6a5c7a80a8b8a7f'
CURRENT_API_KEY = BLS_API_KEY2

# ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
sys.path.append('/home/jyp0615')
from kpds_fig_format_enhanced import *

# %%
# === CPS ì‹œë¦¬ì¦ˆ IDì™€ ì„¤ëª… ë§¤í•‘ ===

CPS_SERIES = {
    # ì£¼ìš” ë…¸ë™ì‹œì¥ ì§€í‘œ
    'LNS11000000': 'Civilian Labor Force Level',
    'LNS11300000': 'Civilian Labor Force Participation Rate',
    'LNS12000000': 'Employment Level',
    'LNS12300000': 'Employment-Population Ratio',
    'LNS12500000': 'Employed, Usually Work Full Time',
    'LNS12600000': 'Employed, Usually Work Part Time',
    'LNS13000000': 'Unemployment Level',
    'LNS14000000': 'Unemployment Rate',
    
    # ì—°ë ¹ë³„ ì‹¤ì—…ë¥ 
    'LNS14000012': 'Unemployment Rate - 16-19 Years',
    'LNS14000025': 'Unemployment Rate - 20 Years & Over Men',
    'LNS14000026': 'Unemployment Rate - 20 Years & Over Women',
    
    # ì¸ì¢…ë³„ ì‹¤ì—…ë¥ 
    'LNS14000003': 'Unemployment Rate - White',
    'LNS14000006': 'Unemployment Rate - Black or African American',
    'LNS14032183': 'Unemployment Rate - Asian',
    'LNS14000009': 'Unemployment Rate - Hispanic or Latino',
    
    # êµìœ¡ìˆ˜ì¤€ë³„ ì‹¤ì—…ë¥ 
    'LNS14027659': 'Unemployment Rate - Less than High School',
    'LNS14027660': 'Unemployment Rate - High School Graduates',
    'LNS14027689': 'Unemployment Rate - Some College',
    'LNS14027662': 'Unemployment Rate - Bachelor\'s Degree and Higher',
    
    # ì‹¤ì—… ê¸°ê°„
    'LNS13008396': 'Unemployed Less Than 5 weeks',
    'LNS13008756': 'Unemployed 5-14 Weeks',
    'LNS13008516': 'Unemployed 15 Weeks & Over',
    'LNS13008636': 'Unemployed 27 Weeks & Over',
    'LNS13008275': 'Average Weeks Unemployed',
    'LNS13008276': 'Median Weeks Unemployed',
    
    # ì‹¤ì—… ìœ í˜•
    'LNS13023621': 'Unemployment - Job Losers',
    'LNS13023653': 'Unemployment - Job Losers On Layoff',
    'LNS13025699': 'Unemployment - Job Losers Not on Layoff',
    'LNS13023705': 'Unemployment - Job Leavers',
    'LNS13023557': 'Unemployment - Reentrants',
    'LNS13023569': 'Unemployment - New Entrants',
    
    # ê¸°íƒ€ ë…¸ë™ì‹œì¥ ì§€í‘œ
    'LNS12032194': 'Part Time for Economic Reasons',
    'LNS15000000': 'Not in Labor Force',
    'LNS15026642': 'Marginally Attached to Labor Force',
    'LNS15026645': 'Discouraged Workers',
    'LNS13327709': 'U-6 Unemployment Rate',
    'LNS12026619': 'Multiple Jobholders Level',
    'LNS12026620': 'Multiple Jobholders as Percent of Employed',
    
    # ë‚ ì”¨ ì˜í–¥
    'LNU02036012': 'Not at Work - Bad Weather',
    'LNU02033224': 'At Work 1-34 Hrs - Bad Weather',
    
    # 20ì„¸ ì´ìƒ ì£¼ìš” ì§€í‘œ
    'LNS11000024': 'Labor Force - 20 Years & Over',
    'LNS11300024': 'Participation Rate - 20 Years & Over',
    'LNS12000024': 'Employment - 20 Years & Over',
    'LNS13000024': 'Unemployment - 20 Years & Over',
    'LNS14000024': 'Unemployment Rate - 20 Years & Over',
    
    # 25ì„¸ ì´ìƒ ì£¼ìš” ì§€í‘œ
    'LNS11000048': 'Labor Force - 25 Years & Over',
    'LNS11300048': 'Participation Rate - 25 Years & Over',
    'LNS12000048': 'Employment - 25 Years & Over',
    'LNS13000048': 'Unemployment - 25 Years & Over',
    'LNS14000048': 'Unemployment Rate - 25 Years & Over',
    
    # 55ì„¸ ì´ìƒ ì£¼ìš” ì§€í‘œ
    'LNS11024230': 'Labor Force - 55 Years & Over',
    'LNS11324230': 'Participation Rate - 55 Years & Over',
    'LNS12024230': 'Employment - 55 Years & Over',
    'LNS13024230': 'Unemployment - 55 Years & Over',
    'LNS14024230': 'Unemployment Rate - 55 Years & Over',
    
    # íˆìŠ¤íŒ¨ë‹‰/ë¼í‹°ë…¸ ì „ì²´ ë…¸ë™ì‹œì¥ ì§€í‘œ
    'LNS11000009': 'Labor Force - Hispanic or Latino',
    'LNS11300009': 'Participation Rate - Hispanic or Latino',
    'LNS12000009': 'Employment - Hispanic or Latino',
    'LNS13000009': 'Unemployment - Hispanic or Latino',
    'LNS15000009': 'Not in Labor Force - Hispanic or Latino',
    
    # === ì¶”ê°€ ì—°ë ¹ë³„ ë…¸ë™ì‹œì¥ ì§€í‘œ (Not Seasonally Adjusted) ===
    'LNU01076975': 'Civilian Labor Force - 18 Years & Over (NSA)',
    'LNU01376975': 'Participation Rate - 18 Years & Over (NSA)',
    'LNU02076975': 'Employment - 18 Years & Over (NSA)',
    'LNU03076975': 'Unemployment - 18 Years & Over (NSA)',
    'LNU04076975': 'Unemployment Rate - 18 Years & Over (NSA)',
    'LNU05076975': 'Not in Labor Force - 18 Years & Over (NSA)',
    
    # 25ì„¸ ì´ìƒ (Not Seasonally Adjusted)
    'LNU01000048': 'Civilian Labor Force - 25 Years & Over (NSA)',
    'LNU01300048': 'Participation Rate - 25 Years & Over (NSA)',
    'LNU02000048': 'Employment - 25 Years & Over (NSA)',
    'LNU02500048': 'Employed Full Time - 25 Years & Over (NSA)',
    'LNU02600048': 'Employed Part Time - 25 Years & Over (NSA)',
    'LNU03000048': 'Unemployment - 25 Years & Over (NSA)',
    'LNU03100048': 'Unemployed Looking for Full-time - 25 Years & Over (NSA)',
    'LNU03200048': 'Unemployed Looking for Part-time - 25 Years & Over (NSA)',
    'LNU04000048': 'Unemployment Rate - 25 Years & Over (NSA)',
    
    # 45ì„¸ ì´ìƒ (Not Seasonally Adjusted)
    'LNU01000092': 'Civilian Labor Force - 45 Years & Over (NSA)',
    'LNU01300092': 'Participation Rate - 45 Years & Over (NSA)',
    'LNU02000092': 'Employment - 45 Years & Over (NSA)',
    'LNU03000092': 'Unemployment - 45 Years & Over (NSA)',
    'LNU04000092': 'Unemployment Rate - 45 Years & Over (NSA)',
    'LNU05000092': 'Not in Labor Force - 45 Years & Over (NSA)',
    
    # 55ì„¸ ì´ìƒ (Not Seasonally Adjusted)
    'LNU01024230': 'Civilian Labor Force - 55 Years & Over (NSA)',
    'LNU01324230': 'Participation Rate - 55 Years & Over (NSA)',
    'LNU02024230': 'Employment - 55 Years & Over (NSA)',
    'LNU02524230': 'Employed Full Time - 55 Years & Over (NSA)',
    'LNU02624230': 'Employed Part Time - 55 Years & Over (NSA)',
    'LNU03024230': 'Unemployment - 55 Years & Over (NSA)',
    'LNU03124230': 'Unemployed Looking for Full-time - 55 Years & Over (NSA)',
    'LNU03224230': 'Unemployed Looking for Part-time - 55 Years & Over (NSA)',
    'LNU04024230': 'Unemployment Rate - 55 Years & Over (NSA)',
    'LNU05024230': 'Not in Labor Force - 55 Years & Over (NSA)',
    
    # 65ì„¸ ì´ìƒ (Not Seasonally Adjusted)
    'LNU01000097': 'Civilian Labor Force - 65 Years & Over (NSA)',
    'LNU01300097': 'Participation Rate - 65 Years & Over (NSA)',
    'LNU02000097': 'Employment - 65 Years & Over (NSA)',
    'LNU03000097': 'Unemployment - 65 Years & Over (NSA)',
    'LNU04000097': 'Unemployment Rate - 65 Years & Over (NSA)',
    'LNU05000097': 'Not in Labor Force - 65 Years & Over (NSA)',
    
    # === ì¶”ê°€ ì¸ì¢…ë³„ ë…¸ë™ì‹œì¥ ì§€í‘œ (Not Seasonally Adjusted) ===
    # ë°±ì¸ (White)
    'LNU01000003': 'Civilian Labor Force - White (NSA)',
    'LNU01300003': 'Participation Rate - White (NSA)',
    'LNU02000003': 'Employment - White (NSA)',
    'LNU02500003': 'Employed Full Time - White (NSA)',
    'LNU02600003': 'Employed Part Time - White (NSA)',
    'LNU03000003': 'Unemployment - White (NSA)',
    'LNU04000003': 'Unemployment Rate - White (NSA)',
    'LNU05000003': 'Not in Labor Force - White (NSA)',
    
    # í‘ì¸ (Black or African American)
    'LNU01000006': 'Civilian Labor Force - Black or African American (NSA)',
    'LNU01300006': 'Participation Rate - Black or African American (NSA)',
    'LNU02000006': 'Employment - Black or African American (NSA)',
    'LNU02500006': 'Employed Full Time - Black or African American (NSA)',
    'LNU02600006': 'Employed Part Time - Black or African American (NSA)',
    'LNU03000006': 'Unemployment - Black or African American (NSA)',
    'LNU04000006': 'Unemployment Rate - Black or African American (NSA)',
    'LNU05000006': 'Not in Labor Force - Black or African American (NSA)',
    
    # ì•„ì‹œì•„ê³„ (Asian)
    'LNU01032183': 'Civilian Labor Force - Asian (NSA)',
    'LNU01332183': 'Participation Rate - Asian (NSA)',
    'LNU02032183': 'Employment - Asian (NSA)',
    'LNU02532183': 'Employed Full Time - Asian (NSA)',
    'LNU02632183': 'Employed Part Time - Asian (NSA)',
    'LNU03032183': 'Unemployment - Asian (NSA)',
    'LNU04032183': 'Unemployment Rate - Asian (NSA)',
    'LNU05032183': 'Not in Labor Force - Asian (NSA)',
    
    # ì•„ë©”ë¦¬ì¹´ ì›ì£¼ë¯¼ (American Indian or Alaska Native)
    'LNU01035243': 'Civilian Labor Force - American Indian or Alaska Native (NSA)',
    'LNU01335243': 'Participation Rate - American Indian or Alaska Native (NSA)',
    'LNU02035243': 'Employment - American Indian or Alaska Native (NSA)',
    'LNU03035243': 'Unemployment - American Indian or Alaska Native (NSA)',
    'LNU04035243': 'Unemployment Rate - American Indian or Alaska Native (NSA)',
    'LNU05035243': 'Not in Labor Force - American Indian or Alaska Native (NSA)',
    
    # í•˜ì™€ì´ ì›ì£¼ë¯¼ ë° íƒœí‰ì–‘ ì„¬ ì£¼ë¯¼ (Native Hawaiian or Other Pacific Islander)
    'LNU01035553': 'Civilian Labor Force - Native Hawaiian or Other Pacific Islander (NSA)',
    'LNU01335553': 'Participation Rate - Native Hawaiian or Other Pacific Islander (NSA)',
    'LNU02035553': 'Employment - Native Hawaiian or Other Pacific Islander (NSA)',
    'LNU03035553': 'Unemployment - Native Hawaiian or Other Pacific Islander (NSA)',
    'LNU04035553': 'Unemployment Rate - Native Hawaiian or Other Pacific Islander (NSA)',
    'LNU05035553': 'Not in Labor Force - Native Hawaiian or Other Pacific Islander (NSA)',
    
    # === ê¸°ë³¸ ì§€í‘œë“¤ì˜ Not Seasonally Adjusted ë²„ì „ ===
    'LNU01000000': 'Civilian Labor Force (NSA)',
    'LNU01300000': 'Civilian Labor Force Participation Rate (NSA)',
    'LNU02000000': 'Employment Level (NSA)',
    'LNU02500000': 'Employed, Usually Work Full Time (NSA)',
    'LNU02600000': 'Employed, Usually Work Part Time (NSA)',
    'LNU03000000': 'Unemployment Level (NSA)',
    'LNU03100000': 'Unemployed Looking for Full-time Work (NSA)',
    'LNU03200000': 'Unemployed Looking for Part-time Work (NSA)',
    'LNU04000000': 'Unemployment Rate (NSA)',
    'LNU04100000': 'Unemployment Rate of the Full-time Labor Force (NSA)',
    'LNU04200000': 'Unemployment Rate of the Part-time Labor Force (NSA)',
    'LNU05000000': 'Not in Labor Force (NSA)'
}

# í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘
CPS_KOREAN_NAMES = {
    # ì£¼ìš” ë…¸ë™ì‹œì¥ ì§€í‘œ
    'LNS11000000': 'ê²½ì œí™œë™ì¸êµ¬',
    'LNS11300000': 'ê²½ì œí™œë™ì°¸ê°€ìœ¨',
    'LNS12000000': 'ì·¨ì—…ììˆ˜',
    'LNS12300000': 'ê³ ìš©ë¥ ',
    'LNS12500000': 'í’€íƒ€ì„ ì·¨ì—…ì',
    'LNS12600000': 'íŒŒíŠ¸íƒ€ì„ ì·¨ì—…ì',
    'LNS13000000': 'ì‹¤ì—…ììˆ˜',
    'LNS14000000': 'ì‹¤ì—…ë¥ ',
    
    # ì—°ë ¹ë³„ ì‹¤ì—…ë¥ 
    'LNS14000012': 'ì‹¤ì—…ë¥  - 16-19ì„¸',
    'LNS14000025': 'ì‹¤ì—…ë¥  - 20ì„¸ ì´ìƒ ë‚¨ì„±',
    'LNS14000026': 'ì‹¤ì—…ë¥  - 20ì„¸ ì´ìƒ ì—¬ì„±',
    
    # ì¸ì¢…ë³„ ì‹¤ì—…ë¥ 
    'LNS14000003': 'ì‹¤ì—…ë¥  - ë°±ì¸',
    'LNS14000006': 'ì‹¤ì—…ë¥  - í‘ì¸',
    'LNS14032183': 'ì‹¤ì—…ë¥  - ì•„ì‹œì•„ê³„',
    'LNS14000009': 'ì‹¤ì—…ë¥  - íˆìŠ¤íŒ¨ë‹‰',
    
    # êµìœ¡ìˆ˜ì¤€ë³„ ì‹¤ì—…ë¥ 
    'LNS14027659': 'ì‹¤ì—…ë¥  - ê³ ì¡¸ ë¯¸ë§Œ',
    'LNS14027660': 'ì‹¤ì—…ë¥  - ê³ ì¡¸',
    'LNS14027689': 'ì‹¤ì—…ë¥  - ëŒ€í•™ ì¤‘í‡´/ì „ë¬¸ëŒ€',
    'LNS14027662': 'ì‹¤ì—…ë¥  - ëŒ€ì¡¸ ì´ìƒ',
    
    # ì‹¤ì—… ê¸°ê°„
    'LNS13008396': 'ì‹¤ì—…ì - 5ì£¼ ë¯¸ë§Œ',
    'LNS13008756': 'ì‹¤ì—…ì - 5-14ì£¼',
    'LNS13008516': 'ì‹¤ì—…ì - 15ì£¼ ì´ìƒ',
    'LNS13008636': 'ì‹¤ì—…ì - 27ì£¼ ì´ìƒ',
    'LNS13008275': 'í‰ê·  ì‹¤ì—… ê¸°ê°„',
    'LNS13008276': 'ì¤‘ê°„ê°’ ì‹¤ì—… ê¸°ê°„',
    
    # ì‹¤ì—… ìœ í˜•
    'LNS13023621': 'ì‹¤ì§ì',
    'LNS13023653': 'ì¼ì‹œí•´ê³ ì',
    'LNS13025699': 'ì˜êµ¬í•´ê³ ì',
    'LNS13023705': 'ìë°œì  ì´ì§ì',
    'LNS13023557': 'ì¬ì§„ì…ì',
    'LNS13023569': 'ì‹ ê·œì§„ì…ì',
    
    # ê¸°íƒ€ ë…¸ë™ì‹œì¥ ì§€í‘œ
    'LNS12032194': 'ê²½ì œì  ì´ìœ  íŒŒíŠ¸íƒ€ì„',
    'LNS15000000': 'ë¹„ê²½ì œí™œë™ì¸êµ¬',
    'LNS15026642': 'í•œê³„ë…¸ë™ë ¥',
    'LNS15026645': 'êµ¬ì§ë‹¨ë…ì',
    'LNS13327709': 'U-6 ì‹¤ì—…ë¥  (ê´‘ì˜)',
    'LNS12026619': 'ë³µìˆ˜ì§ì—… ë³´ìœ ì',
    'LNS12026620': 'ë³µìˆ˜ì§ì—… ë³´ìœ ìœ¨',
    
    # ë‚ ì”¨ ì˜í–¥
    'LNU02036012': 'ì•…ì²œí›„ ê²°ê·¼',
    'LNU02033224': 'ì•…ì²œí›„ ë‹¨ì¶•ê·¼ë¬´',
    
    # 20ì„¸ ì´ìƒ ì£¼ìš” ì§€í‘œ
    'LNS11000024': 'ê²½ì œí™œë™ì¸êµ¬ - 20ì„¸ ì´ìƒ',
    'LNS11300024': 'ê²½ì œí™œë™ì°¸ê°€ìœ¨ - 20ì„¸ ì´ìƒ',
    'LNS12000024': 'ì·¨ì—…ììˆ˜ - 20ì„¸ ì´ìƒ',
    'LNS13000024': 'ì‹¤ì—…ììˆ˜ - 20ì„¸ ì´ìƒ',
    'LNS14000024': 'ì‹¤ì—…ë¥  - 20ì„¸ ì´ìƒ',
    
    # 25ì„¸ ì´ìƒ ì£¼ìš” ì§€í‘œ
    'LNS11000048': 'ê²½ì œí™œë™ì¸êµ¬ - 25ì„¸ ì´ìƒ',
    'LNS11300048': 'ê²½ì œí™œë™ì°¸ê°€ìœ¨ - 25ì„¸ ì´ìƒ',
    'LNS12000048': 'ì·¨ì—…ììˆ˜ - 25ì„¸ ì´ìƒ',
    'LNS13000048': 'ì‹¤ì—…ììˆ˜ - 25ì„¸ ì´ìƒ',
    'LNS14000048': 'ì‹¤ì—…ë¥  - 25ì„¸ ì´ìƒ',
    
    # 55ì„¸ ì´ìƒ ì£¼ìš” ì§€í‘œ
    'LNS11024230': 'ê²½ì œí™œë™ì¸êµ¬ - 55ì„¸ ì´ìƒ',
    'LNS11324230': 'ê²½ì œí™œë™ì°¸ê°€ìœ¨ - 55ì„¸ ì´ìƒ',
    'LNS12024230': 'ì·¨ì—…ììˆ˜ - 55ì„¸ ì´ìƒ',
    'LNS13024230': 'ì‹¤ì—…ììˆ˜ - 55ì„¸ ì´ìƒ',
    'LNS14024230': 'ì‹¤ì—…ë¥  - 55ì„¸ ì´ìƒ',
    
    # íˆìŠ¤íŒ¨ë‹‰/ë¼í‹°ë…¸ ì „ì²´ ë…¸ë™ì‹œì¥ ì§€í‘œ
    'LNS11000009': 'ê²½ì œí™œë™ì¸êµ¬ - íˆìŠ¤íŒ¨ë‹‰/ë¼í‹°ë…¸',
    'LNS11300009': 'ê²½ì œí™œë™ì°¸ê°€ìœ¨ - íˆìŠ¤íŒ¨ë‹‰/ë¼í‹°ë…¸',
    'LNS12000009': 'ì·¨ì—…ììˆ˜ - íˆìŠ¤íŒ¨ë‹‰/ë¼í‹°ë…¸',
    'LNS13000009': 'ì‹¤ì—…ììˆ˜ - íˆìŠ¤íŒ¨ë‹‰/ë¼í‹°ë…¸',
    'LNS15000009': 'ë¹„ê²½ì œí™œë™ì¸êµ¬ - íˆìŠ¤íŒ¨ë‹‰/ë¼í‹°ë…¸',
    
    # === ì¶”ê°€ ì—°ë ¹ë³„ ë…¸ë™ì‹œì¥ ì§€í‘œ í•œêµ­ì–´ ë§¤í•‘ (Not Seasonally Adjusted) ===
    # 18ì„¸ ì´ìƒ
    'LNU01076975': 'ê²½ì œí™œë™ì¸êµ¬ - 18ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU01376975': 'ê²½ì œí™œë™ì°¸ê°€ìœ¨ - 18ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02076975': 'ì·¨ì—…ììˆ˜ - 18ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU03076975': 'ì‹¤ì—…ììˆ˜ - 18ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU04076975': 'ì‹¤ì—…ë¥  - 18ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU05076975': 'ë¹„ê²½ì œí™œë™ì¸êµ¬ - 18ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    
    # 25ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)
    'LNU01000048': 'ê²½ì œí™œë™ì¸êµ¬ - 25ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU01300048': 'ê²½ì œí™œë™ì°¸ê°€ìœ¨ - 25ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02000048': 'ì·¨ì—…ììˆ˜ - 25ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02500048': 'í’€íƒ€ì„ ì·¨ì—…ì - 25ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02600048': 'íŒŒíŠ¸íƒ€ì„ ì·¨ì—…ì - 25ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU03000048': 'ì‹¤ì—…ììˆ˜ - 25ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU03100048': 'í’€íƒ€ì„ êµ¬ì§ì - 25ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU03200048': 'íŒŒíŠ¸íƒ€ì„ êµ¬ì§ì - 25ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU04000048': 'ì‹¤ì—…ë¥  - 25ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    
    # 45ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)
    'LNU01000092': 'ê²½ì œí™œë™ì¸êµ¬ - 45ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU01300092': 'ê²½ì œí™œë™ì°¸ê°€ìœ¨ - 45ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02000092': 'ì·¨ì—…ììˆ˜ - 45ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU03000092': 'ì‹¤ì—…ììˆ˜ - 45ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU04000092': 'ì‹¤ì—…ë¥  - 45ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU05000092': 'ë¹„ê²½ì œí™œë™ì¸êµ¬ - 45ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    
    # 55ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)
    'LNU01024230': 'ê²½ì œí™œë™ì¸êµ¬ - 55ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU01324230': 'ê²½ì œí™œë™ì°¸ê°€ìœ¨ - 55ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02024230': 'ì·¨ì—…ììˆ˜ - 55ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02524230': 'í’€íƒ€ì„ ì·¨ì—…ì - 55ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02624230': 'íŒŒíŠ¸íƒ€ì„ ì·¨ì—…ì - 55ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU03024230': 'ì‹¤ì—…ììˆ˜ - 55ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU03124230': 'í’€íƒ€ì„ êµ¬ì§ì - 55ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU03224230': 'íŒŒíŠ¸íƒ€ì„ êµ¬ì§ì - 55ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU04024230': 'ì‹¤ì—…ë¥  - 55ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU05024230': 'ë¹„ê²½ì œí™œë™ì¸êµ¬ - 55ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    
    # 65ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)
    'LNU01000097': 'ê²½ì œí™œë™ì¸êµ¬ - 65ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU01300097': 'ê²½ì œí™œë™ì°¸ê°€ìœ¨ - 65ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02000097': 'ì·¨ì—…ììˆ˜ - 65ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU03000097': 'ì‹¤ì—…ììˆ˜ - 65ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU04000097': 'ì‹¤ì—…ë¥  - 65ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU05000097': 'ë¹„ê²½ì œí™œë™ì¸êµ¬ - 65ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
    
    # === ì¶”ê°€ ì¸ì¢…ë³„ ë…¸ë™ì‹œì¥ ì§€í‘œ í•œêµ­ì–´ ë§¤í•‘ (Not Seasonally Adjusted) ===
    # ë°±ì¸ (ë¹„ê³„ì ˆì¡°ì •)
    'LNU01000003': 'ê²½ì œí™œë™ì¸êµ¬ - ë°±ì¸ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU01300003': 'ê²½ì œí™œë™ì°¸ê°€ìœ¨ - ë°±ì¸ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02000003': 'ì·¨ì—…ììˆ˜ - ë°±ì¸ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02500003': 'í’€íƒ€ì„ ì·¨ì—…ì - ë°±ì¸ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02600003': 'íŒŒíŠ¸íƒ€ì„ ì·¨ì—…ì - ë°±ì¸ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU03000003': 'ì‹¤ì—…ììˆ˜ - ë°±ì¸ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU04000003': 'ì‹¤ì—…ë¥  - ë°±ì¸ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU05000003': 'ë¹„ê²½ì œí™œë™ì¸êµ¬ - ë°±ì¸ (ë¹„ê³„ì ˆì¡°ì •)',
    
    # í‘ì¸ (ë¹„ê³„ì ˆì¡°ì •)
    'LNU01000006': 'ê²½ì œí™œë™ì¸êµ¬ - í‘ì¸ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU01300006': 'ê²½ì œí™œë™ì°¸ê°€ìœ¨ - í‘ì¸ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02000006': 'ì·¨ì—…ììˆ˜ - í‘ì¸ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02500006': 'í’€íƒ€ì„ ì·¨ì—…ì - í‘ì¸ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02600006': 'íŒŒíŠ¸íƒ€ì„ ì·¨ì—…ì - í‘ì¸ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU03000006': 'ì‹¤ì—…ììˆ˜ - í‘ì¸ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU04000006': 'ì‹¤ì—…ë¥  - í‘ì¸ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU05000006': 'ë¹„ê²½ì œí™œë™ì¸êµ¬ - í‘ì¸ (ë¹„ê³„ì ˆì¡°ì •)',
    
    # ì•„ì‹œì•„ê³„ (ë¹„ê³„ì ˆì¡°ì •)
    'LNU01032183': 'ê²½ì œí™œë™ì¸êµ¬ - ì•„ì‹œì•„ê³„ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU01332183': 'ê²½ì œí™œë™ì°¸ê°€ìœ¨ - ì•„ì‹œì•„ê³„ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02032183': 'ì·¨ì—…ììˆ˜ - ì•„ì‹œì•„ê³„ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02532183': 'í’€íƒ€ì„ ì·¨ì—…ì - ì•„ì‹œì•„ê³„ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02632183': 'íŒŒíŠ¸íƒ€ì„ ì·¨ì—…ì - ì•„ì‹œì•„ê³„ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU03032183': 'ì‹¤ì—…ììˆ˜ - ì•„ì‹œì•„ê³„ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU04032183': 'ì‹¤ì—…ë¥  - ì•„ì‹œì•„ê³„ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU05032183': 'ë¹„ê²½ì œí™œë™ì¸êµ¬ - ì•„ì‹œì•„ê³„ (ë¹„ê³„ì ˆì¡°ì •)',
    
    # ì•„ë©”ë¦¬ì¹´ ì›ì£¼ë¯¼ (ë¹„ê³„ì ˆì¡°ì •)
    'LNU01035243': 'ê²½ì œí™œë™ì¸êµ¬ - ì•„ë©”ë¦¬ì¹´ ì›ì£¼ë¯¼ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU01335243': 'ê²½ì œí™œë™ì°¸ê°€ìœ¨ - ì•„ë©”ë¦¬ì¹´ ì›ì£¼ë¯¼ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02035243': 'ì·¨ì—…ììˆ˜ - ì•„ë©”ë¦¬ì¹´ ì›ì£¼ë¯¼ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU03035243': 'ì‹¤ì—…ììˆ˜ - ì•„ë©”ë¦¬ì¹´ ì›ì£¼ë¯¼ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU04035243': 'ì‹¤ì—…ë¥  - ì•„ë©”ë¦¬ì¹´ ì›ì£¼ë¯¼ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU05035243': 'ë¹„ê²½ì œí™œë™ì¸êµ¬ - ì•„ë©”ë¦¬ì¹´ ì›ì£¼ë¯¼ (ë¹„ê³„ì ˆì¡°ì •)',
    
    # í•˜ì™€ì´ ì›ì£¼ë¯¼ ë° íƒœí‰ì–‘ ì„¬ ì£¼ë¯¼ (ë¹„ê³„ì ˆì¡°ì •)
    'LNU01035553': 'ê²½ì œí™œë™ì¸êµ¬ - í•˜ì™€ì´/íƒœí‰ì–‘ ì›ì£¼ë¯¼ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU01335553': 'ê²½ì œí™œë™ì°¸ê°€ìœ¨ - í•˜ì™€ì´/íƒœí‰ì–‘ ì›ì£¼ë¯¼ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02035553': 'ì·¨ì—…ììˆ˜ - í•˜ì™€ì´/íƒœí‰ì–‘ ì›ì£¼ë¯¼ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU03035553': 'ì‹¤ì—…ììˆ˜ - í•˜ì™€ì´/íƒœí‰ì–‘ ì›ì£¼ë¯¼ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU04035553': 'ì‹¤ì—…ë¥  - í•˜ì™€ì´/íƒœí‰ì–‘ ì›ì£¼ë¯¼ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU05035553': 'ë¹„ê²½ì œí™œë™ì¸êµ¬ - í•˜ì™€ì´/íƒœí‰ì–‘ ì›ì£¼ë¯¼ (ë¹„ê³„ì ˆì¡°ì •)',
    
    # === ê¸°ë³¸ ì§€í‘œë“¤ì˜ ë¹„ê³„ì ˆì¡°ì • ë²„ì „ í•œêµ­ì–´ ë§¤í•‘ ===
    'LNU01000000': 'ê²½ì œí™œë™ì¸êµ¬ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU01300000': 'ê²½ì œí™œë™ì°¸ê°€ìœ¨ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02000000': 'ì·¨ì—…ììˆ˜ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02500000': 'í’€íƒ€ì„ ì·¨ì—…ì (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU02600000': 'íŒŒíŠ¸íƒ€ì„ ì·¨ì—…ì (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU03000000': 'ì‹¤ì—…ììˆ˜ (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU03100000': 'í’€íƒ€ì„ êµ¬ì§ì (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU03200000': 'íŒŒíŠ¸íƒ€ì„ êµ¬ì§ì (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU04000000': 'ì‹¤ì—…ë¥  (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU04100000': 'í’€íƒ€ì„ ì‹¤ì—…ë¥  (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU04200000': 'íŒŒíŠ¸íƒ€ì„ ì‹¤ì—…ë¥  (ë¹„ê³„ì ˆì¡°ì •)',
    'LNU05000000': 'ë¹„ê²½ì œí™œë™ì¸êµ¬ (ë¹„ê³„ì ˆì¡°ì •)'
}

# CPS ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
CPS_CATEGORIES = {
    'í•µì‹¬ì§€í‘œ': {
        'ì£¼ìš” ì§€í‘œ': ['LNS14000000', 'LNS11300000', 'LNS12300000'],
        'ê³ ìš© í˜„í™©': ['LNS12000000', 'LNS13000000', 'LNS11000000'],
        'ê´‘ì˜ ì‹¤ì—…ë¥ ': ['LNS14000000', 'LNS13327709']
    },
    'ì¸êµ¬í†µê³„ë³„': {
        'ì—°ë ¹ë³„': ['LNS14000012', 'LNS14000025', 'LNS14000026'],
        'ì¸ì¢…ë³„': ['LNS14000003', 'LNS14000006', 'LNS14032183', 'LNS14000009'],
        'êµìœ¡ìˆ˜ì¤€ë³„': ['LNS14027659', 'LNS14027660', 'LNS14027689', 'LNS14027662']
    },
    'ì—°ë ¹ëŒ€ë³„ë¶„ì„': {
        '16ì„¸ì´ìƒì „ì²´': ['LNS11000000', 'LNS11300000', 'LNS12000000', 'LNS13000000', 'LNS14000000', 'LNS15000000'],
        '18ì„¸ì´ìƒ': ['LNU01076975', 'LNU01376975', 'LNU02076975', 'LNU03076975', 'LNU04076975', 'LNU05076975'],
        '20ì„¸ì´ìƒ': ['LNS11000024', 'LNS11300024', 'LNS12000024', 'LNS13000024', 'LNS14000024'],
        '25ì„¸ì´ìƒ': ['LNS11000048', 'LNS11300048', 'LNS12000048', 'LNS13000048', 'LNS14000048'],
        '25ì„¸ì´ìƒë¹„ê³„ì ˆì¡°ì •': ['LNU01000048', 'LNU01300048', 'LNU02000048', 'LNU03000048', 'LNU04000048'],
        '45ì„¸ì´ìƒ': ['LNU01000092', 'LNU01300092', 'LNU02000092', 'LNU03000092', 'LNU04000092', 'LNU05000092'],
        '55ì„¸ì´ìƒ': ['LNS11024230', 'LNS11324230', 'LNS12024230', 'LNS13024230', 'LNS14024230'],
        '55ì„¸ì´ìƒë¹„ê³„ì ˆì¡°ì •': ['LNU01024230', 'LNU01324230', 'LNU02024230', 'LNU03024230', 'LNU04024230', 'LNU05024230'],
        '65ì„¸ì´ìƒ': ['LNU01000097', 'LNU01300097', 'LNU02000097', 'LNU03000097', 'LNU04000097', 'LNU05000097']
    },
    'ì¸ì¢…ë³„ë¶„ì„': {
        'ë°±ì¸': ['LNS14000003', 'LNU01000003', 'LNU01300003', 'LNU02000003', 'LNU03000003', 'LNU04000003', 'LNU05000003'],
        'í‘ì¸': ['LNS14000006', 'LNU01000006', 'LNU01300006', 'LNU02000006', 'LNU03000006', 'LNU04000006', 'LNU05000006'],
        'ì•„ì‹œì•„ê³„': ['LNS14032183', 'LNU01032183', 'LNU01332183', 'LNU02032183', 'LNU03032183', 'LNU04032183', 'LNU05032183'],
        'ì•„ë©”ë¦¬ì¹´ì›ì£¼ë¯¼': ['LNU01035243', 'LNU01335243', 'LNU02035243', 'LNU03035243', 'LNU04035243', 'LNU05035243'],
        'í•˜ì™€ì´íƒœí‰ì–‘ì›ì£¼ë¯¼': ['LNU01035553', 'LNU01335553', 'LNU02035553', 'LNU03035553', 'LNU04035553', 'LNU05035553'],
        'íˆìŠ¤íŒ¨ë‹‰ë¼í‹°ë…¸': ['LNS14000009', 'LNS11000009', 'LNS11300009', 'LNS12000009', 'LNS13000009', 'LNS15000009']
    },
    'ê³„ì ˆì¡°ì •ë¹„êµ': {
        'ê²½ì œí™œë™ì¸êµ¬': ['LNS11000000', 'LNU01000000'],
        'ê²½ì œí™œë™ì°¸ê°€ìœ¨': ['LNS11300000', 'LNU01300000'],
        'ì·¨ì—…ììˆ˜': ['LNS12000000', 'LNU02000000'],
        'ì‹¤ì—…ììˆ˜': ['LNS13000000', 'LNU03000000'],
        'ì‹¤ì—…ë¥ ': ['LNS14000000', 'LNU04000000'],
        'ë¹„ê²½ì œí™œë™ì¸êµ¬': ['LNS15000000', 'LNU05000000']
    },
    'ì‹¤ì—…ë¶„ì„': {
        'ì‹¤ì—…ê¸°ê°„': ['LNS13008396', 'LNS13008756', 'LNS13008516', 'LNS13008636'],
        'ì‹¤ì—…ê¸°ê°„í†µê³„': ['LNS13008275', 'LNS13008276'],
        'ì‹¤ì—…ìœ í˜•': ['LNS13023621', 'LNS13023653', 'LNS13025699', 'LNS13023705']
    },
    'ê³ ìš©í˜•íƒœ': {
        'í’€íƒ€ì„/íŒŒíŠ¸íƒ€ì„': ['LNS12500000', 'LNS12600000', 'LNS12032194'],
        'ë³µìˆ˜ì§ì—…': ['LNS12026619', 'LNS12026620']
    },
    'ë…¸ë™ì‹œì¥ì°¸ì—¬': {
        'ë¹„ê²½ì œí™œë™': ['LNS15000000', 'LNS15026642', 'LNS15026645'],
        'ì§„ì…/ì´íƒˆ': ['LNS13023557', 'LNS13023569']
    }
}

# %%
# === ì „ì—­ ë°ì´í„° ì €ì¥ì†Œ ===

# API ì„¤ì •
BLS_SESSION = None
API_INITIALIZED = False

# ì „ì—­ ë°ì´í„° ì €ì¥ì†Œ
CPS_DATA = {
    'raw_data': pd.DataFrame(),      # ì›ë³¸ ë ˆë²¨ ë°ì´í„°
    'mom_data': pd.DataFrame(),      # ì „ì›”ëŒ€ë¹„ ë³€í™” ë°ì´í„°
    'yoy_data': pd.DataFrame(),      # ì „ë…„ë™ì›”ëŒ€ë¹„ ë³€í™” ë°ì´í„°
    'latest_values': {},             # ìµœì‹  ê°’ë“¤
    'load_info': {
        'loaded': False,
        'load_time': None,
        'start_date': None,
        'series_count': 0,
        'data_points': 0
    }
}

# %%
# === API ì´ˆê¸°í™” ë° ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ë“¤ ===

def initialize_bls_api():
    """BLS API ì„¸ì…˜ ì´ˆê¸°í™”"""
    global BLS_SESSION
    
    if not BLS_API_AVAILABLE:
        print("âš ï¸ BLS API ì‚¬ìš© ë¶ˆê°€ (requests ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ)")
        return False
    
    try:
        BLS_SESSION = requests.Session()
        print("âœ“ BLS API ì„¸ì…˜ ì´ˆê¸°í™” ì„±ê³µ")
        return True
    except Exception as e:
        print(f"âš ï¸ BLS API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def switch_api_key():
    """API í‚¤ë¥¼ ì „í™˜í•˜ëŠ” í•¨ìˆ˜"""
    global CURRENT_API_KEY
    if CURRENT_API_KEY == BLS_API_KEY:
        CURRENT_API_KEY = BLS_API_KEY2
        print("ğŸ”„ BLS API í‚¤ë¥¼ BLS_API_KEY2ë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.")
    elif CURRENT_API_KEY == BLS_API_KEY2:
        CURRENT_API_KEY = BLS_API_KEY3
        print("ğŸ”„ BLS API í‚¤ë¥¼ BLS_API_KEY3ë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.")
    else:
        CURRENT_API_KEY = BLS_API_KEY
        print("ğŸ”„ BLS API í‚¤ë¥¼ BLS_API_KEYë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.")

def get_bls_data(series_id, start_year=2020, end_year=None):
    """
    BLS APIì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (API í‚¤ ì´ì¤‘í™” ì§€ì›)
    
    Args:
        series_id: BLS ì‹œë¦¬ì¦ˆ ID
        start_year: ì‹œì‘ ì—°ë„
        end_year: ì¢…ë£Œ ì—°ë„ (Noneì´ë©´ í˜„ì¬ ì—°ë„)
    
    Returns:
        pandas.Series: ë‚ ì§œë¥¼ ì¸ë±ìŠ¤ë¡œ í•˜ëŠ” ì‹œë¦¬ì¦ˆ ë°ì´í„°
    """
    global CURRENT_API_KEY
    
    if not BLS_API_AVAILABLE or BLS_SESSION is None:
        print(f"âŒ BLS API ì‚¬ìš© ë¶ˆê°€ - {series_id}")
        return None
    
    if end_year is None:
        end_year = datetime.datetime.now().year
    
    # BLS API ìš”ì²­ ë°ì´í„°
    data = {
        'seriesid': [series_id],
        'startyear': str(start_year),
        'endyear': str(end_year),
        'catalog': False,
        'calculations': False,
        'annualaverage': False
    }
    
    # í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ API í‚¤ ì¶”ê°€
    if CURRENT_API_KEY:
        data['registrationkey'] = CURRENT_API_KEY
    
    url = 'https://api.bls.gov/publicAPI/v2/timeseries/data/'
    headers = {'Content-type': 'application/json'}
    
    try:
        current_key_name = "ì£¼ìš”" if CURRENT_API_KEY == BLS_API_KEY else "ë°±ì—…"
        print(f"ğŸ“Š BLSì—ì„œ ë¡œë”© ({current_key_name}): {series_id}")
        response = BLS_SESSION.post(url, data=json.dumps(data), headers=headers, timeout=30)
        response.raise_for_status()
        
        json_data = response.json()
        
        if json_data.get('status') == 'REQUEST_SUCCEEDED':
            series_data = json_data['Results']['series'][0]['data']
            
            # ë°ì´í„° ì •ë¦¬
            dates = []
            values = []
            
            for item in series_data:
                try:
                    year = int(item['year'])
                    period = item['period']
                    if period.startswith('M'):
                        month = int(period[1:])
                        date = pd.Timestamp(year, month, 1)
                        value = float(item['value'])
                        
                        dates.append(date)
                        values.append(value)
                except (ValueError, KeyError):
                    continue
            
            if dates and values:
                # ë‚ ì§œìˆœ ì •ë ¬
                df = pd.DataFrame({'date': dates, 'value': values})
                df = df.sort_values('date')
                series = pd.Series(df['value'].values, index=df['date'], name=series_id)
                
                print(f"âœ“ BLS ì„±ê³µ: {series_id} ({len(series)}ê°œ í¬ì¸íŠ¸)")
                return series
            else:
                print(f"âŒ BLS ë°ì´í„° ì—†ìŒ: {series_id}")
                return None
        else:
            error_msg = json_data.get('message', 'Unknown error')
            print(f"âš ï¸ BLS API ì˜¤ë¥˜: {error_msg}")
            
            # Daily threshold ì´ˆê³¼ì¸ ê²½ìš° API í‚¤ ì „í™˜ ì‹œë„
            if 'daily threshold' in error_msg.lower() or 'daily quota' in error_msg.lower():
                print("ğŸ“ˆ Daily threshold ì´ˆê³¼ ê°ì§€ - API í‚¤ ì „í™˜ ì‹œë„")
                switch_api_key()
                
                # ìƒˆë¡œìš´ API í‚¤ë¡œ ì¬ì‹œë„
                data['registrationkey'] = CURRENT_API_KEY
                try:
                    print(f"ğŸ”„ ìƒˆ API í‚¤ë¡œ ì¬ì‹œë„: {series_id}")
                    response = BLS_SESSION.post(url, data=json.dumps(data), headers=headers, timeout=30)
                    response.raise_for_status()
                    
                    json_data = response.json()
                    if json_data.get('status') == 'REQUEST_SUCCEEDED':
                        series_data = json_data['Results']['series'][0]['data']
                        
                        dates = []
                        values = []
                        
                        for item in series_data:
                            try:
                                year = int(item['year'])
                                period = item['period']
                                if period.startswith('M'):
                                    month = int(period[1:])
                                    date = pd.Timestamp(year, month, 1)
                                    value = float(item['value'])
                                    
                                    dates.append(date)
                                    values.append(value)
                            except (ValueError, KeyError):
                                continue
                        
                        if dates and values:
                            df = pd.DataFrame({'date': dates, 'value': values})
                            df = df.sort_values('date')
                            series = pd.Series(df['value'].values, index=df['date'], name=series_id)
                            
                            print(f"âœ… ë°±ì—… API í‚¤ë¡œ ì„±ê³µ: {series_id} ({len(series)}ê°œ í¬ì¸íŠ¸)")
                            return series
                    
                    print(f"âŒ ë°±ì—… API í‚¤ë¡œë„ ì‹¤íŒ¨: {series_id}")
                    return None
                except Exception as e:
                    print(f"âŒ ë°±ì—… API í‚¤ ìš”ì²­ ì‹¤íŒ¨: {series_id} - {e}")
                    return None
            else:
                return None
            
    except Exception as e:
        print(f"âŒ BLS ìš”ì²­ ì‹¤íŒ¨: {series_id} - {e}")
        return None

# %%
# === ë°ì´í„° ê³„ì‚° ë° ë¡œë“œ í•¨ìˆ˜ë“¤ ===

def calculate_mom_change(data):
    """ì „ì›”ëŒ€ë¹„ ë³€í™” ê³„ì‚° (ë ˆë²¨ ë°ì´í„°ëŠ” ì°¨ì´, ë¹„ìœ¨ ë°ì´í„°ëŠ” ì°¨ì´)"""
    if data.name and ('Rate' in data.name or 'Ratio' in data.name or data.name.startswith('LNS14')):
        # ë¹„ìœ¨ ë°ì´í„°ëŠ” ì°¨ì´ ê³„ì‚°
        return data.diff()
    else:
        # ë ˆë²¨ ë°ì´í„°ëŠ” ë³€í™”ìœ¨ ê³„ì‚°
        return ((data / data.shift(1)) - 1) * 100

def calculate_yoy_change(data):
    """ì „ë…„ë™ì›”ëŒ€ë¹„ ë³€í™” ê³„ì‚°"""
    if data.name and ('Rate' in data.name or 'Ratio' in data.name or data.name.startswith('LNS14')):
        # ë¹„ìœ¨ ë°ì´í„°ëŠ” ì°¨ì´ ê³„ì‚°
        return data - data.shift(12)
    else:
        # ë ˆë²¨ ë°ì´í„°ëŠ” ë³€í™”ìœ¨ ê³„ì‚°
        return ((data / data.shift(12)) - 1) * 100

def get_series_data(series_id, start_date='2020-01-01', end_date=None, min_points=12, is_update=False):
    """BLS APIë¥¼ ì‚¬ìš©í•œ ê°œë³„ ì‹œë¦¬ì¦ˆ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    if not BLS_SESSION:
        print(f"âŒ BLS ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ: {series_id}")
        return None
    
    try:
        start_year = pd.to_datetime(start_date).year
        end_year = pd.to_datetime(end_date).year if end_date else None
        data = get_bls_data(series_id, start_year, end_year)
        
        if data is None or len(data) == 0:
            print(f"âŒ ë°ì´í„° ì—†ìŒ: {series_id}")
            return None
        
        # ë‚ ì§œ í•„í„°ë§
        if start_date:
            data = data[data.index >= start_date]
        if end_date:
            data = data[data.index <= end_date]
        
        # NaN ì œê±°
        data = data.dropna()
        
        # ì—…ë°ì´íŠ¸ ëª¨ë“œì¼ ë•ŒëŠ” ìµœì†Œ ë°ì´í„° í¬ì¸íŠ¸ ìš”êµ¬ëŸ‰ì„ ë‚®ì¶¤
        if is_update:
            min_required = 1  # ì—…ë°ì´íŠ¸ ì‹œì—ëŠ” 1ê°œ í¬ì¸íŠ¸ë§Œ ìˆì–´ë„ í—ˆìš©
        else:
            min_required = min_points
        
        if len(data) < min_required:
            print(f"âŒ ë°ì´í„° ë¶€ì¡±: {series_id} ({len(data)}ê°œ)")
            return None
        
        print(f"âœ“ ì„±ê³µ: {series_id} ({len(data)}ê°œ í¬ì¸íŠ¸)")
        return data
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {series_id} - {e}")
        return None

# %%
# === CSV ì €ì¥/ë¡œë“œ í•¨ìˆ˜ë“¤ ===

def save_cps_data_to_csv(file_path='/home/jyp0615/us_eco/cps_data.csv'):
    """
    í˜„ì¬ ë¡œë“œëœ CPS ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
    
    Args:
        file_path: ì €ì¥í•  CSV íŒŒì¼ ê²½ë¡œ
    """
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return False
    
    try:
        # raw_dataì™€ ë©”íƒ€ë°ì´í„°ë¥¼ í•¨ê»˜ ì €ì¥
        raw_data = CPS_DATA['raw_data']
        
        # ì €ì¥í•  ë°ì´í„° ì¤€ë¹„
        save_data = {
            'timestamp': raw_data.index.tolist(),
            **{col: raw_data[col].tolist() for col in raw_data.columns}
        }
        
        # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
        save_df = pd.DataFrame(save_data)
        save_df.to_csv(file_path, index=False, encoding='utf-8')
        
        # ë©”íƒ€ë°ì´í„°ë„ ë³„ë„ ì €ì¥
        meta_file = file_path.replace('.csv', '_meta.json')
        import json
        with open(meta_file, 'w', encoding='utf-8') as f:
            meta_data = {
                'load_time': CPS_DATA['load_info']['load_time'].isoformat() if CPS_DATA['load_info']['load_time'] else None,
                'start_date': CPS_DATA['load_info']['start_date'],
                'series_count': CPS_DATA['load_info']['series_count'],
                'data_points': CPS_DATA['load_info']['data_points'],
                'latest_values': CPS_DATA['latest_values']
            }
            json.dump(meta_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… CPS ë°ì´í„° ì €ì¥ ì™„ë£Œ: {file_path}")
        print(f"âœ… ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {meta_file}")
        return True
        
    except Exception as e:
        print(f"âŒ CSV ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def load_cps_data_from_csv(file_path='/home/jyp0615/us_eco/cps_data.csv'):
    """
    CSV íŒŒì¼ì—ì„œ CPS ë°ì´í„° ë¡œë“œ
    
    Args:
        file_path: ë¡œë“œí•  CSV íŒŒì¼ ê²½ë¡œ
    
    Returns:
        bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
    """
    global CPS_DATA
    
    import os
    if not os.path.exists(file_path):
        print(f"âš ï¸ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return False
    
    try:
        # CSV ë°ì´í„° ë¡œë“œ
        df = pd.read_csv(file_path, encoding='utf-8')
        
        # timestamp ì»¬ëŸ¼ì„ ë‚ ì§œ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df.set_index('timestamp', inplace=True)
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        meta_file = file_path.replace('.csv', '_meta.json')
        latest_values = {}
        if os.path.exists(meta_file):
            import json
            with open(meta_file, 'r', encoding='utf-8') as f:
                meta_data = json.load(f)
                latest_values = meta_data.get('latest_values', {})
        
        # ì „ì—­ ì €ì¥ì†Œì— ì €ì¥
        CPS_DATA['raw_data'] = df
        CPS_DATA['mom_data'] = df.apply(calculate_mom_change)
        CPS_DATA['yoy_data'] = df.apply(calculate_yoy_change)
        CPS_DATA['latest_values'] = latest_values
        CPS_DATA['load_info'] = {
            'loaded': True,
            'load_time': datetime.datetime.now(),
            'start_date': df.index[0].strftime('%Y-%m-%d') if len(df) > 0 else None,
            'series_count': len(df.columns),
            'data_points': len(df)
        }
        
        print(f"âœ… CSVì—ì„œ CPS ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {file_path}")
        print_load_info()
        return True
        
    except Exception as e:
        print(f"âŒ CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

# %%
# === ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ í•¨ìˆ˜ë“¤ ===

def check_recent_data_consistency(series_list=None, check_count=3):
    """
    ìµœê·¼ Nê°œ ë°ì´í„°ì˜ ì¼ì¹˜ì„±ì„ í™•ì¸í•˜ëŠ” í•¨ìˆ˜ (ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸)
    
    Args:
        series_list: í™•ì¸í•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ì£¼ìš” ì‹œë¦¬ì¦ˆë§Œ)
        check_count: í™•ì¸í•  ìµœê·¼ ë°ì´í„° ê°œìˆ˜
    
    Returns:
        dict: ì¼ì¹˜ì„± í™•ì¸ ê²°ê³¼ (need_update, reason, mismatches)
    """
    if not CPS_DATA['load_info']['loaded']:
        return {'need_update': True, 'reason': 'ê¸°ì¡´ ë°ì´í„° ì—†ìŒ'}
    
    if series_list is None:
        # ì£¼ìš” ì‹œë¦¬ì¦ˆë§Œ ì²´í¬ (ì†ë„ í–¥ìƒ)
        series_list = ['LNS14000000', 'LNS11300000', 'LNS12300000', 'LNS13327709']
    
    # BLS API ì´ˆê¸°í™”
    if not initialize_bls_api():
        return {'need_update': True, 'reason': 'API ì´ˆê¸°í™” ì‹¤íŒ¨'}
    
    print(f"ğŸ“Š ìµœê·¼ {check_count}ê°œ ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸ ì¤‘...")
    
    mismatches = []
    new_data_available = False
    
    for series_id in series_list:
        if series_id not in CPS_DATA['raw_data'].columns:
            continue
        
        existing_data = CPS_DATA['raw_data'][series_id]
        
        # ìµœê·¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        current_year = datetime.datetime.now().year
        api_data = get_bls_data(series_id, current_year - 1, current_year)
        
        if api_data is None or len(api_data) == 0:
            mismatches.append({
                'series': series_id,
                'reason': 'API ë°ì´í„° ì—†ìŒ'
            })
            continue
        
        # ë¨¼ì € ìƒˆë¡œìš´ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        latest_existing = existing_data.index[-1]
        latest_api = api_data.index[-1]
        
        if latest_api > latest_existing:
            new_data_available = True
            mismatches.append({
                'series': series_id,
                'reason': 'ìƒˆë¡œìš´ ë°ì´í„° ì¡´ì¬',
                'existing_latest': latest_existing,
                'api_latest': latest_api
            })
            continue  # ìƒˆ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë‹¤ë¥¸ ì²´í¬ëŠ” ê±´ë„ˆëœ€
        
        # ìµœê·¼ Nê°œ ë°ì´í„° ë¹„êµ (ìƒˆ ë°ì´í„°ê°€ ì—†ì„ ë•Œë§Œ)
        existing_recent = existing_data.tail(check_count)
        api_recent = api_data.tail(check_count)
        
        # ë‚ ì§œì™€ ê°’ ëª¨ë‘ ë¹„êµ
        for date in existing_recent.index[-check_count:]:
            if date in api_recent.index:
                existing_val = existing_recent.loc[date]
                api_val = api_recent.loc[date]
                
                # ê°’ì´ ë‹¤ë¥´ë©´ ë¶ˆì¼ì¹˜
                if abs(existing_val - api_val) > 0.01:  # 0.01 ì´ìƒ ì°¨ì´
                    mismatches.append({
                        'series': series_id,
                        'date': date,
                        'existing': existing_val,
                        'api': api_val,
                        'diff': abs(existing_val - api_val)
                    })
            else:
                mismatches.append({
                    'series': series_id,
                    'date': date,
                    'existing': existing_recent.loc[date],
                    'api': None,
                    'reason': 'ë‚ ì§œ ì—†ìŒ'
                })
    
    # ê²°ê³¼ íŒì • ë¡œì§ ê°œì„ 
    if new_data_available:
        print(f"ğŸ†• ìƒˆë¡œìš´ ë°ì´í„° ê°ì§€: ì—…ë°ì´íŠ¸ í•„ìš”")
        for mismatch in mismatches[:3]:
            if 'reason' in mismatch and mismatch['reason'] == 'ìƒˆë¡œìš´ ë°ì´í„° ì¡´ì¬':
                print(f"   - {mismatch['series']}: {mismatch['existing_latest']} â†’ {mismatch['api_latest']}")
        return {'need_update': True, 'reason': 'ìƒˆë¡œìš´ ë°ì´í„°', 'mismatches': mismatches}
    elif any(m for m in mismatches if m.get('reason') != 'ìƒˆë¡œìš´ ë°ì´í„° ì¡´ì¬'):
        # ê°’ ë¶ˆì¼ì¹˜ê°€ ìˆëŠ” ê²½ìš°
        value_mismatches = [m for m in mismatches if m.get('reason') != 'ìƒˆë¡œìš´ ë°ì´í„° ì¡´ì¬']
        print(f"âš ï¸ ë°ì´í„° ë¶ˆì¼ì¹˜ ë°œê²¬: {len(value_mismatches)}ê°œ")
        for mismatch in value_mismatches[:3]:
            print(f"   - {mismatch}")
        return {'need_update': True, 'reason': 'ë°ì´í„° ë¶ˆì¼ì¹˜', 'mismatches': mismatches}
    else:
        print("âœ… ìµœê·¼ ë°ì´í„°ê°€ ì™„ì „íˆ ì¼ì¹˜í•©ë‹ˆë‹¤. ì—…ë°ì´íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return {'need_update': False, 'reason': 'ë°ì´í„° ì¼ì¹˜'}

def update_cps_data_from_api(start_date=None, series_list=None, smart_update=True):
    """
    APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸ (ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì§€ì›)
    
    Args:
        start_date: ì—…ë°ì´íŠ¸ ì‹œì‘ ë‚ ì§œ (Noneì´ë©´ ë§ˆì§€ë§‰ ë°ì´í„° ì´í›„ë¶€í„°)
        series_list: ì—…ë°ì´íŠ¸í•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  ì‹œë¦¬ì¦ˆ)
        smart_update: ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì‚¬ìš© ì—¬ë¶€ (ìµœê·¼ 3ê°œ ë°ì´í„° ë¹„êµ)
    
    Returns:
        bool: ì—…ë°ì´íŠ¸ ì„±ê³µ ì—¬ë¶€
    """
    global CPS_DATA
    
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ê¸°ì¡´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ë¡œë“œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
        return load_all_cps_data()
    
    # ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ í™œì„±í™”ì‹œ ìµœê·¼ ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸
    if smart_update:
        consistency_check = check_recent_data_consistency()
        
        # ì—…ë°ì´íŠ¸ í•„ìš” ì—†ìœ¼ë©´ ë°”ë¡œ ì¢…ë£Œ
        if not consistency_check['need_update']:
            print("ğŸ¯ ë°ì´í„°ê°€ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤. API í˜¸ì¶œì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return True
        
        # ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•œ ê²½ìš° ì²˜ë¦¬
        if consistency_check['reason'] == 'ë°ì´í„° ë¶ˆì¼ì¹˜':
            print("âš ï¸ ìµœê·¼ 3ê°œ ë°ì´í„° ë¶ˆì¼ì¹˜ë¡œ ì¸í•œ ì „ì²´ ì¬ë¡œë“œ")
            # ìµœê·¼ 3ê°œì›” ë°ì´í„°ë¶€í„° ë‹¤ì‹œ ë¡œë“œ
            last_date = CPS_DATA['raw_data'].index[-1]
            start_date = (last_date - pd.DateOffset(months=3)).strftime('%Y-%m-01')
        elif consistency_check['reason'] == 'ê¸°ì¡´ ë°ì´í„° ì—†ìŒ':
            # ì „ì²´ ì¬ë¡œë“œ
            return load_all_cps_data(force_reload=True)
        else:
            print(f"ğŸ”„ ì—…ë°ì´íŠ¸ ì§„í–‰: {consistency_check['reason']}")
    
    # BLS API ì´ˆê¸°í™”
    if not initialize_bls_api():
        print("âŒ BLS API ì´ˆê¸°í™” ì‹¤íŒ¨")
        return False
    
    # ì—…ë°ì´íŠ¸ ì‹œì‘ ë‚ ì§œ ê²°ì •
    if start_date is None:
        last_date = CPS_DATA['raw_data'].index[-1]
        # ë§ˆì§€ë§‰ ë‚ ì§œì˜ ë‹¤ìŒ ë‹¬ë¶€í„° ì—…ë°ì´íŠ¸
        start_date = (last_date + pd.DateOffset(months=1)).strftime('%Y-%m-01')
    
    print(f"ğŸ”„ CPS ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ ({start_date}ë¶€í„°)")
    print("="*50)
    
    if series_list is None:
        series_list = list(CPS_SERIES.keys())
    
    updated_data = {}
    new_count = 0
    
    for series_id in series_list:
        if series_id not in CPS_SERIES:
            continue
        
        # ìƒˆë¡œìš´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        start_year = pd.to_datetime(start_date).year
        new_data = get_bls_data(series_id, start_year)
        
        if new_data is not None and len(new_data) > 0:
            # ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©
            if series_id in CPS_DATA['raw_data'].columns:
                existing_data = CPS_DATA['raw_data'][series_id]
                original_count = existing_data.notna().sum()
                
                # ê°œì„ ëœ ë³‘í•© ë°©ì‹: ì¸ë±ìŠ¤ ë¨¼ì € í™•ì¥ í›„ ê°’ í• ë‹¹
                all_dates = existing_data.index.union(new_data.index).sort_values()
                combined_data = existing_data.reindex(all_dates)
                
                # ìƒˆ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ê°’ ë®ì–´ì“°ê¸°)
                for date, value in new_data.items():
                    combined_data.loc[date] = value
                
                updated_data[series_id] = combined_data
                
                # ì‹¤ì œ ì¶”ê°€ëœ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ ê³„ì‚°
                final_count = combined_data.notna().sum()
                new_points = final_count - original_count
                new_count += new_points
                
                if new_points > 0:
                    print(f"âœ… ì—…ë°ì´íŠ¸: {series_id} (ê¸°ì¡´ {original_count}ê°œ + ì‹ ê·œ {len(new_data)}ê°œ â†’ ì´ {final_count}ê°œ, ì‹¤ì œ ì¶”ê°€: {new_points}ê°œ)")
                else:
                    print(f"â„¹ï¸  ìµœì‹  ìƒíƒœ: {series_id}")
            else:
                updated_data[series_id] = new_data
                new_count += len(new_data)
                print(f"âœ… ì‹ ê·œ ì¶”ê°€: {series_id} ({len(new_data)}ê°œ í¬ì¸íŠ¸)")
    
    if updated_data:
        # ì „ì—­ ì €ì¥ì†Œ ì—…ë°ì´íŠ¸
        updated_df = pd.DataFrame(updated_data)
        CPS_DATA['raw_data'] = updated_df
        CPS_DATA['mom_data'] = updated_df.apply(calculate_mom_change)
        CPS_DATA['yoy_data'] = updated_df.apply(calculate_yoy_change)
        
        # ìµœì‹  ê°’ ì—…ë°ì´íŠ¸
        for series_id in updated_data.keys():
            if series_id in CPS_DATA['raw_data'].columns:
                raw_data = CPS_DATA['raw_data'][series_id].dropna()
                if len(raw_data) > 0:
                    CPS_DATA['latest_values'][series_id] = raw_data.iloc[-1]
        
        # ë¡œë“œ ì •ë³´ ì—…ë°ì´íŠ¸
        CPS_DATA['load_info']['load_time'] = datetime.datetime.now()
        CPS_DATA['load_info']['series_count'] = len(updated_df.columns)
        CPS_DATA['load_info']['data_points'] = len(updated_df)
        
        print(f"\nâœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ! ìƒˆë¡œ ì¶”ê°€ëœ ë°ì´í„°: {new_count}ê°œ í¬ì¸íŠ¸")
        print_load_info()
        
        # ìë™ìœ¼ë¡œ CSVì— ì €ì¥
        save_cps_data_to_csv()
        
        return True
    else:
        print("\nâš ï¸ ì—…ë°ì´íŠ¸í•  ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False

# %%
# === ë©”ì¸ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ===

def load_all_cps_data(start_date='2020-01-01', series_list=None, force_reload=False, csv_file='/home/jyp0615/us_eco/cps_data.csv'):
    """
    CPS ë°ì´í„° ë¡œë“œ (CSV ìš°ì„ , API ë°±ì—… ë°©ì‹)
    
    Args:
        start_date: ì‹œì‘ ë‚ ì§œ
        series_list: ë¡œë“œí•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  ì‹œë¦¬ì¦ˆ)
        force_reload: ê°•ì œ ì¬ë¡œë“œ ì—¬ë¶€
        csv_file: CSV íŒŒì¼ ê²½ë¡œ
    
    Returns:
        bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
    """
    global CPS_DATA
    
    # ì´ë¯¸ ë¡œë“œëœ ê²½ìš° ìŠ¤í‚µ
    if CPS_DATA['load_info']['loaded'] and not force_reload:
        print("ğŸ’¾ ì´ë¯¸ ë¡œë“œëœ ë°ì´í„° ì‚¬ìš© ì¤‘")
        print_load_info()
        return True
    
    # CSV íŒŒì¼ì´ ìˆìœ¼ë©´ ìš°ì„  ë¡œë“œ ì‹œë„
    import os
    if not force_reload and os.path.exists(csv_file):
        print("ğŸ“‚ ê¸°ì¡´ CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ ì‹œë„...")
        if load_cps_data_from_csv(csv_file):
            print("ğŸ”„ CSV ë¡œë“œ í›„ ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì‹œë„...")
            # CSV ë¡œë“œ ì„±ê³µ í›„ ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸
            update_cps_data_from_api(smart_update=True)
            return True
        else:
            print("âš ï¸ CSV ë¡œë“œ ì‹¤íŒ¨, APIì—ì„œ ì „ì²´ ë¡œë“œ ì‹œë„...")
    
    print("ğŸš€ CPS ë°ì´í„° ë¡œë”© ì‹œì‘... (BLS API ì „ìš©)")
    print("="*50)
    
    # BLS API ì´ˆê¸°í™”
    if not initialize_bls_api():
        print("âŒ BLS API ì´ˆê¸°í™” ì‹¤íŒ¨")
        return False
    
    if series_list is None:
        series_list = list(CPS_SERIES.keys())
    
    # ë°ì´í„° ìˆ˜ì§‘
    raw_data_dict = {}
    mom_data_dict = {}
    yoy_data_dict = {}
    latest_values = {}
    
    for series_id in series_list:
        if series_id not in CPS_SERIES:
            print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì‹œë¦¬ì¦ˆ: {series_id}")
            continue
        
        # ì›ë³¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        series_data = get_series_data(series_id, start_date)
        
        if series_data is not None and len(series_data) > 0:
            # ì›ë³¸ ë°ì´í„° ì €ì¥
            raw_data_dict[series_id] = series_data
            
            # MoM ê³„ì‚°
            mom_data = calculate_mom_change(series_data)
            mom_data_dict[series_id] = mom_data
            
            # YoY ê³„ì‚°
            yoy_data = calculate_yoy_change(series_data)
            yoy_data_dict[series_id] = yoy_data
            
            # ìµœì‹  ê°’ ì €ì¥
            if len(series_data.dropna()) > 0:
                latest_value = series_data.dropna().iloc[-1]
                latest_values[series_id] = latest_value
            else:
                print(f"âš ï¸ ë°ì´í„° ì—†ìŒ: {series_id}")
        else:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {series_id}")
    
    # ë¡œë“œëœ ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì˜¤ë¥˜ ë°œìƒ
    if len(raw_data_dict) < 5:  # ìµœì†Œ 5ê°œ ì‹œë¦¬ì¦ˆëŠ” ìˆì–´ì•¼ í•¨
        error_msg = f"âŒ ë¡œë“œëœ ì‹œë¦¬ì¦ˆê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤: {len(raw_data_dict)}ê°œ (ìµœì†Œ 5ê°œ í•„ìš”)"
        print(error_msg)
        raise ValueError(error_msg)
    
    # ì „ì—­ ì €ì¥ì†Œì— ì €ì¥
    CPS_DATA['raw_data'] = pd.DataFrame(raw_data_dict)
    CPS_DATA['mom_data'] = pd.DataFrame(mom_data_dict)
    CPS_DATA['yoy_data'] = pd.DataFrame(yoy_data_dict)
    CPS_DATA['latest_values'] = latest_values
    CPS_DATA['load_info'] = {
        'loaded': True,
        'load_time': datetime.datetime.now(),
        'start_date': start_date,
        'series_count': len(raw_data_dict),
        'data_points': len(CPS_DATA['raw_data']) if not CPS_DATA['raw_data'].empty else 0
    }
    
    print("\nâœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
    print_load_info()
    
    # ìë™ìœ¼ë¡œ CSVì— ì €ì¥
    save_cps_data_to_csv(csv_file)
    
    return True

def print_load_info():
    """ë¡œë“œ ì •ë³´ ì¶œë ¥"""
    info = CPS_DATA['load_info']
    if not info['loaded']:
        print("âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ")
        return
    
    print(f"ğŸ“Š ë¡œë“œëœ ë°ì´í„° ì •ë³´:")
    print(f"   ì‹œë¦¬ì¦ˆ ê°œìˆ˜: {info['series_count']}")
    print(f"   ë°ì´í„° í¬ì¸íŠ¸: {info['data_points']}")
    print(f"   ì‹œì‘ ë‚ ì§œ: {info['start_date']}")
    print(f"   ë¡œë“œ ì‹œê°„: {info['load_time'].strftime('%Y-%m-%d %H:%M:%S')}")
    
    if not CPS_DATA['raw_data'].empty:
        date_range = f"{CPS_DATA['raw_data'].index[0].strftime('%Y-%m')} ~ {CPS_DATA['raw_data'].index[-1].strftime('%Y-%m')}"
        print(f"   ë°ì´í„° ê¸°ê°„: {date_range}")

def clear_data():
    """ë°ì´í„° ì´ˆê¸°í™”"""
    global CPS_DATA
    CPS_DATA = {
        'raw_data': pd.DataFrame(),
        'mom_data': pd.DataFrame(),
        'yoy_data': pd.DataFrame(),
        'latest_values': {},
        'load_info': {'loaded': False, 'load_time': None, 'start_date': None, 'series_count': 0, 'data_points': 0}
    }
    print("ğŸ—‘ï¸ ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤")

# %%
# === ë°ì´í„° ì ‘ê·¼ í•¨ìˆ˜ë“¤ ===

def get_raw_data(series_names=None):
    """ì›ë³¸ ë ˆë²¨ ë°ì´í„° ë°˜í™˜"""
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_cps_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return pd.DataFrame()
    
    if series_names is None:
        return CPS_DATA['raw_data'].copy()
    
    available_series = [s for s in series_names if s in CPS_DATA['raw_data'].columns]
    if not available_series:
        print(f"âš ï¸ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤: {series_names}")
        return pd.DataFrame()
    
    return CPS_DATA['raw_data'][available_series].copy()

def get_mom_data(series_names=None):
    """ì „ì›”ëŒ€ë¹„ ë³€í™” ë°ì´í„° ë°˜í™˜"""
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_cps_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return pd.DataFrame()
    
    if series_names is None:
        return CPS_DATA['mom_data'].copy()
    
    available_series = [s for s in series_names if s in CPS_DATA['mom_data'].columns]
    if not available_series:
        print(f"âš ï¸ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤: {series_names}")
        return pd.DataFrame()
    
    return CPS_DATA['mom_data'][available_series].copy()

def get_yoy_data(series_names=None):
    """ì „ë…„ë™ì›”ëŒ€ë¹„ ë³€í™” ë°ì´í„° ë°˜í™˜"""
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_cps_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return pd.DataFrame()
    
    if series_names is None:
        return CPS_DATA['yoy_data'].copy()
    
    available_series = [s for s in series_names if s in CPS_DATA['yoy_data'].columns]
    if not available_series:
        print(f"âš ï¸ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤: {series_names}")
        return pd.DataFrame()
    
    return CPS_DATA['yoy_data'][available_series].copy()

def get_latest_values(series_names=None):
    """ìµœì‹  ê°’ë“¤ ë°˜í™˜"""
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_cps_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return {}
    
    if series_names is None:
        return CPS_DATA['latest_values'].copy()
    
    return {name: CPS_DATA['latest_values'].get(name, 0) for name in series_names if name in CPS_DATA['latest_values']}

def list_available_series():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œë¦¬ì¦ˆ ëª©ë¡ ë°˜í™˜"""
    if not CPS_DATA['load_info']['loaded']:
        return []
    return list(CPS_DATA['raw_data'].columns)

# %%
# === KPDS ìŠ¤íƒ€ì¼ ì‹œê°í™” í•¨ìˆ˜ë“¤ ===

def create_labor_market_dashboard():
    """
    ì£¼ìš” ë…¸ë™ì‹œì¥ ì§€í‘œ ëŒ€ì‹œë³´ë“œ ìƒì„± (KPDS í¬ë§·)
    
    Returns:
        plotly figure
    """
    print("US Labor Market Dashboard")
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_cps_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ë°ì´í„° ì¤€ë¹„
    data_dict = {
        'LNS14000000': 'ì‹¤ì—…ë¥ ',
        'LNS11300000': 'ê²½ì œí™œë™ì°¸ê°€ìœ¨', 
        'LNS12300000': 'ê³ ìš©ë¥ ',
        'LNS13327709': 'U-6 ì‹¤ì—…ë¥ '
    }
    
    df = get_raw_data(list(data_dict.keys()))
    df = df.rename(columns=data_dict)
    
    # KPDS ë‹¤ì¤‘ ë¼ì¸ ì°¨íŠ¸ë¡œ ìƒì„±
    return df_multi_line_chart(
        df=df,
        ytitle="%"
    )

def create_unemployment_by_demographics(demographic_type='race'):
    """
    ì¸êµ¬í†µê³„ë³„ ì‹¤ì—…ë¥  ë¹„êµ ì°¨íŠ¸ (KPDS í¬ë§·)
    
    Args:
        demographic_type: 'race', 'age', 'education'
    
    Returns:
        plotly figure
    """
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_cps_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    if demographic_type == 'race':
        series_dict = {
            'LNS14000003': 'ë°±ì¸', 
            'LNS14000006': 'í‘ì¸',
            'LNS14032183': 'ì•„ì‹œì•„ê³„', 
            'LNS14000009': 'íˆìŠ¤íŒ¨ë‹‰'
        }
        print_title = "ì‹¤ì—…ë¥  - ì¸ì¢…ë³„"
    elif demographic_type == 'age':
        series_dict = {
            'LNS14000012': '16-19ì„¸',
            'LNS14000025': '20ì„¸+ ë‚¨ì„±', 
            'LNS14000026': '20ì„¸+ ì—¬ì„±'
        }
        print_title = "ì‹¤ì—…ë¥  - ì—°ë ¹/ì„±ë³„"
    elif demographic_type == 'education':
        series_dict = {
            'LNS14027659': 'ê³ ì¡¸ ë¯¸ë§Œ',
            'LNS14027660': 'ê³ ì¡¸', 
            'LNS14027689': 'ëŒ€í•™ ì¤‘í‡´/ì „ë¬¸ëŒ€',
            'LNS14027662': 'ëŒ€ì¡¸ ì´ìƒ'
        }
        print_title = "ì‹¤ì—…ë¥  - êµìœ¡ìˆ˜ì¤€ë³„"
    else:
        print(f"âš ï¸ ì˜ëª»ëœ demographic_type: {demographic_type}")
        return None
    
    # ë°ì´í„° ì¤€ë¹„
    df = get_raw_data(list(series_dict.keys()))
    df = df.rename(columns=series_dict)
    
    print(print_title)
    
    # KPDS ë‹¤ì¤‘ ë¼ì¸ ì°¨íŠ¸ë¡œ ìƒì„±
    return df_multi_line_chart(
        df=df,
        ytitle="%"
    )

def create_unemployment_duration_analysis():
    """
    ì‹¤ì—… ê¸°ê°„ ë¶„ì„ ì°¨íŠ¸ (KPDS í¬ë§·)
    
    Returns:
        plotly figure
    """
    print("ì‹¤ì—… ê¸°ê°„ ë¶„ì„")
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_cps_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # í‰ê· /ì¤‘ê°„ê°’ ì‹¤ì—…ê¸°ê°„ ë°ì´í„°
    duration_dict = {
        'LNS13008275': 'í‰ê·  ì‹¤ì—…ê¸°ê°„',
        'LNS13008276': 'ì¤‘ê°„ê°’ ì‹¤ì—…ê¸°ê°„'
    }
    
    df = get_raw_data(list(duration_dict.keys()))
    df = df.rename(columns=duration_dict)
    
    # KPDS ë‹¤ì¤‘ ë¼ì¸ ì°¨íŠ¸ë¡œ ìƒì„±
    return df_multi_line_chart(
        df=df,
        ytitle="ì£¼"
    )

def create_employment_type_analysis():
    """
    ê³ ìš© í˜•íƒœ ë¶„ì„ ì°¨íŠ¸ (KPDS í¬ë§·)
    
    Returns:
        plotly figure
    """
    print("ê³ ìš© í˜•íƒœ ë¶„ì„")
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_cps_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ê³ ìš© í˜•íƒœë³„ ë°ì´í„°
    employment_dict = {
        'LNS12500000': 'í’€íƒ€ì„ ì·¨ì—…ì',
        'LNS12600000': 'íŒŒíŠ¸íƒ€ì„ ì·¨ì—…ì',
        'LNS12032194': 'ê²½ì œì  ì´ìœ  íŒŒíŠ¸íƒ€ì„'
    }
    
    df = get_raw_data(list(employment_dict.keys()))
    df = df.rename(columns=employment_dict)
    
    # KPDS ë‹¤ì¤‘ ë¼ì¸ ì°¨íŠ¸ë¡œ ìƒì„±
    return df_multi_line_chart(
        df=df,
        ytitle="ì²œëª…"
    )

def create_labor_force_flows():
    """
    ë…¸ë™ì‹œì¥ ì°¸ì—¬/ì´íƒˆ íë¦„ ë¶„ì„ (KPDS í¬ë§·)
    
    Returns:
        plotly figure
    """
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_cps_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ì‹¤ì—… ìœ í˜•ë³„ ë°ì´í„°
    flows_dict = {
        'LNS13023621': 'ì‹¤ì§ì',
        'LNS13023705': 'ìë°œì  ì´ì§ì', 
        'LNS13023557': 'ì¬ì§„ì…ì',
        'LNS13023569': 'ì‹ ê·œì§„ì…ì'
    }
    
    df = get_raw_data(list(flows_dict.keys()))
    df = df.rename(columns=flows_dict)
    
    # KPDS ë‹¤ì¤‘ ë¼ì¸ ì°¨íŠ¸ë¡œ ìƒì„±
    print("ì‹¤ì—…ì êµ¬ì„± ë¶„ì„")
    
    return df_multi_line_chart(
        df=df,
        ytitle="ì²œëª…"
    )

def create_u3_vs_u6_comparison():
    """
    U-3 vs U-6 ì‹¤ì—…ë¥  ë¹„êµ ì°¨íŠ¸ (KPDS í¬ë§·)
    
    Returns:
        plotly figure  
    """
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_cps_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # U-3 vs U-6 ë°ì´í„°
    u_rates_dict = {
        'LNS14000000': 'U-3 (ê³µì‹ ì‹¤ì—…ë¥ )',
        'LNS13327709': 'U-6 (ê´‘ì˜ ì‹¤ì—…ë¥ )'
    }
    
    df = get_raw_data(list(u_rates_dict.keys()))
    df = df.rename(columns=u_rates_dict)
    
    # KPDS ë‹¤ì¤‘ ë¼ì¸ ì°¨íŠ¸ë¡œ ìƒì„±
    print("U-3 vs U-6 ì‹¤ì—…ë¥  ë¹„êµ")
    
    return df_multi_line_chart(
        df=df,
        ytitle="%"
    )

def create_labor_market_heatmap(start_date=None):
    """
    ë…¸ë™ì‹œì¥ ì§€í‘œ íˆíŠ¸ë§µ (ìƒê´€ê´€ê³„ ë¶„ì„)
    
    Args:
        start_date: ë¶„ì„ ì‹œì‘ ë‚ ì§œ
    
    Returns:
        plotly figure
    """
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_cps_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ì£¼ìš” ì§€í‘œ ì„ íƒ
    key_series = [
        'LNS14000000',  # ì‹¤ì—…ë¥ 
        'LNS11300000',  # ê²½ì œí™œë™ì°¸ê°€ìœ¨
        'LNS12300000',  # ê³ ìš©ë¥ 
        'LNS13327709',  # U-6
        'LNS12032194',  # ê²½ì œì  ì´ìœ  íŒŒíŠ¸íƒ€ì„
        'LNS15026645',  # êµ¬ì§ë‹¨ë…ì
        'LNS13008275',  # í‰ê·  ì‹¤ì—…ê¸°ê°„
        'LNS12026620'   # ë³µìˆ˜ì§ì—… ë³´ìœ ìœ¨
    ]
    
    # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    data = get_raw_data(key_series)
    
    if start_date:
        data = data[data.index >= start_date]
    
    # ë³€í™”ìœ¨ ê³„ì‚°
    data_changes = data.pct_change().dropna()
    
    # ìƒê´€ê´€ê³„ ê³„ì‚°
    correlation = data_changes.corr()
    
    # ë¼ë²¨ ë§¤í•‘
    labels = [CPS_KOREAN_NAMES.get(col, col) for col in correlation.columns]
    
    # íˆíŠ¸ë§µ ìƒì„±
    fig = go.Figure(data=go.Heatmap(
        z=correlation.values,
        x=labels,
        y=labels,
        colorscale='RdBu',
        zmid=0,
        text=np.round(correlation.values, 2),
        texttemplate='%{text}',
        textfont={"size": 10},
        reversescale=True
    ))
    
    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    print("ë…¸ë™ì‹œì¥ ì§€í‘œ ìƒê´€ê´€ê³„ ë¶„ì„")
    
    fig.update_layout(
        width=800,
        height=700,
        paper_bgcolor='white',
        font=dict(family='NanumGothic', size=FONT_SIZE_GENERAL),
        xaxis=dict(tickangle=-45),
        margin=dict(l=150, r=50, t=100, b=150)
    )
    
    return fig

def create_monthly_change_table(months_back=6):
    """
    ìµœê·¼ Nê°œì›” ì£¼ìš” ì§€í‘œ ë³€í™” í…Œì´ë¸”
    
    Args:
        months_back: í‘œì‹œí•  ê°œì›” ìˆ˜
    
    Returns:
        plotly figure
    """
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_cps_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ì£¼ìš” ì§€í‘œ ì„ íƒ
    key_series = [
        'LNS14000000',  # ì‹¤ì—…ë¥ 
        'LNS11300000',  # ê²½ì œí™œë™ì°¸ê°€ìœ¨
        'LNS12300000',  # ê³ ìš©ë¥ 
        'LNS13327709',  # U-6
        'LNS12000000',  # ì·¨ì—…ììˆ˜
        'LNS13000000'   # ì‹¤ì—…ììˆ˜
    ]
    
    # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    raw_data = get_raw_data(key_series)
    mom_data = get_mom_data(key_series)
    
    # ìµœê·¼ Nê°œì›” ë°ì´í„°
    recent_raw = raw_data.tail(months_back + 1)
    recent_mom = mom_data.tail(months_back)
    
    # í…Œì´ë¸” ë°ì´í„° ì¤€ë¹„
    headers = ['ì§€í‘œ'] + [date.strftime('%Y-%m') for date in recent_raw.index[1:]]
    
    table_data = []
    for series_id in key_series:
        if series_id in recent_raw.columns:
            row = [CPS_KOREAN_NAMES.get(series_id, series_id)]
            
            for i in range(1, len(recent_raw)):
                value = recent_raw[series_id].iloc[i]
                change = recent_mom[series_id].iloc[i-1] if i > 0 else 0
                
                # í¬ë§·íŒ…
                if 'Rate' in series_id or 'Ratio' in series_id or series_id.startswith('LNS14'):
                    cell_text = f"{value:.1f}%<br>({change:+.1f}%p)"
                else:
                    cell_text = f"{value:,.0f}<br>({change:+.1f}%)"
                
                row.append(cell_text)
            
            table_data.append(row)
    
    # í…Œì´ë¸” ìƒì„±
    fig = go.Figure(data=[go.Table(
        header=dict(
            values=headers,
            line_color='darkslategray',
            fill_color='lightgrey',
            align='center',
            font=dict(size=12, family='NanumGothic')
        ),
        cells=dict(
            values=list(zip(*table_data)),
            line_color='darkslategray',
            fill_color='white',
            align=['left'] + ['center'] * months_back,
            font=dict(size=11, family='NanumGothic'),
            height=40
        )
    )])
    
    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    fig.update_layout(
        title=dict(text=f"ì£¼ìš” ë…¸ë™ì‹œì¥ ì§€í‘œ - ìµœê·¼ {months_back}ê°œì›”", 
                  font=dict(family='NanumGothic', size=FONT_SIZE_TITLE)),
        width=900,
        height=400,
        paper_bgcolor='white',
        margin=dict(l=50, r=50, t=80, b=50)
    )
    
    return fig

# %%
# === ìƒˆë¡œìš´ KPDS ìŠ¤íƒ€ì¼ ì‹œê°í™” í•¨ìˆ˜ë“¤ ===

def create_age_group_analysis():
    """
    ì—°ë ¹ëŒ€ë³„ ë…¸ë™ì‹œì¥ ë¶„ì„ (KPDS í¬ë§·)
    
    Returns:
        plotly figure
    """
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_cps_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ì—°ë ¹ëŒ€ë³„ ì‹¤ì—…ë¥  ë°ì´í„°
    age_dict = {
        'LNU04076975': '18ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
        'LNU04000048': '25ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
        'LNU04000092': '45ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)', 
        'LNU04024230': '55ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
        'LNU04000097': '65ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)'
    }
    
    df = get_raw_data(list(age_dict.keys()))
    df = df.rename(columns=age_dict)
    
    print("ì—°ë ¹ëŒ€ë³„ ì‹¤ì—…ë¥  ë¹„êµ")
    
    return df_multi_line_chart(
        df=df,
        ytitle="%"
    )

def create_race_comparison_chart():
    """
    ì¸ì¢…ë³„ ë…¸ë™ì‹œì¥ ì§€í‘œ ë¹„êµ (KPDS í¬ë§·) 
    
    Returns:
        plotly figure
    """
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_cps_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ì¸ì¢…ë³„ ì‹¤ì—…ë¥  ë°ì´í„°
    race_dict = {
        'LNU04000003': 'ë°±ì¸ (ë¹„ê³„ì ˆì¡°ì •)',
        'LNU04000006': 'í‘ì¸ (ë¹„ê³„ì ˆì¡°ì •)',
        'LNU04032183': 'ì•„ì‹œì•„ê³„ (ë¹„ê³„ì ˆì¡°ì •)',
        'LNU04035243': 'ì•„ë©”ë¦¬ì¹´ ì›ì£¼ë¯¼ (ë¹„ê³„ì ˆì¡°ì •)',
        'LNU04035553': 'í•˜ì™€ì´/íƒœí‰ì–‘ ì›ì£¼ë¯¼ (ë¹„ê³„ì ˆì¡°ì •)'
    }
    
    df = get_raw_data(list(race_dict.keys()))
    df = df.rename(columns=race_dict)
    
    print("ì¸ì¢…ë³„ ì‹¤ì—…ë¥  ë¹„êµ")
    
    return df_multi_line_chart(
        df=df,
        ytitle="%"
    )

def create_seasonal_adjustment_comparison():
    """
    ê³„ì ˆì¡°ì • vs ë¹„ê³„ì ˆì¡°ì • ë¹„êµ (KPDS í¬ë§·)
    
    Returns:
        plotly figure
    """
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_cps_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ê³„ì ˆì¡°ì • ë¹„êµ ë°ì´í„°
    seasonal_dict = {
        'LNS14000000': 'ì‹¤ì—…ë¥  (ê³„ì ˆì¡°ì •)',
        'LNU04000000': 'ì‹¤ì—…ë¥  (ë¹„ê³„ì ˆì¡°ì •)'
    }
    
    df = get_raw_data(list(seasonal_dict.keys()))
    df = df.rename(columns=seasonal_dict)
    
    print("ê³„ì ˆì¡°ì • vs ë¹„ê³„ì ˆì¡°ì • ì‹¤ì—…ë¥ ")
    
    return df_multi_line_chart(
        df=df,
        ytitle="%"
    )

def create_participation_rate_by_age():
    """
    ì—°ë ¹ëŒ€ë³„ ê²½ì œí™œë™ì°¸ê°€ìœ¨ ë¹„êµ (KPDS í¬ë§·)
    
    Returns:
        plotly figure
    """
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_cps_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ì—°ë ¹ëŒ€ë³„ ê²½ì œí™œë™ì°¸ê°€ìœ¨
    participation_dict = {
        'LNU01376975': '18ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
        'LNU01300048': '25ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)', 
        'LNU01300092': '45ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
        'LNU01324230': '55ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)',
        'LNU01300097': '65ì„¸ ì´ìƒ (ë¹„ê³„ì ˆì¡°ì •)'
    }
    
    df = get_raw_data(list(participation_dict.keys()))
    df = df.rename(columns=participation_dict)
    
    print("ì—°ë ¹ëŒ€ë³„ ê²½ì œí™œë™ì°¸ê°€ìœ¨")
    
    return df_multi_line_chart(
        df=df,
        ytitle="%"
    )

def create_employment_level_by_race():
    """
    ì¸ì¢…ë³„ ì·¨ì—…ììˆ˜ ë¹„êµ (KPDS í¬ë§·)
    
    Returns:
        plotly figure  
    """
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_cps_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ì¸ì¢…ë³„ ì·¨ì—…ììˆ˜
    employment_dict = {
        'LNU02000003': 'ë°±ì¸ ì·¨ì—…ì',
        'LNU02000006': 'í‘ì¸ ì·¨ì—…ì', 
        'LNU02032183': 'ì•„ì‹œì•„ê³„ ì·¨ì—…ì'
    }
    
    df = get_raw_data(list(employment_dict.keys()))
    df = df.rename(columns=employment_dict)
    
    print("ì¸ì¢…ë³„ ì·¨ì—…ììˆ˜ ë¹„êµ")
    
    return df_multi_line_chart(
        df=df,
        ytitle="ì²œëª…"
    )

def create_dual_axis_unemployment_employment():
    """
    ì‹¤ì—…ë¥ ê³¼ ì·¨ì—…ììˆ˜ ì´ì¤‘ì¶• ì°¨íŠ¸ (KPDS í¬ë§·)
    
    Returns:
        plotly figure
    """
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_cps_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    df = get_raw_data(['LNS14000000', 'LNS12000000'])
    df = df.rename(columns={
        'LNS14000000': 'ì‹¤ì—…ë¥ ',
        'LNS12000000': 'ì·¨ì—…ììˆ˜'
    })
    
    print("ì‹¤ì—…ë¥  vs ì·¨ì—…ììˆ˜")
    
    return df_dual_axis_chart(
        df=df,
        left_cols=['ì‹¤ì—…ë¥ '],
        right_cols=['ì·¨ì—…ììˆ˜'],
        left_title="%", 
        right_title="ì²œëª…"
    )

# %%
# === í†µí•© ë¶„ì„ í•¨ìˆ˜ë“¤ ===

def run_complete_cps_analysis(start_date='2020-01-01', force_reload=False):
    """
    ì™„ì „í•œ CPS ë¶„ì„ ì‹¤í–‰ - ë°ì´í„° ë¡œë“œ í›„ ëª¨ë“  ì°¨íŠ¸ ìƒì„±
    
    Args:
        start_date: ë°ì´í„° ì‹œì‘ ë‚ ì§œ
        force_reload: ê°•ì œ ì¬ë¡œë“œ ì—¬ë¶€
    
    Returns:
        dict: ìƒì„±ëœ ì°¨íŠ¸ë“¤
    """
    print("ğŸš€ ì™„ì „í•œ CPS ë…¸ë™ì‹œì¥ ë¶„ì„ ì‹œì‘")
    print("="*50)
    
    # 1. ë°ì´í„° ë¡œë“œ
    print("\n1ï¸âƒ£ ë°ì´í„° ë¡œë”©")
    success = load_all_cps_data(start_date=start_date, force_reload=force_reload)
    
    if not success:
        print("âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨")
        return None
    
    # 2. ì‹œê°í™” ìƒì„±
    print("\n2ï¸âƒ£ ì‹œê°í™” ìƒì„±")
    
    results = {}
    
    try:
        # ëŒ€ì‹œë³´ë“œ
        print("   ğŸ“Š ë…¸ë™ì‹œì¥ ëŒ€ì‹œë³´ë“œ...")
        results['dashboard'] = create_labor_market_dashboard()
        
        # ì¸êµ¬í†µê³„ë³„ ë¶„ì„
        print("   ğŸ“ˆ ì¸êµ¬í†µê³„ë³„ ì‹¤ì—…ë¥ ...")
        results['unemployment_by_race'] = create_unemployment_by_demographics('race')
        results['unemployment_by_education'] = create_unemployment_by_demographics('education')
        
        # ì‹¤ì—… ê¸°ê°„ ë¶„ì„
        print("   â±ï¸ ì‹¤ì—… ê¸°ê°„ ë¶„ì„...")
        results['unemployment_duration'] = create_unemployment_duration_analysis()
        
        # ê³ ìš© í˜•íƒœ ë¶„ì„
        print("   ğŸ’¼ ê³ ìš© í˜•íƒœ ë¶„ì„...")
        results['employment_type'] = create_employment_type_analysis()
        
        # U-3 vs U-6
        print("   ğŸ“Š U-3 vs U-6 ë¹„êµ...")
        results['u3_vs_u6'] = create_u3_vs_u6_comparison()
        
        # ë…¸ë™ì‹œì¥ íë¦„
        print("   ğŸ”„ ë…¸ë™ì‹œì¥ íë¦„ ë¶„ì„...")
        results['labor_flows'] = create_labor_force_flows()
        
        # ì›”ë³„ ë³€í™” í…Œì´ë¸”
        print("   ğŸ“‹ ì›”ë³„ ë³€í™” í…Œì´ë¸”...")
        results['monthly_table'] = create_monthly_change_table()
        
    except Exception as e:
        print(f"âš ï¸ ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
    
    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ! ìƒì„±ëœ ì°¨íŠ¸: {len(results)}ê°œ")
    return results

def create_economic_briefing(reference_date=None):
    """
    ì´ì½”ë…¸ë¯¸ìŠ¤íŠ¸ë¥¼ ìœ„í•œ ê²½ì œ ë¸Œë¦¬í•‘ ë¦¬í¬íŠ¸ ìƒì„±
    
    Args:
        reference_date: ê¸°ì¤€ ë‚ ì§œ (Noneì´ë©´ ìµœì‹  ë°ì´í„°)
    
    Returns:
        dict: ë¸Œë¦¬í•‘ ë‚´ìš©
    """
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_cps_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ìµœì‹  ë°ì´í„° ê¸°ì¤€
    latest_values = get_latest_values()
    raw_data = get_raw_data()
    
    if reference_date is None:
        reference_date = raw_data.index[-1]
    
    # ì£¼ìš” ì§€í‘œ ì¶”ì¶œ
    briefing = {
        'reference_date': reference_date.strftime('%Yë…„ %mì›”'),
        'headline_indicators': {
            'ì‹¤ì—…ë¥ ': f"{latest_values.get('LNS14000000', 0):.1f}%",
            'ê²½ì œí™œë™ì°¸ê°€ìœ¨': f"{latest_values.get('LNS11300000', 0):.1f}%",
            'ê³ ìš©ë¥ ': f"{latest_values.get('LNS12300000', 0):.1f}%",
            'U-6 ì‹¤ì—…ë¥ ': f"{latest_values.get('LNS13327709', 0):.1f}%"
        }
    }
    
    # ì „ì›” ëŒ€ë¹„ ë³€í™”
    mom_data = get_mom_data()
    latest_mom = mom_data.iloc[-1]
    
    briefing['monthly_changes'] = {
        'ì‹¤ì—…ë¥  ë³€í™”': f"{latest_mom.get('LNS14000000', 0):+.1f}%p",
        'ê²½ì œí™œë™ì°¸ê°€ìœ¨ ë³€í™”': f"{latest_mom.get('LNS11300000', 0):+.1f}%p",
        'ì·¨ì—…ììˆ˜ ë³€í™”': f"{latest_mom.get('LNS12000000', 0):+.1f}%"
    }
    
    # ì „ë…„ ëŒ€ë¹„ ë³€í™”
    yoy_data = get_yoy_data()
    latest_yoy = yoy_data.iloc[-1]
    
    briefing['yearly_changes'] = {
        'ì‹¤ì—…ë¥  ë³€í™”': f"{latest_yoy.get('LNS14000000', 0):+.1f}%p",
        'ê²½ì œí™œë™ì°¸ê°€ìœ¨ ë³€í™”': f"{latest_yoy.get('LNS11300000', 0):+.1f}%p",
        'ì·¨ì—…ììˆ˜ ë³€í™”': f"{latest_yoy.get('LNS12000000', 0):+.1f}%"
    }
    
    # ì£¼ìš” ì¸ì‚¬ì´íŠ¸ ìƒì„±
    insights = []
    
    # ì‹¤ì—…ë¥  íŠ¸ë Œë“œ
    unemployment_rate = latest_values.get('LNS14000000', 0)
    if unemployment_rate < 4.0:
        insights.append("ì‹¤ì—…ë¥ ì´ 4% ë¯¸ë§Œìœ¼ë¡œ ì™„ì „ê³ ìš©ì— ê·¼ì ‘í•œ ìƒíƒœì…ë‹ˆë‹¤.")
    elif unemployment_rate > 5.0:
        insights.append("ì‹¤ì—…ë¥ ì´ 5%ë¥¼ ì´ˆê³¼í•˜ì—¬ ë…¸ë™ì‹œì¥ ì•½í™” ì‹ í˜¸ê°€ ë‚˜íƒ€ë‚˜ê³  ìˆìŠµë‹ˆë‹¤.")
    
    # U-6ì™€ U-3 ê²©ì°¨
    u6_u3_spread = latest_values.get('LNS13327709', 0) - latest_values.get('LNS14000000', 0)
    if u6_u3_spread > 4.0:
        insights.append(f"U-6ì™€ U-3 ì‹¤ì—…ë¥  ê²©ì°¨ê°€ {u6_u3_spread:.1f}%pë¡œ í™•ëŒ€ë˜ì–´ ë¶ˆì™„ì „ê³ ìš© ë¬¸ì œê°€ ì‹¬í™”ë˜ê³  ìˆìŠµë‹ˆë‹¤.")
    
    # í‰ê·  ì‹¤ì—…ê¸°ê°„
    avg_duration = latest_values.get('LNS13008275', 0)
    if avg_duration > 20:
        insights.append(f"í‰ê·  ì‹¤ì—…ê¸°ê°„ì´ {avg_duration:.1f}ì£¼ë¡œ ì¥ê¸°ì‹¤ì—… ë¬¸ì œê°€ ìš°ë ¤ë©ë‹ˆë‹¤.")
    
    briefing['key_insights'] = insights
    
    # ì„¹í„°ë³„ ë¶„ì„
    briefing['demographic_analysis'] = {
        'ì²­ë…„ì‹¤ì—…ë¥  (16-19ì„¸)': f"{latest_values.get('LNS14000012', 0):.1f}%",
        'ëŒ€ì¡¸ì´ìƒ ì‹¤ì—…ë¥ ': f"{latest_values.get('LNS14027662', 0):.1f}%",
        'ê³ ì¡¸ë¯¸ë§Œ ì‹¤ì—…ë¥ ': f"{latest_values.get('LNS14027659', 0):.1f}%"
    }
    
    return briefing

# %%
# === ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ===

def show_available_series():
    """ì‚¬ìš© ê°€ëŠ¥í•œ CPS ì‹œë¦¬ì¦ˆ í‘œì‹œ"""
    print("=== ì‚¬ìš© ê°€ëŠ¥í•œ CPS ì‹œë¦¬ì¦ˆ ===")
    
    for series_id, description in CPS_SERIES.items():
        korean_name = CPS_KOREAN_NAMES.get(series_id, description)
        print(f"  '{series_id}': {korean_name} ({description})")

def show_category_options():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ ì˜µì…˜ í‘œì‹œ"""
    print("=== ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ ===")
    for category, groups in CPS_CATEGORIES.items():
        print(f"\n{category}:")
        for group_name, series_list in groups.items():
            print(f"  {group_name}: {len(series_list)}ê°œ ì‹œë¦¬ì¦ˆ")
            for series_id in series_list:
                korean_name = CPS_KOREAN_NAMES.get(series_id, series_id)
                print(f"    - {series_id}: {korean_name}")

def get_data_status():
    """í˜„ì¬ ë°ì´í„° ìƒíƒœ ë°˜í™˜"""
    return {
        'loaded': CPS_DATA['load_info']['loaded'],
        'series_count': CPS_DATA['load_info']['series_count'],
        'available_series': list_available_series(),
        'load_info': CPS_DATA['load_info']
    }

def create_custom_analysis(series_ids, chart_type='line'):
    """
    ì‚¬ìš©ì ì •ì˜ ë¶„ì„ ì°¨íŠ¸ ìƒì„±
    
    Args:
        series_ids: ë¶„ì„í•  ì‹œë¦¬ì¦ˆ ID ë¦¬ìŠ¤íŠ¸
        chart_type: 'line', 'bar', 'scatter'
    
    Returns:
        plotly figure
    """
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_cps_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    data = get_raw_data(series_ids)
    
    if data.empty:
        print("âš ï¸ ìš”ì²­í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ì°¨íŠ¸ ìƒì„±
    fig = go.Figure()
    
    if chart_type == 'line':
        for i, col in enumerate(data.columns):
            korean_name = CPS_KOREAN_NAMES.get(col, CPS_SERIES.get(col, col))
            fig.add_trace(go.Scatter(
                x=data.index,
                y=data[col],
                name=korean_name,
                mode='lines',
                line=dict(color=get_kpds_color(i), width=2)
            ))
    
    elif chart_type == 'bar':
        # ìµœì‹  ë°ì´í„°ë§Œ ì‚¬ìš©
        latest_data = data.iloc[-1]
        labels = [CPS_KOREAN_NAMES.get(col, CPS_SERIES.get(col, col)) for col in data.columns]
        
        fig.add_trace(go.Bar(
            x=labels,
            y=latest_data.values,
            marker_color=[get_kpds_color(i) for i in range(len(labels))]
        ))
    
    elif chart_type == 'scatter':
        if len(data.columns) >= 2:
            x_col, y_col = data.columns[0], data.columns[1]
            x_label = CPS_KOREAN_NAMES.get(x_col, x_col)
            y_label = CPS_KOREAN_NAMES.get(y_col, y_col)
            
            fig.add_trace(go.Scatter(
                x=data[x_col],
                y=data[y_col],
                mode='markers',
                marker=dict(color=deepblue_pds, size=8),
                name=f"{x_label} vs {y_label}"
            ))
    
    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    print("Custom Labor Market Analysis")
    
    fig.update_layout(
        paper_bgcolor='white',
        plot_bgcolor='white',
        width=686,
        height=500,
        font=dict(family='NanumGothic', size=FONT_SIZE_GENERAL),
        xaxis=dict(
            showline=True, linewidth=1.3, linecolor='lightgrey',
            showgrid=True, gridwidth=1, gridcolor='lightgrey'
        ),
        yaxis=dict(
            showline=False,
            showgrid=True, gridwidth=1, gridcolor='lightgrey'
        ),
        legend=dict(
            orientation="v",
            yanchor="top", y=1,
            xanchor="left", x=1.02,
            font=dict(family='NanumGothic', size=FONT_SIZE_LEGEND)
        ),
        margin=dict(l=80, r=200, t=80, b=60)
    )
    
    return fig

def export_analysis_data(output_format='excel', filename=None):
    """
    ë¶„ì„ ë°ì´í„°ë¥¼ ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°
    
    Args:
        output_format: 'excel', 'csv', 'json'
        filename: ì €ì¥í•  íŒŒì¼ëª… (Noneì´ë©´ ìë™ ìƒì„±)
    
    Returns:
        bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_cps_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return False
    
    # íŒŒì¼ëª… ìë™ ìƒì„±
    if filename is None:
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'/home/jyp0615/us_eco/cps_analysis_{timestamp}'
    
    try:
        if output_format == 'excel':
            with pd.ExcelWriter(f'{filename}.xlsx', engine='openpyxl') as writer:
                # ì›ë³¸ ë°ì´í„°
                CPS_DATA['raw_data'].to_excel(writer, sheet_name='Raw Data')
                
                # MoM ë³€í™”
                CPS_DATA['mom_data'].to_excel(writer, sheet_name='MoM Changes')
                
                # YoY ë³€í™”
                CPS_DATA['yoy_data'].to_excel(writer, sheet_name='YoY Changes')
                
                # ìµœì‹  ê°’ ìš”ì•½
                latest_df = pd.DataFrame({
                    'Series ID': list(CPS_DATA['latest_values'].keys()),
                    'Korean Name': [CPS_KOREAN_NAMES.get(k, k) for k in CPS_DATA['latest_values'].keys()],
                    'Latest Value': list(CPS_DATA['latest_values'].values())
                })
                latest_df.to_excel(writer, sheet_name='Latest Values', index=False)
            
            print(f"âœ… Excel íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}.xlsx")
        
        elif output_format == 'csv':
            CPS_DATA['raw_data'].to_csv(f'{filename}_raw.csv')
            CPS_DATA['mom_data'].to_csv(f'{filename}_mom.csv')
            CPS_DATA['yoy_data'].to_csv(f'{filename}_yoy.csv')
            print(f"âœ… CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}_*.csv")
        
        elif output_format == 'json':
            export_data = {
                'metadata': {
                    'load_time': CPS_DATA['load_info']['load_time'].isoformat(),
                    'start_date': CPS_DATA['load_info']['start_date'],
                    'series_count': CPS_DATA['load_info']['series_count']
                },
                'latest_values': CPS_DATA['latest_values'],
                'raw_data': CPS_DATA['raw_data'].to_dict(),
                'mom_data': CPS_DATA['mom_data'].to_dict(),
                'yoy_data': CPS_DATA['yoy_data'].to_dict()
            }
            
            import json
            with open(f'{filename}.json', 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"âœ… JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}.json")
        
        else:
            print(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {output_format}")
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
        return False

def generate_markdown_report():
    """
    ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
    
    Returns:
        str: ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸
    """
    if not CPS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_cps_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    briefing = create_economic_briefing()
    if not briefing:
        return None
    
    report = f"""
# US Labor Market Analysis Report
## {briefing['reference_date']}

### ğŸ“Š ì£¼ìš” ì§€í‘œ (Headline Indicators)

| ì§€í‘œ | í˜„ì¬ê°’ | ì „ì›” ëŒ€ë¹„ | ì „ë…„ ëŒ€ë¹„ |
|------|--------|-----------|-----------|
| ì‹¤ì—…ë¥  | {briefing['headline_indicators']['ì‹¤ì—…ë¥ ']} | {briefing['monthly_changes']['ì‹¤ì—…ë¥  ë³€í™”']} | {briefing['yearly_changes']['ì‹¤ì—…ë¥  ë³€í™”']} |
| ê²½ì œí™œë™ì°¸ê°€ìœ¨ | {briefing['headline_indicators']['ê²½ì œí™œë™ì°¸ê°€ìœ¨']} | {briefing['monthly_changes']['ê²½ì œí™œë™ì°¸ê°€ìœ¨ ë³€í™”']} | {briefing['yearly_changes']['ê²½ì œí™œë™ì°¸ê°€ìœ¨ ë³€í™”']} |
| ê³ ìš©ë¥  | {briefing['headline_indicators']['ê³ ìš©ë¥ ']} | - | - |
| U-6 ì‹¤ì—…ë¥  | {briefing['headline_indicators']['U-6 ì‹¤ì—…ë¥ ']} | - | - |

### ğŸ“ˆ ì£¼ìš” ì¸ì‚¬ì´íŠ¸

"""
    
    for insight in briefing['key_insights']:
        report += f"- {insight}\n"
    
    report += f"""

### ğŸ¯ ì¸êµ¬í†µê³„ë³„ ë¶„ì„

| ê·¸ë£¹ | ì‹¤ì—…ë¥  |
|------|--------|
| ì²­ë…„ì¸µ (16-19ì„¸) | {briefing['demographic_analysis']['ì²­ë…„ì‹¤ì—…ë¥  (16-19ì„¸)']} |
| ëŒ€ì¡¸ ì´ìƒ | {briefing['demographic_analysis']['ëŒ€ì¡¸ì´ìƒ ì‹¤ì—…ë¥ ']} |
| ê³ ì¡¸ ë¯¸ë§Œ | {briefing['demographic_analysis']['ê³ ì¡¸ë¯¸ë§Œ ì‹¤ì—…ë¥ ']} |

### ğŸ“Œ ë°ì´í„° ì •ë³´

- ë°ì´í„° ê¸°ê°„: {CPS_DATA['raw_data'].index[0].strftime('%Y-%m')} ~ {CPS_DATA['raw_data'].index[-1].strftime('%Y-%m')}
- ì‹œë¦¬ì¦ˆ ê°œìˆ˜: {CPS_DATA['load_info']['series_count']}ê°œ
- ë°ì´í„° í¬ì¸íŠ¸: {CPS_DATA['load_info']['data_points']}ê°œ
- ìµœì¢… ì—…ë°ì´íŠ¸: {CPS_DATA['load_info']['load_time'].strftime('%Y-%m-%d %H:%M:%S')}

---
*ì´ ë¦¬í¬íŠ¸ëŠ” BLS CPS ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
"""
    
    return report

# %%
# === ì‚¬ìš© ì˜ˆì‹œ ë° ë©”ì¸ ì‹¤í–‰ ===

print("\n=== CPS ë…¸ë™ì‹œì¥ ë¶„ì„ ë„êµ¬ ì‚¬ìš©ë²• ===")
print("\nğŸ¯ ì£¼ìš” ê¸°ëŠ¥:")
print("1. ë°ì´í„° ë¡œë“œ (CSV ìš°ì„ , API ë°±ì—…):")
print("   load_all_cps_data()  # CSVê°€ ìˆìœ¼ë©´ ë¡œë“œ í›„ ìë™ ì—…ë°ì´íŠ¸")
print("   load_cps_data_from_csv()  # CSVì—ì„œë§Œ ë¡œë“œ")
print("   update_cps_data_from_api()  # ìµœì‹  ë°ì´í„°ë§Œ APIë¡œ ì—…ë°ì´íŠ¸")
print()
print("2. ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸:")
print("   check_recent_data_consistency()  # ìµœê·¼ 3ê°œ ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸")
print("   update_cps_data_from_api(smart_update=True)  # ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ (ê¸°ë³¸ê°’)")
print("   update_cps_data_from_api(smart_update=False)  # ê°•ì œ ì—…ë°ì´íŠ¸")
print()
print("3. ì‹œê°í™” - ëŒ€ì‹œë³´ë“œ:")
print("   create_labor_market_dashboard()  # 4ê°œ ì£¼ìš” ì§€í‘œ ëŒ€ì‹œë³´ë“œ")
print()
print("4. ì‹œê°í™” - ì¸êµ¬í†µê³„ë³„ ë¶„ì„:")
print("   create_unemployment_by_demographics('race')  # ì¸ì¢…ë³„")
print("   create_unemployment_by_demographics('age')  # ì—°ë ¹ë³„")
print("   create_unemployment_by_demographics('education')  # êµìœ¡ìˆ˜ì¤€ë³„")
print()
print("5. ì‹œê°í™” - ì‹¬ì¸µ ë¶„ì„:")
print("   create_unemployment_duration_analysis()  # ì‹¤ì—… ê¸°ê°„ ë¶„ì„")
print("   create_employment_type_analysis()  # ê³ ìš© í˜•íƒœ ë¶„ì„")
print("   create_u3_vs_u6_comparison()  # U-3 vs U-6 ë¹„êµ")
print("   create_labor_force_flows()  # ë…¸ë™ì‹œì¥ íë¦„")
print("   create_labor_market_heatmap()  # ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ")
print()
print("6. í…Œì´ë¸” ë° ë¦¬í¬íŠ¸:")
print("   create_monthly_change_table()  # ì›”ë³„ ë³€í™” í…Œì´ë¸”")
print("   create_economic_briefing()  # ê²½ì œ ë¸Œë¦¬í•‘ ë°ì´í„°")
print("   generate_markdown_report()  # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸")
print()
print("7. í†µí•© ë¶„ì„:")
print("   run_complete_cps_analysis()  # ëª¨ë“  ë¶„ì„ ì‹¤í–‰")
print()
print("8. ë°ì´í„° ê´€ë¦¬:")
print("   save_cps_data_to_csv()  # CSVë¡œ ì €ì¥")
print("   export_analysis_data('excel')  # Excelë¡œ ë‚´ë³´ë‚´ê¸°")
print("   get_data_status()  # ë°ì´í„° ìƒíƒœ í™•ì¸")
print("   show_available_series()  # ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œë¦¬ì¦ˆ")
print("   show_category_options()  # ì¹´í…Œê³ ë¦¬ ì˜µì…˜")
print()
print("9. ì‚¬ìš©ì ì •ì˜:")
print("   create_custom_analysis(['LNS14000000', 'LNS11300000'])  # ì»¤ìŠ¤í…€ ì°¨íŠ¸")
print()
print("10. ğŸŒ ì´ë¯¼ ì •ì±… ê´€ë ¨ ë¶„ì„:")
print("   create_immigration_policy_report()  # ì¢…í•© ì´ë¯¼ì •ì±… ë¶„ì„ ë¦¬í¬íŠ¸")
print("   plot_immigration_labor_trends()     # ì´ë¯¼ ê´€ë ¨ ë…¸ë™ì‹œì¥ íŠ¸ë Œë“œ ì°¨íŠ¸")
print("   analyze_immigration_labor_impact()  # íˆìŠ¤íŒ¨ë‹‰/ë¼í‹°ë…¸ vs ì „ì²´ ë¹„êµë¶„ì„")
print("   analyze_age_group_participation()   # ì—°ë ¹ëŒ€ë³„ ê²½ì œí™œë™ì°¸ê°€ìœ¨ ë¶„ì„")
print()
print("ğŸ“Œ API í‚¤ ê´€ë¦¬:")
print("   switch_api_key()  # API í‚¤ ìˆ˜ë™ ì „í™˜ (ì¼ì¼ í•œë„ ì´ˆê³¼ ì‹œ)")

# %%
# === ì´ë¯¼ ì •ì±… ê´€ë ¨ ë¶„ì„ ë„êµ¬ ===
# ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸
def analyze_immigration_labor_impact():
    """
    ì´ë¯¼ ì •ì±… ê´€ë ¨ ë…¸ë™ì‹œì¥ ì˜í–¥ ë¶„ì„
    - íˆìŠ¤íŒ¨ë‹‰/ë¼í‹°ë…¸ vs ì „ì²´ ì¸êµ¬ ë¹„êµ
    - ì—°ë ¹ëŒ€ë³„ ë…¸ë™ì‹œì¥ ì°¸ì—¬ ë³€í™”
    - ìµœê·¼ íŠ¸ë Œë“œ ë¶„ì„
    """
    if CPS_DATA['raw_data'].empty:
        print("âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_cps_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return None
    
    # ìµœê·¼ 3ë…„ ë°ì´í„° ë¶„ì„
    recent_data = CPS_DATA['raw_data'].tail(36)  # ìµœê·¼ 36ê°œì›”
    
    # íˆìŠ¤íŒ¨ë‹‰/ë¼í‹°ë…¸ vs ì „ì²´ ë¹„êµ ì§€í‘œ
    comparison_metrics = {
        'ì „ì²´ì¸êµ¬_ì‹¤ì—…ë¥ ': 'LNS14000000',
        'íˆìŠ¤íŒ¨ë‹‰_ì‹¤ì—…ë¥ ': 'LNS14000009',
        'ì „ì²´ì¸êµ¬_ì°¸ê°€ìœ¨': 'LNS11300000', 
        'íˆìŠ¤íŒ¨ë‹‰_ì°¸ê°€ìœ¨': 'LNS11300009',
        'ì „ì²´ì¸êµ¬_ê³ ìš©ë¥ ': 'LNS12300000',
        'íˆìŠ¤íŒ¨ë‹‰_ì·¨ì—…ì': 'LNS12000009'
    }
    
    analysis_results = {}
    
    # ìµœì‹  ê°’ ë¹„êµ
    latest_values = {}
    for key, series_id in comparison_metrics.items():
        if series_id in recent_data.columns:
            latest_val = recent_data[series_id].dropna().iloc[-1]
            latest_values[key] = latest_val
    
    # ì‹¤ì—…ë¥  ê²©ì°¨ ê³„ì‚°
    if 'ì „ì²´ì¸êµ¬_ì‹¤ì—…ë¥ ' in latest_values and 'íˆìŠ¤íŒ¨ë‹‰_ì‹¤ì—…ë¥ ' in latest_values:
        unemployment_gap = latest_values['íˆìŠ¤íŒ¨ë‹‰_ì‹¤ì—…ë¥ '] - latest_values['ì „ì²´ì¸êµ¬_ì‹¤ì—…ë¥ ']
        analysis_results['ì‹¤ì—…ë¥ _ê²©ì°¨'] = unemployment_gap
    
    # ì°¸ê°€ìœ¨ ê²©ì°¨ ê³„ì‚°  
    if 'ì „ì²´ì¸êµ¬_ì°¸ê°€ìœ¨' in latest_values and 'íˆìŠ¤íŒ¨ë‹‰_ì°¸ê°€ìœ¨' in latest_values:
        participation_gap = latest_values['íˆìŠ¤íŒ¨ë‹‰_ì°¸ê°€ìœ¨'] - latest_values['ì „ì²´ì¸êµ¬_ì°¸ê°€ìœ¨']
        analysis_results['ì°¸ê°€ìœ¨_ê²©ì°¨'] = participation_gap
    
    # ìµœê·¼ 1ë…„ íŠ¸ë Œë“œ
    if len(recent_data) >= 12:
        last_12m = recent_data.tail(12)
        
        # íˆìŠ¤íŒ¨ë‹‰ ì‹¤ì—…ë¥  ë³€í™”
        if 'LNS14000009' in last_12m.columns:
            hispanic_unemp_change = (last_12m['LNS14000009'].iloc[-1] - 
                                   last_12m['LNS14000009'].iloc[0])
            analysis_results['íˆìŠ¤íŒ¨ë‹‰_ì‹¤ì—…ë¥ _1ë…„ë³€í™”'] = hispanic_unemp_change
        
        # ì „ì²´ ì‹¤ì—…ë¥  ë³€í™”
        if 'LNS14000000' in last_12m.columns:
            total_unemp_change = (last_12m['LNS14000000'].iloc[-1] - 
                                last_12m['LNS14000000'].iloc[0])
            analysis_results['ì „ì²´_ì‹¤ì—…ë¥ _1ë…„ë³€í™”'] = total_unemp_change
    
    analysis_results['ìµœì‹ ê°’'] = latest_values
    analysis_results['ë¶„ì„ì¼ì'] = datetime.datetime.now().strftime('%Y-%m-%d %H:%M')
    
    return analysis_results

def plot_immigration_labor_trends():
    """
    ì´ë¯¼ ê´€ë ¨ ë…¸ë™ì‹œì¥ íŠ¸ë Œë“œ ì‹œê°í™”
    """
    if CPS_DATA['raw_data'].empty:
        print("âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    # ìµœê·¼ 5ë…„ ë°ì´í„°
    recent_data = CPS_DATA['raw_data'].tail(60)
    
    # 4ê°œ ì„œë¸Œí”Œë¡¯ ìƒì„±
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=[
            'ì‹¤ì—…ë¥  ë¹„êµ: ì „ì²´ vs íˆìŠ¤íŒ¨ë‹‰/ë¼í‹°ë…¸',
            'ê²½ì œí™œë™ì°¸ê°€ìœ¨ ë¹„êµ: ì „ì²´ vs íˆìŠ¤íŒ¨ë‹‰/ë¼í‹°ë…¸', 
            'ì—°ë ¹ëŒ€ë³„ ì‹¤ì—…ë¥  íŠ¸ë Œë“œ',
            'íˆìŠ¤íŒ¨ë‹‰/ë¼í‹°ë…¸ ë…¸ë™ì‹œì¥ ì§€í‘œ'
        ],
        specs=[[{"secondary_y": False}, {"secondary_y": False}],
               [{"secondary_y": False}, {"secondary_y": True}]]
    )
    
    # 1. ì‹¤ì—…ë¥  ë¹„êµ
    if 'LNS14000000' in recent_data.columns and 'LNS14000009' in recent_data.columns:
        fig.add_trace(
            go.Scatter(x=recent_data.index, y=recent_data['LNS14000000'],
                      name='ì „ì²´ ì‹¤ì—…ë¥ ', line=dict(color='blue', width=2)),
            row=1, col=1
        )
        fig.add_trace(
            go.Scatter(x=recent_data.index, y=recent_data['LNS14000009'],
                      name='íˆìŠ¤íŒ¨ë‹‰ ì‹¤ì—…ë¥ ', line=dict(color='red', width=2)),
            row=1, col=1
        )
    
    # 2. ê²½ì œí™œë™ì°¸ê°€ìœ¨ ë¹„êµ
    if 'LNS11300000' in recent_data.columns and 'LNS11300009' in recent_data.columns:
        fig.add_trace(
            go.Scatter(x=recent_data.index, y=recent_data['LNS11300000'],
                      name='ì „ì²´ ì°¸ê°€ìœ¨', line=dict(color='green', width=2)),
            row=1, col=2
        )
        fig.add_trace(
            go.Scatter(x=recent_data.index, y=recent_data['LNS11300009'],
                      name='íˆìŠ¤íŒ¨ë‹‰ ì°¸ê°€ìœ¨', line=dict(color='orange', width=2)),
            row=1, col=2
        )
    
    # 3. ì—°ë ¹ëŒ€ë³„ ì‹¤ì—…ë¥ 
    age_series = {
        '16-19ì„¸': 'LNS14000012',
        '20+ë‚¨ì„±': 'LNS14000025', 
        '20+ì—¬ì„±': 'LNS14000026'
    }
    
    colors = ['purple', 'darkblue', 'darkred']
    for i, (name, series_id) in enumerate(age_series.items()):
        if series_id in recent_data.columns:
            fig.add_trace(
                go.Scatter(x=recent_data.index, y=recent_data[series_id],
                          name=f'{name} ì‹¤ì—…ë¥ ', line=dict(color=colors[i], width=2)),
                row=2, col=1
            )
    
    # 4. íˆìŠ¤íŒ¨ë‹‰ ë…¸ë™ì‹œì¥ ì§€í‘œ (ì´ì¤‘ì¶•)
    if 'LNS12000009' in recent_data.columns:  # ì·¨ì—…ììˆ˜
        fig.add_trace(
            go.Scatter(x=recent_data.index, y=recent_data['LNS12000009'],
                      name='íˆìŠ¤íŒ¨ë‹‰ ì·¨ì—…ììˆ˜', line=dict(color='darkgreen', width=2)),
            row=2, col=2
        )
    
    if 'LNS14000009' in recent_data.columns:  # ì‹¤ì—…ë¥ 
        fig.add_trace(
            go.Scatter(x=recent_data.index, y=recent_data['LNS14000009'],
                      name='íˆìŠ¤íŒ¨ë‹‰ ì‹¤ì—…ë¥ ', line=dict(color='red', width=2),
                      yaxis='y4'),
            row=2, col=2, secondary_y=True
        )
    
    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    fig.update_layout(
        title={
            'text': 'ğŸŒ ì´ë¯¼ ì •ì±… ê´€ë ¨ ë…¸ë™ì‹œì¥ ë¶„ì„ ëŒ€ì‹œë³´ë“œ',
            'font': {'size': 20, 'family': 'Arial Black'},
            'x': 0.5
        },
        height=800,
        showlegend=True,
        template='plotly_white'
    )
    
    # Yì¶• ë¼ë²¨ ì„¤ì •
    fig.update_yaxes(title_text="ì‹¤ì—…ë¥  (%)", row=1, col=1)
    fig.update_yaxes(title_text="ì°¸ê°€ìœ¨ (%)", row=1, col=2)
    fig.update_yaxes(title_text="ì‹¤ì—…ë¥  (%)", row=2, col=1)
    fig.update_yaxes(title_text="ì·¨ì—…ììˆ˜ (ì²œëª…)", row=2, col=2)
    fig.update_yaxes(title_text="ì‹¤ì—…ë¥  (%)", row=2, col=2, secondary_y=True)
    
    return fig

# %%
# === ë²”ìš© ì‹œê°í™” í•¨ìˆ˜ë“¤ (ì‚¬ìš©ì ì§€ì • ì‹œë¦¬ì¦ˆ) ===

def plot_cps_series(series_list, chart_type='multi_line', data_type='raw', 
                   periods=36, labels=None, left_ytitle=None, right_ytitle=None, target_date=None):
    """
    ë²”ìš© CPS ì‹œê°í™” í•¨ìˆ˜ - ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì‹œë¦¬ì¦ˆë¡œ ë‹¤ì–‘í•œ ì°¨íŠ¸ ìƒì„±
    
    Args:
        series_list: ì‹œê°í™”í•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['LNS14000000', 'LNS11300000'])
        chart_type: ì°¨íŠ¸ ì¢…ë¥˜ ('multi_line', 'dual_axis', 'horizontal_bar', 'single_line')
        data_type: ë°ì´í„° íƒ€ì… ('raw', 'mom', 'yoy')
        periods: í‘œì‹œí•  ê¸°ê°„ (ê°œì›”)
        labels: ì‹œë¦¬ì¦ˆ ë¼ë²¨ ë”•ì…”ë„ˆë¦¬ (Noneì´ë©´ ìë™)
        left_ytitle: ì™¼ìª½ Yì¶• ì œëª©
        right_ytitle: ì˜¤ë¥¸ìª½ Yì¶• ì œëª©
        target_date: íŠ¹ì • ë‚ ì§œ ê¸°ì¤€ (ì˜ˆ: '2025-06-01', Noneì´ë©´ ìµœì‹  ë°ì´í„°)
    
    Returns:
        plotly figure
    """
    if CPS_DATA['raw_data'].empty:
        print("âš ï¸ ë¨¼ì € load_all_cps_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ë°ì´í„° íƒ€ì…ì— ë”°ë¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    if data_type == 'raw':
        data = get_raw_data()
        unit = "%" if any('Rate' in CPS_SERIES.get(s, '') or 'Ratio' in CPS_SERIES.get(s, '') for s in series_list) else "ì²œëª…"
        desc = "ìˆ˜ì¤€"
    elif data_type == 'mom':
        data = get_mom_data()
        unit = "%p"
        desc = "ì „ì›”ëŒ€ë¹„"
    elif data_type == 'yoy':
        data = get_yoy_data()
        unit = "%p"
        desc = "ì „ë…„ë™ì›”ëŒ€ë¹„"
    else:
        print("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” data_typeì…ë‹ˆë‹¤. 'raw', 'mom', 'yoy' ì¤‘ ì„ íƒí•˜ì„¸ìš”.")
        return None
    
    if data.empty:
        print("âŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ê¸°ê°„ ì œí•œ ë˜ëŠ” íŠ¹ì • ë‚ ì§œ ê¸°ì¤€
    if target_date:
        try:
            target_date_parsed = pd.to_datetime(target_date)
            # í•´ë‹¹ ë‚ ì§œ ì´ì „ì˜ ë°ì´í„°ë§Œ ì„ íƒ
            filtered_data = data[data.index <= target_date_parsed]
            if filtered_data.empty:
                print(f"âš ï¸ {target_date} ì´ì „ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
            recent_data = filtered_data.tail(periods)
        except:
            print(f"âš ï¸ ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹ì…ë‹ˆë‹¤: {target_date}. 'YYYY-MM-DD' í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            return None
    else:
        recent_data = data.tail(periods)
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ í™•ì¸
    available_cols = [col for col in series_list if col in recent_data.columns]
    
    if not available_cols:
        print("âŒ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
        print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œë¦¬ì¦ˆ: {list(recent_data.columns[:10])}...")
        return None
    
    # ìë™ ë¼ë²¨ ìƒì„±
    if labels is None:
        labels = {col: CPS_KOREAN_NAMES.get(col, CPS_SERIES.get(col, col)) for col in available_cols}
    
    # Yì¶• ì œëª© ìë™ ì„¤ì •
    if left_ytitle is None:
        left_ytitle = unit
    
    # ì°¨íŠ¸ íƒ€ì…ë³„ ì‹œê°í™”
    if chart_type == 'multi_line':
        print(f"CPS ì‹œë¦¬ì¦ˆ ë‹¤ì¤‘ ë¼ì¸ ì°¨íŠ¸ ({desc})")
        fig = df_multi_line_chart(
            df=recent_data,
            columns=available_cols,
            ytitle=left_ytitle,
            labels=labels
        )
    
    elif chart_type == 'single_line' and len(available_cols) == 1:
        print(f"CPS ì‹œë¦¬ì¦ˆ ë‹¨ì¼ ë¼ì¸ ì°¨íŠ¸ ({desc})")
        fig = df_line_chart(
            df=recent_data,
            column=available_cols[0],
            ytitle=left_ytitle,
            label=labels[available_cols[0]]
        )
    
    elif chart_type == 'dual_axis' and len(available_cols) >= 2:
        # ë°˜ë°˜ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì™¼ìª½/ì˜¤ë¥¸ìª½ ì¶•ì— ë°°ì¹˜
        mid = len(available_cols) // 2
        left_cols = available_cols[:mid] if mid > 0 else available_cols[:1]
        right_cols = available_cols[mid:] if mid > 0 else available_cols[1:]
        
        print(f"CPS ì‹œë¦¬ì¦ˆ ì´ì¤‘ì¶• ì°¨íŠ¸ ({desc})")
        fig = df_dual_axis_chart(
            df=recent_data,
            left_cols=left_cols,
            right_cols=right_cols,
            left_labels=[labels[col] for col in left_cols],
            right_labels=[labels[col] for col in right_cols],
            left_title=left_ytitle,
            right_title=right_ytitle or left_ytitle
        )
    
    elif chart_type == 'horizontal_bar':
        # ìµœì‹ ê°’ ê¸°ì¤€ ê°€ë¡œ ë°” ì°¨íŠ¸
        latest_values = {}
        for col in available_cols:
            latest_val = recent_data[col].dropna().iloc[-1] if not recent_data[col].dropna().empty else 0
            latest_values[labels[col]] = latest_val
        
        # ë‚ ì§œ ì •ë³´ í‘œì‹œ
        latest_date = recent_data.index[-1].strftime('%Y-%m') if not recent_data.empty else "N/A"
        date_info = f" ({latest_date})" if target_date else ""
        
        print(f"CPS ì‹œë¦¬ì¦ˆ ê°€ë¡œ ë°” ì°¨íŠ¸ ({desc}){date_info}")
        fig = create_horizontal_bar_chart(
            data_dict=latest_values,
            positive_color=deepred_pds,
            negative_color=deepblue_pds,
            unit=unit
        )
    
    else:
        print("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” chart_typeì´ê±°ë‚˜ ì‹œë¦¬ì¦ˆ ê°œìˆ˜ê°€ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print("   - single_line: 1ê°œ ì‹œë¦¬ì¦ˆ")
        print("   - multi_line: ì—¬ëŸ¬ ì‹œë¦¬ì¦ˆ")
        print("   - dual_axis: 2ê°œ ì´ìƒ ì‹œë¦¬ì¦ˆ")
        print("   - horizontal_bar: ì—¬ëŸ¬ ì‹œë¦¬ì¦ˆ")
        return None
    
    return fig

def analyze_age_group_participation():
    """
    ì—°ë ¹ëŒ€ë³„ ê²½ì œí™œë™ì°¸ê°€ìœ¨ ë¶„ì„ (ì´ë¯¼ì •ì±… ì˜í–¥ ê´€ì )
    """
    if CPS_DATA['raw_data'].empty:
        print("âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    # ì—°ë ¹ëŒ€ë³„ ì‹œë¦¬ì¦ˆ
    age_series = {
        '16ì„¸ì´ìƒ': 'LNS11300000',
        '20ì„¸ì´ìƒ': 'LNS11300024', 
        '25ì„¸ì´ìƒ': 'LNS11300048',
        '55ì„¸ì´ìƒ': 'LNS11324230'
    }
    
    recent_data = CPS_DATA['raw_data'].tail(36)  # ìµœê·¼ 3ë…„
    
    analysis_results = {}
    
    # ìµœì‹  ì°¸ê°€ìœ¨
    latest_participation = {}
    for age_group, series_id in age_series.items():
        if series_id in recent_data.columns:
            latest_val = recent_data[series_id].dropna().iloc[-1]
            latest_participation[age_group] = latest_val
    
    # 1ë…„ ë³€í™”
    participation_change_1y = {}
    if len(recent_data) >= 12:
        for age_group, series_id in age_series.items():
            if series_id in recent_data.columns:
                current = recent_data[series_id].dropna().iloc[-1]
                year_ago = recent_data[series_id].dropna().iloc[-12]
                change = current - year_ago
                participation_change_1y[age_group] = change
    
    # 3ë…„ ë³€í™”  
    participation_change_3y = {}
    for age_group, series_id in age_series.items():
        if series_id in recent_data.columns:
            current = recent_data[series_id].dropna().iloc[-1]
            three_years_ago = recent_data[series_id].dropna().iloc[0]
            change = current - three_years_ago
            participation_change_3y[age_group] = change
    
    analysis_results = {
        'ìµœì‹ _ì°¸ê°€ìœ¨': latest_participation,
        '1ë…„_ë³€í™”': participation_change_1y,
        '3ë…„_ë³€í™”': participation_change_3y,
        'ë¶„ì„_ê¸°ê°„': f"{recent_data.index[0].strftime('%Y-%m')} ~ {recent_data.index[-1].strftime('%Y-%m')}"
    }
    
    return analysis_results

def create_immigration_policy_report():
    """
    ì´ë¯¼ ì •ì±… ê´€ë ¨ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
    """
    print("\n" + "="*60)
    print("ğŸŒ ì´ë¯¼ ì •ì±… ê´€ë ¨ ë…¸ë™ì‹œì¥ ë¶„ì„ ë¦¬í¬íŠ¸")
    print("="*60)
    
    # 1. ê¸°ë³¸ ë¶„ì„
    immigration_analysis = analyze_immigration_labor_impact()
    if immigration_analysis:
        print("\nğŸ“Š íˆìŠ¤íŒ¨ë‹‰/ë¼í‹°ë…¸ vs ì „ì²´ ì¸êµ¬ ë¹„êµ:")
        print(f"   ì‹¤ì—…ë¥  ê²©ì°¨: {immigration_analysis.get('ì‹¤ì—…ë¥ _ê²©ì°¨', 0):.2f}%p")
        print(f"   ì°¸ê°€ìœ¨ ê²©ì°¨: {immigration_analysis.get('ì°¸ê°€ìœ¨_ê²©ì°¨', 0):.2f}%p")
        
        if 'ìµœì‹ ê°’' in immigration_analysis:
            latest = immigration_analysis['ìµœì‹ ê°’']
            print(f"   ìµœì‹  íˆìŠ¤íŒ¨ë‹‰ ì‹¤ì—…ë¥ : {latest.get('íˆìŠ¤íŒ¨ë‹‰_ì‹¤ì—…ë¥ ', 0):.1f}%")
            print(f"   ìµœì‹  ì „ì²´ ì‹¤ì—…ë¥ : {latest.get('ì „ì²´ì¸êµ¬_ì‹¤ì—…ë¥ ', 0):.1f}%")
    
    # 2. ì—°ë ¹ëŒ€ë³„ ë¶„ì„
    age_analysis = analyze_age_group_participation()
    if age_analysis:
        print(f"\nğŸ“ˆ ì—°ë ¹ëŒ€ë³„ ê²½ì œí™œë™ì°¸ê°€ìœ¨ (ìµœê·¼ 3ë…„ ë³€í™”):")
        for age_group, change in age_analysis['3ë…„_ë³€í™”'].items():
            print(f"   {age_group}: {change:+.1f}%p")
    
    # 3. ì‹œê°í™” ìƒì„±
    print(f"\nğŸ“Š ì‹œê°í™” ì°¨íŠ¸ ìƒì„± ì¤‘...")
    fig = plot_immigration_labor_trends()
    if fig:
        fig.show()
        print("âœ… ì´ë¯¼ ì •ì±… ê´€ë ¨ ë…¸ë™ì‹œì¥ ë¶„ì„ ì°¨íŠ¸ê°€ í‘œì‹œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    print(f"\në¶„ì„ ì™„ë£Œ ì‹œê°„: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)

# %%
# ê¸°ë³¸ ì‹¤í–‰ ì˜ˆì œ
if __name__ == "__main__":
    print("\n" + "="*60)
    print("ğŸš€ CPS ë…¸ë™ì‹œì¥ ë¶„ì„ ë„êµ¬ ì‹œì‘")
    print("="*60)
    
    # ë°ì´í„° ë¡œë“œ (CSV ìš°ì„ , ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ í¬í•¨)
    success = load_all_cps_data()
    
    if success:
        print("\nâœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ! ë¶„ì„ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("\nì˜ˆì‹œ: create_labor_market_dashboard() ì‹¤í–‰í•˜ì—¬ ëŒ€ì‹œë³´ë“œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    else:
        print("\nâŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨. ë¬¸ì œë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# %%
"""
=== ì¶”ê°€ ì‹œê°í™” ë° ë¶„ì„ í•¨ìˆ˜ë“¤ ===
house_price_and_sales.pyì™€ ë™ì¼í•œ êµ¬ì¡°ë¡œ êµ¬í˜„ëœ ë²”ìš© í•¨ìˆ˜ë“¤
"""

def show_series_summary():
    """ì „ì²´ ì‹œë¦¬ì¦ˆ ìš”ì•½ ì •ë³´ ì¶œë ¥"""
    if CPS_DATA is None:
        print("âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_cps_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    raw_data = CPS_DATA['raw']
    
    print("ğŸ“‹ CPS Employment Series Summary")
    print("=" * 60)
    
    # ì£¼ìš” ì¹´í…Œê³ ë¦¬ë³„ ì‹œë¦¬ì¦ˆ ì¹´ìš´íŠ¸
    unemployment_series = [col for col in raw_data.columns if 'LNS14' in col]
    participation_series = [col for col in raw_data.columns if 'LNS11' in col]
    employment_series = [col for col in raw_data.columns if 'LNS12' in col]
    other_series = [col for col in raw_data.columns if not any(x in col for x in ['LNS14', 'LNS11', 'LNS12'])]
    
    print(f"Unemployment Rate Series (LNS14xxx): {len(unemployment_series)}ê°œ")
    print(f"Labor Force Participation Series (LNS11xxx): {len(participation_series)}ê°œ") 
    print(f"Employment-Population Ratio Series (LNS12xxx): {len(employment_series)}ê°œ")
    print(f"Other Series: {len(other_series)}ê°œ")
    print(f"Total Series: {len(raw_data.columns)}ê°œ")
    print("=" * 60)
    
    # ìµœê·¼ ë°ì´í„° ìƒíƒœ
    latest_date = raw_data.index.max()
    print(f"Latest Data: {latest_date.strftime('%Y-%m-%d')}")
    
    # ì£¼ìš” ì‹œë¦¬ì¦ˆë³„ ìµœê·¼ê°’
    print("\nì£¼ìš” ì‹œë¦¬ì¦ˆë³„ ìµœê·¼ê°’:")
    key_series = ['LNS14000000', 'LNS11300000', 'LNS12300000', 'LNS13327709']
    series_names = {
        'LNS14000000': 'ì‹¤ì—…ë¥ ',
        'LNS11300000': 'ê²½ì œí™œë™ì°¸ê°€ìœ¨', 
        'LNS12300000': 'ê³ ìš©ë¥ ',
        'LNS13327709': 'U-6 ì‹¤ì—…ë¥ '
    }
    
    for series in key_series:
        if series in raw_data.columns:
            latest_value = raw_data[series].iloc[-1]
            print(f"  {series_names[series]} ({series}): {latest_value:.1f}%")

def plot_multi_line_chart(series_names, data_type='raw', title=None, ytitle=None, labels=None, 
                         width_cm=12, height_cm=8, start_date=None, end_date=None):
    """
    ë‹¤ì¤‘ ë¼ì¸ ì°¨íŠ¸ ê·¸ë¦¬ê¸°
    
    Parameters:
    - series_names: ì‹œë¦¬ì¦ˆ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
    - data_type: 'raw', 'yoy', 'mom' ì¤‘ ì„ íƒ
    - title: ì°¨íŠ¸ ì œëª© (Noneì´ë©´ ìë™ ìƒì„±)
    - ytitle: Yì¶• ì œëª©
    - labels: ì‹œë¦¬ì¦ˆ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸
    - width_cm, height_cm: ì°¨íŠ¸ í¬ê¸°
    - start_date, end_date: ë‚ ì§œ ë²”ìœ„ (YYYY-MM-DD í˜•ì‹)
    """
    if CPS_DATA is None:
        print("âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_cps_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    # ë°ì´í„° íƒ€ì…ì— ë”°ë¼ ë°ì´í„° ì„ íƒ
    if data_type == 'raw':
        data = get_raw_data(series_names)
        if ytitle is None:
            ytitle = "%"
    elif data_type == 'yoy':
        data = get_yoy_data(series_names)
        if ytitle is None:
            ytitle = "%"
    elif data_type == 'mom':
        data = get_mom_data(series_names)
        if ytitle is None:
            ytitle = "%"
    else:
        print("âŒ data_typeì€ 'raw', 'yoy', 'mom' ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        return
    
    if data is None:
        return
    
    # ë‚ ì§œ ë²”ìœ„ í•„í„°ë§
    if start_date:
        data = data[data.index >= start_date]
    if end_date:
        data = data[data.index <= end_date]
    
    # ìë™ ì œëª© ìƒì„±
    if title is None:
        data_type_names = {'raw': 'Labor Market Indicators', 'yoy': 'Labor Market YoY Changes', 'mom': 'Labor Market MoM Changes'}
        title = data_type_names.get(data_type, 'Labor Market Chart')
    
    # ì°¨íŠ¸ ì œëª© ì¶œë ¥ (ê·¸ë˜í”„ ìì²´ì—ëŠ” ë„£ì§€ ì•ŠìŒ)
    print(title)
    
    # KPDS ë‹¤ì¤‘ ë¼ì¸ ì°¨íŠ¸ ê·¸ë¦¬ê¸°
    df_multi_line_chart(
        df=data,
        columns=series_names,
        title="",  # ì œëª©ì€ ë¹ˆ ë¬¸ìì—´
        xtitle="Date",
        ytitle=ytitle,
        labels=labels,
        width_cm=width_cm,
        height_cm=height_cm
    )

def plot_dual_axis_chart(left_series, right_series, left_data_type='raw', right_data_type='raw',
                        left_labels=None, right_labels=None, left_ytitle=None, right_ytitle=None,
                        title=None, width_cm=12, height_cm=8, start_date=None, end_date=None):
    """
    ì´ì¤‘ ì¶• ì°¨íŠ¸ ê·¸ë¦¬ê¸°
    
    Parameters:
    - left_series: ì™¼ìª½ Yì¶• ì‹œë¦¬ì¦ˆ (ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ë¬¸ìì—´)
    - right_series: ì˜¤ë¥¸ìª½ Yì¶• ì‹œë¦¬ì¦ˆ (ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ë¬¸ìì—´)
    - left_data_type, right_data_type: 'raw', 'yoy', 'mom' ì¤‘ ì„ íƒ
    - left_labels, right_labels: ê° ì¶•ì˜ ì‹œë¦¬ì¦ˆ ë¼ë²¨
    - left_ytitle, right_ytitle: ê° ì¶•ì˜ ì œëª©
    - title: ì°¨íŠ¸ ì œëª©
    - width_cm, height_cm: ì°¨íŠ¸ í¬ê¸°
    - start_date, end_date: ë‚ ì§œ ë²”ìœ„
    """
    if CPS_DATA is None:
        print("âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_cps_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    # ì™¼ìª½ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    if left_data_type == 'raw':
        left_data = get_raw_data(left_series)
    elif left_data_type == 'yoy':
        left_data = get_yoy_data(left_series)
    elif left_data_type == 'mom':
        left_data = get_mom_data(left_series)
    else:
        print("âŒ left_data_typeì€ 'raw', 'yoy', 'mom' ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        return
    
    # ì˜¤ë¥¸ìª½ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    if right_data_type == 'raw':
        right_data = get_raw_data(right_series)
    elif right_data_type == 'yoy':
        right_data = get_yoy_data(right_series)
    elif right_data_type == 'mom':
        right_data = get_mom_data(right_series)
    else:
        print("âŒ right_data_typeì€ 'raw', 'yoy', 'mom' ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        return
    
    if left_data is None or right_data is None:
        return
    
    # ë°ì´í„° ê²°í•©
    combined_data = pd.concat([left_data, right_data], axis=1)
    
    # ë‚ ì§œ ë²”ìœ„ í•„í„°ë§
    if start_date:
        combined_data = combined_data[combined_data.index >= start_date]
    if end_date:
        combined_data = combined_data[combined_data.index <= end_date]
    
    # Yì¶• ì œëª© ìë™ ì„¤ì •
    if left_ytitle is None:
        left_ytitle = "%"
    
    if right_ytitle is None:
        right_ytitle = "%"
    
    # ìë™ ì œëª© ìƒì„±
    if title is None:
        title = "Labor Market Dual Axis Chart"
    
    # ì°¨íŠ¸ ì œëª© ì¶œë ¥
    print(title)
    
    # ì‹œë¦¬ì¦ˆë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if isinstance(left_series, str):
        left_series = [left_series]
    if isinstance(right_series, str):
        right_series = [right_series]
    
    # KPDS ì´ì¤‘ ì¶• ì°¨íŠ¸ ê·¸ë¦¬ê¸°
    df_dual_axis_chart(
        df=combined_data,
        left_cols=left_series,
        right_cols=right_series,
        left_labels=left_labels,
        right_labels=right_labels,
        left_title=left_ytitle,
        right_title=right_ytitle,
        title="",  # ì œëª©ì€ ë¹ˆ ë¬¸ìì—´
        xtitle="Date",
        width_cm=width_cm,
        height_cm=height_cm
    )

def plot_horizontal_bar_chart(series_names, data_type='raw', title=None, periods=12, labels=None):
    """
    ìˆ˜í‰ ë§‰ëŒ€ ì°¨íŠ¸ ê·¸ë¦¬ê¸° (ìµœê·¼ Nê°œì›” ë°ì´í„°)
    
    Parameters:
    - series_names: ì‹œë¦¬ì¦ˆ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
    - data_type: 'raw', 'yoy', 'mom' ì¤‘ ì„ íƒ
    - title: ì°¨íŠ¸ ì œëª©
    - periods: í‘œì‹œí•  ìµœê·¼ ê¸°ê°„ ìˆ˜ (ê¸°ë³¸ê°’: 12ê°œì›”)
    - labels: ì‹œë¦¬ì¦ˆ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸
    """
    if CPS_DATA is None:
        print("âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_cps_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    # ë°ì´í„° íƒ€ì…ì— ë”°ë¼ ë°ì´í„° ì„ íƒ
    if data_type == 'raw':
        data = get_raw_data(series_names)
    elif data_type == 'yoy':
        data = get_yoy_data(series_names)
    elif data_type == 'mom':
        data = get_mom_data(series_names)
    else:
        print("âŒ data_typeì€ 'raw', 'yoy', 'mom' ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        return
    
    if data is None:
        return
    
    # ìµœê·¼ Nê°œ ê¸°ê°„ ë°ì´í„°ë§Œ ì„ íƒ
    recent_data = data.tail(periods)
    
    # ìë™ ì œëª© ìƒì„±
    if title is None:
        data_type_names = {'raw': 'Labor Market Indicators', 'yoy': 'Labor Market YoY Changes', 'mom': 'Labor Market MoM Changes'}
        title = f"{data_type_names.get(data_type, 'Labor Market')} - Recent {periods} Months"
    
    # ì°¨íŠ¸ ì œëª© ì¶œë ¥
    print(title)
    
    # matplotlibì„ ì‚¬ìš©í•œ ìˆ˜í‰ ë§‰ëŒ€ ì°¨íŠ¸
    _, ax = plt.subplots(figsize=(10, 6))
    
    # ê° ì‹œë¦¬ì¦ˆë³„ë¡œ ë§‰ëŒ€ ê·¸ë¦¬ê¸°
    n_series = len(series_names)
    bar_height = 0.8 / n_series
    
    for i, series in enumerate(series_names):
        positions = range(len(recent_data))
        values = recent_data[series].values
        
        # ë¼ë²¨ ì„¤ì •
        if labels and i < len(labels):
            label = labels[i]
        else:
            label = series
        
        ax.barh([p + i * bar_height for p in positions], values, 
                bar_height, label=label, alpha=0.8)
    
    # ì¶• ì„¤ì •
    ax.set_yticks([p + bar_height * (n_series - 1) / 2 for p in range(len(recent_data))])
    ax.set_yticklabels([d.strftime('%Y-%m') for d in recent_data.index])
    ax.invert_yaxis()  # ìµœì‹  ë°ì´í„°ë¥¼ ìœ„ì— í‘œì‹œ
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

def plot_series(series_names, chart_type='multi_line', data_type='raw', title=None, 
               labels=None, width_cm=12, height_cm=8, start_date=None, end_date=None,
               periods=12, left_ytitle=None, right_ytitle=None):
    """
    ì¢…í•©ì ì¸ ì‹œê°í™” í•¨ìˆ˜ - ì›í•˜ëŠ” ì‹œë¦¬ì¦ˆ, ì°¨íŠ¸ íƒ€ì…, ë°ì´í„° ë³€í™˜ì„ í•œ ë²ˆì— ì„ íƒ
    
    Parameters:
    - series_names: ì‹œë¦¬ì¦ˆ ì´ë¦„ (ë¬¸ìì—´ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸)
                   dual_axisì˜ ê²½ìš°: [left_series, right_series] ë˜ëŠ” [[left1, left2], [right1, right2]]
    - chart_type: 'multi_line', 'dual_axis', 'horizontal_bar' ì¤‘ ì„ íƒ
    - data_type: 'raw', 'yoy', 'mom' ì¤‘ ì„ íƒ
                dual_axisì˜ ê²½ìš°: 'raw' ë˜ëŠ” ['left_type', 'right_type']
    - title: ì°¨íŠ¸ ì œëª© (Noneì´ë©´ ìë™ ìƒì„±)
    - labels: ì‹œë¦¬ì¦ˆ ë¼ë²¨ (dual_axisì˜ ê²½ìš°: [left_labels, right_labels])
    - width_cm, height_cm: ì°¨íŠ¸ í¬ê¸°
    - start_date, end_date: ë‚ ì§œ ë²”ìœ„ (YYYY-MM-DD í˜•ì‹)
    - periods: horizontal_barì—ì„œ í‘œì‹œí•  ìµœê·¼ ê¸°ê°„ ìˆ˜
    - left_ytitle, right_ytitle: dual_axisì—ì„œ Yì¶• ì œëª©
    
    Examples:
    # ë‹¤ì¤‘ ë¼ì¸ ì°¨íŠ¸
    plot_series(['LNS14000000', 'LNS11300000'], 'multi_line', 'raw')
    
    # ì´ì¤‘ ì¶• ì°¨íŠ¸ (ê°™ì€ ë°ì´í„° íƒ€ì…)
    plot_series(['LNS14000000', 'LNS13327709'], 'dual_axis', 'raw')
    
    # ì´ì¤‘ ì¶• ì°¨íŠ¸ (ë‹¤ë¥¸ ë°ì´í„° íƒ€ì…)
    plot_series(['LNS14000000', 'LNS13327709'], 'dual_axis', ['raw', 'yoy'])
    
    # ìˆ˜í‰ ë§‰ëŒ€ ì°¨íŠ¸
    plot_series(['LNS14000000'], 'horizontal_bar', 'mom', periods=6)
    """
    if CPS_DATA is None:
        print("âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_cps_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    # ì°¨íŠ¸ íƒ€ì…ë³„ ì²˜ë¦¬
    if chart_type == 'multi_line':
        plot_multi_line_chart(
            series_names=series_names,
            data_type=data_type,
            title=title,
            labels=labels,
            width_cm=width_cm,
            height_cm=height_cm,
            start_date=start_date,
            end_date=end_date
        )
        
    elif chart_type == 'dual_axis':
        # series_namesê°€ 2ê°œ ìš”ì†Œë¥¼ ê°€ì ¸ì•¼ í•¨
        if not isinstance(series_names, list) or len(series_names) != 2:
            print("âŒ dual_axisì—ì„œëŠ” series_namesê°€ [left_series, right_series] í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.")
            return
        
        left_series = series_names[0]
        right_series = series_names[1]
        
        # data_type ì²˜ë¦¬
        if isinstance(data_type, list) and len(data_type) == 2:
            left_data_type = data_type[0]
            right_data_type = data_type[1]
        else:
            left_data_type = data_type
            right_data_type = data_type
        
        # labels ì²˜ë¦¬
        if labels and isinstance(labels, list) and len(labels) == 2:
            left_labels = labels[0] if isinstance(labels[0], list) else [labels[0]]
            right_labels = labels[1] if isinstance(labels[1], list) else [labels[1]]
        else:
            left_labels = None
            right_labels = None
        
        plot_dual_axis_chart(
            left_series=left_series,
            right_series=right_series,
            left_data_type=left_data_type,
            right_data_type=right_data_type,
            left_labels=left_labels,
            right_labels=right_labels,
            left_ytitle=left_ytitle,
            right_ytitle=right_ytitle,
            title=title,
            width_cm=width_cm,
            height_cm=height_cm,
            start_date=start_date,
            end_date=end_date
        )
        
    elif chart_type == 'horizontal_bar':
        plot_horizontal_bar_chart(
            series_names=series_names,
            data_type=data_type,
            title=title,
            periods=periods,
            labels=labels
        )
        
    else:
        print("âŒ chart_typeì€ 'multi_line', 'dual_axis', 'horizontal_bar' ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        print("ì‚¬ìš© ê°€ëŠ¥í•œ ì°¨íŠ¸ íƒ€ì…:")
        print("  - 'multi_line': ë‹¤ì¤‘ ë¼ì¸ ì°¨íŠ¸")
        print("  - 'dual_axis': ì´ì¤‘ ì¶• ì°¨íŠ¸")
        print("  - 'horizontal_bar': ìˆ˜í‰ ë§‰ëŒ€ ì°¨íŠ¸")

def create_labor_market_dashboard_enhanced(data_type='raw'):
    """
    ì£¼ìš” ë…¸ë™ì‹œì¥ ì§€í‘œë“¤ì˜ ëŒ€ì‹œë³´ë“œ ìƒì„± (í–¥ìƒëœ ë²„ì „)
    
    Parameters:
    - data_type: 'raw', 'yoy', 'mom' ì¤‘ ì„ íƒ
    """
    key_series = ['LNS14000000', 'LNS11300000', 'LNS12300000', 'LNS13327709']
    labels = ['ì‹¤ì—…ë¥ ', 'ê²½ì œí™œë™ì°¸ê°€ìœ¨', 'ê³ ìš©ë¥ ', 'U-6 ì‹¤ì—…ë¥ ']
    
    plot_series(
        series_names=key_series,
        chart_type='multi_line',
        data_type=data_type,
        title=f"Major Labor Market Indicators ({data_type.upper()})",
        labels=labels,
        width_cm=14,
        height_cm=9
    )

# %%
run_complete_cps_analysis()
# %%
list_available_series()
# %%
print_load_info()
# %%
labels = {'LNS11000000' : "ê²½ì œí™œë™ì¸êµ¬", 'LNS11300000' : "ê²½ì œí™œë™ì°¸ê°€ìœ¨(ìš°)"}
plot_cps_series(['LNS11000000', 'LNS11300000'], chart_type='dual_axis', data_type='raw', left_ytitle='ì²œ ëª…', right_ytitle='%', labels=labels)
# %%
plot_cps_series(['LNS13000000'], chart_type='single_line', data_type='raw')
# %%
plot_cps_series(['LNU01076975', 'LNU01000048', 'LNU01000092', 'LNU01024230', 'LNU01000097'], chart_type='multi_line', data_type='raw')

# %%
plot_cps_series(['LNU05000097', 'LNU05024230'], chart_type='multi_line', data_type='raw')

# %%
plot_cps_series(['LNU01000003', 'LNU01000006', 'LNU01032183', 'LNU01035243', 'LNU01035553'], chart_type='multi_line', data_type='raw')

# %%