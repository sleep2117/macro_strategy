# %%
"""
BLS API ì „ìš© PPI ë¶„ì„ ë° ì‹œê°í™” ë„êµ¬
- BLS APIë§Œ ì‚¬ìš©í•˜ì—¬ PPI ë°ì´í„° ìˆ˜ì§‘
- ê³„ì¸µêµ¬ì¡°ë³„ ë°ì´í„° ë¶„ë¥˜
- YoY/MoM ê¸°ì¤€ ì‹œê°í™” ì§€ì›
- CSV ì €ì¥/ë¡œë“œ ë° ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸
"""
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import sys
import warnings
warnings.filterwarnings('ignore')

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    import requests
    import json
    BLS_API_AVAILABLE = True
    print("âœ“ BLS API ì—°ë™ ê°€ëŠ¥ (requests ë¼ì´ë¸ŒëŸ¬ë¦¬)")
except ImportError:
    print("âš ï¸ requests ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜í•˜ì„¸ìš”: pip install requests")
    BLS_API_AVAILABLE = False

# BLS API í‚¤ ì„¤ì • (CPIì™€ ë™ì¼)
BLS_API_KEY = '56b193612b614cdc9416359fd1c73a74'
BLS_API_KEY2 = '0450ef37363c48b5bedd2ae6fc92dd6e'
BLS_API_KEY3 = 'daf1ca7970b74e81b6a5c7a80a8b8a7f'
CURRENT_API_KEY = BLS_API_KEY2

# ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
sys.path.append('/home/jyp0615')
from kpds_fig_format_enhanced import *

# %%
# === PPI ì‹œë¦¬ì¦ˆ IDì™€ í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘ ===

# PPI ì‹œë¦¬ì¦ˆ IDì™€ í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘
PPI_SERIES = {
    # Final Demand (ìµœì¢… ìˆ˜ìš”)
    'WPSFD4': 'Final demand',
    'WPSFD41': 'Final demand goods',
    'WPSFD411': 'Final demand foods',
    'WPSFD412': 'Final demand energy',
    'WPSFD49104': 'Final demand less foods and energy',
    'WPSFD49116': 'Final demand less foods, energy, & trade services',
    'WPSFD42': 'Final demand services',
    'WPSFD422': 'Final demand transportation and warehousing',
    'WPSFD423': 'Final demand trade services',
    'WPSFD421': 'Final demand services less trade, trans., wrhsg',
    'WPSFD43': 'Final demand construction',

    # Final Demand (ìµœì¢… ìˆ˜ìš”) - ê³„ì ˆë¯¸ì¡°ì •
    'WPUFD4': 'Final demand',
    'WPUFD41': 'Final demand goods',
    'WPUFD411': 'Final demand foods',
    'WPUFD412': 'Final demand energy',
    'WPUFD49104': 'Final demand less foods and energy',
    'WPUFD49116': 'Final demand less foods, energy, & trade services',
    'WPUFD42': 'Final demand services',
    'WPUFD422': 'Final demand transportation and warehousing',
    'WPUFD423': 'Final demand trade services',
    'WPUFD421': 'Final demand services less trade, trans., wrhsg',
    'WPUFD43': 'Final demand construction',
    
    # Intermediate Demand (ì¤‘ê°„ ìˆ˜ìš”)
    'WPSID61': 'Processed goods for intermediate demand',
    'WPSID62': 'Unprocessed goods for intermediate demand',
    'WPSID63': 'Services for intermediate demand',
    'WPSID54': 'Stage 4 intermediate demand',
    'WPSID53': 'Stage 3 intermediate demand',
    'WPSID52': 'Stage 2 intermediate demand',
    'WPSID51': 'Stage 1 intermediate demand',
    
    # Specific Commodities (ì£¼ìš” í’ˆëª©)
    'WPS1411': 'Motor vehicles',
    'WPS0638': 'Pharmaceutical preparations',
    'WPS0571': 'Gasoline',
    'WPS0221': 'Meats',
    'WPS061': 'Industrial chemicals',
    'WPS081': 'Lumber',
    'WPS1017': 'Steel mill products',
    'WPS057303': 'Diesel fuel',
    'WPS029': 'Prepared animal feeds',
    'WPS0561': 'Crude petroleum',
    'WPS012': 'Grains',
    'WPS101211': 'Carbon steel scrap',
    
    # Services (ì„œë¹„ìŠ¤)
    'WPS5111': 'Outpatient healthcare',
    'WPS5121': 'Inpatient healthcare services',
    'WPS5811': 'Food and alcohol retailing',
    'WPS5831': 'Apparel and jewelry retailing',
    'WPS3022': 'Airline passenger services',
    'WPS4011': 'Securities brokerage, investment, and related',
    'WPS3911': 'Business loans (partial)',
    'WPS4511': 'Legal services',
    'WPS301': 'Truck transportation of freight',
    'WPS057': 'Machinery and equipment wholesaling',
    
    # Finished Goods (ì™„ì œí’ˆ)
    'WPSFD49207': 'Finished goods',
    'WPSFD4131': 'Finished core',
    
    # All Commodities (ì „ì²´ ìƒí’ˆ)
    'WPSSOP3000': 'All commodities',
    'WPS03THRU15': 'Industrial commodities'
}

# í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘
PPI_KOREAN_NAMES = {
    # Final Demand (ìµœì¢…ìˆ˜ìš”) - ê³„ì ˆì¡°ì •
    'WPSFD4': 'ìµœì¢…ìˆ˜ìš” (ê³„ì ˆì¡°ì •)',
    'WPSFD41': 'ìµœì¢…ìˆ˜ìš” ì¬í™” (ê³„ì ˆì¡°ì •)',
    'WPSFD411': 'ìµœì¢…ìˆ˜ìš” ì‹í’ˆ (ê³„ì ˆì¡°ì •)',
    'WPSFD412': 'ìµœì¢…ìˆ˜ìš” ì—ë„ˆì§€ (ê³„ì ˆì¡°ì •)',
    'WPSFD49104': 'ìµœì¢…ìˆ˜ìš”(ì‹í’ˆÂ·ì—ë„ˆì§€ ì œì™¸) (ê³„ì ˆì¡°ì •)',
    'WPSFD49116': 'ìµœì¢…ìˆ˜ìš”(ì‹í’ˆÂ·ì—ë„ˆì§€Â·ë¬´ì—­ì„œë¹„ìŠ¤ ì œì™¸) (ê³„ì ˆì¡°ì •)',
    'WPSFD42': 'ìµœì¢…ìˆ˜ìš” ì„œë¹„ìŠ¤ (ê³„ì ˆì¡°ì •)',
    'WPSFD422': 'ìµœì¢…ìˆ˜ìš” ìš´ì†¡Â·ì°½ê³ ì—… (ê³„ì ˆì¡°ì •)',
    'WPSFD423': 'ìµœì¢…ìˆ˜ìš” ë¬´ì—­ì„œë¹„ìŠ¤ (ê³„ì ˆì¡°ì •)',
    'WPSFD421': 'ìµœì¢…ìˆ˜ìš” ì„œë¹„ìŠ¤(ë¬´ì—­Â·ìš´ì†¡Â·ì°½ê³  ì œì™¸) (ê³„ì ˆì¡°ì •)',
    'WPSFD43': 'ìµœì¢…ìˆ˜ìš” ê±´ì„¤ì—… (ê³„ì ˆì¡°ì •)',
    
    # Final Demand (ìµœì¢…ìˆ˜ìš”) - ê³„ì ˆë¯¸ì¡°ì •
    'WPUFD4': 'ìµœì¢…ìˆ˜ìš”',
    'WPUFD41': 'ìµœì¢…ìˆ˜ìš” ì¬í™”',
    'WPUFD411': 'ìµœì¢…ìˆ˜ìš” ì‹í’ˆ',
    'WPUFD412': 'ìµœì¢…ìˆ˜ìš” ì—ë„ˆì§€',
    'WPUFD49104': 'ìµœì¢…ìˆ˜ìš”(ì‹í’ˆÂ·ì—ë„ˆì§€ ì œì™¸)',
    'WPUFD49116': 'ìµœì¢…ìˆ˜ìš”(ì‹í’ˆÂ·ì—ë„ˆì§€Â·ë¬´ì—­ì„œë¹„ìŠ¤ ì œì™¸)',
    'WPUFD42': 'ìµœì¢…ìˆ˜ìš” ì„œë¹„ìŠ¤',
    'WPUFD422': 'ìµœì¢…ìˆ˜ìš” ìš´ì†¡Â·ì°½ê³ ì—…',
    'WPUFD423': 'ìµœì¢…ìˆ˜ìš” ë¬´ì—­ì„œë¹„ìŠ¤',
    'WPUFD421': 'ìµœì¢…ìˆ˜ìš” ì„œë¹„ìŠ¤(ë¬´ì—­Â·ìš´ì†¡Â·ì°½ê³  ì œì™¸)',
    'WPUFD43': 'ìµœì¢…ìˆ˜ìš” ê±´ì„¤ì—…',
    
    # Intermediate Demand (ì¤‘ê°„ìˆ˜ìš”) - ê³„ì ˆì¡°ì •
    'WPSID61': 'ì¤‘ê°„ìˆ˜ìš” ê°€ê³µì¬ (ê³„ì ˆì¡°ì •)',
    'WPSID62': 'ì¤‘ê°„ìˆ˜ìš” ë¯¸ê°€ê³µì¬ (ê³„ì ˆì¡°ì •)',
    'WPSID63': 'ì¤‘ê°„ìˆ˜ìš” ì„œë¹„ìŠ¤ (ê³„ì ˆì¡°ì •)',
    'WPSID54': '4ë‹¨ê³„ ì¤‘ê°„ìˆ˜ìš” (ê³„ì ˆì¡°ì •)',
    'WPSID53': '3ë‹¨ê³„ ì¤‘ê°„ìˆ˜ìš” (ê³„ì ˆì¡°ì •)',
    'WPSID52': '2ë‹¨ê³„ ì¤‘ê°„ìˆ˜ìš” (ê³„ì ˆì¡°ì •)',
    'WPSID51': '1ë‹¨ê³„ ì¤‘ê°„ìˆ˜ìš” (ê³„ì ˆì¡°ì •)',
    
    # Intermediate Demand (ì¤‘ê°„ìˆ˜ìš”) - ê³„ì ˆë¯¸ì¡°ì • (ì¼ë°˜ì ìœ¼ë¡œ WPU ì ‘ë‘ì‚¬ ì‚¬ìš©)
    'WPUID61': 'ì¤‘ê°„ìˆ˜ìš” ê°€ê³µì¬',
    'WPUID62': 'ì¤‘ê°„ìˆ˜ìš” ë¯¸ê°€ê³µì¬',
    'WPUID63': 'ì¤‘ê°„ìˆ˜ìš” ì„œë¹„ìŠ¤',
    'WPUID54': '4ë‹¨ê³„ ì¤‘ê°„ìˆ˜ìš”',
    'WPUID53': '3ë‹¨ê³„ ì¤‘ê°„ìˆ˜ìš”',
    'WPUID52': '2ë‹¨ê³„ ì¤‘ê°„ìˆ˜ìš”',
    'WPUID51': '1ë‹¨ê³„ ì¤‘ê°„ìˆ˜ìš”',
    
    # Specific Commodities (ì£¼ìš” í’ˆëª©) - ê³„ì ˆì¡°ì •
    'WPS1411': 'ìë™ì°¨ (ê³„ì ˆì¡°ì •)',
    'WPS0638': 'ì˜ì•½í’ˆ (ê³„ì ˆì¡°ì •)',
    'WPS0571': 'ê°€ì†”ë¦° (ê³„ì ˆì¡°ì •)',
    'WPS0221': 'ìœ¡ë¥˜ (ê³„ì ˆì¡°ì •)',
    'WPS061': 'ì‚°ì—…í™”í•™ (ê³„ì ˆì¡°ì •)',
    'WPS081': 'ëª©ì¬ (ê³„ì ˆì¡°ì •)',
    'WPS1017': 'ì œì²  ì œí’ˆ (ê³„ì ˆì¡°ì •)',
    'WPS057303': 'ë””ì ¤ì—°ë£Œ (ê³„ì ˆì¡°ì •)',
    'WPS029': 'ì‚¬ë£Œ (ê³„ì ˆì¡°ì •)',
    'WPS0561': 'ì›ìœ  (ê³„ì ˆì¡°ì •)',
    'WPS012': 'ê³¡ë¬¼ (ê³„ì ˆì¡°ì •)',
    'WPS101211': 'íƒ„ì†Œê°• ìŠ¤í¬ë© (ê³„ì ˆì¡°ì •)',
    
    # Specific Commodities (ì£¼ìš” í’ˆëª©) - ê³„ì ˆë¯¸ì¡°ì •
    'WPU1411': 'ìë™ì°¨',
    'WPU0638': 'ì˜ì•½í’ˆ',
    'WPU0571': 'ê°€ì†”ë¦°',
    'WPU0221': 'ìœ¡ë¥˜',
    'WPU061': 'ì‚°ì—…í™”í•™',
    'WPU081': 'ëª©ì¬',
    'WPU1017': 'ì œì²  ì œí’ˆ',
    'WPU057303': 'ë””ì ¤ì—°ë£Œ',
    'WPU029': 'ì‚¬ë£Œ',
    'WPU0561': 'ì›ìœ ',
    'WPU012': 'ê³¡ë¬¼',
    'WPU101211': 'íƒ„ì†Œê°• ìŠ¤í¬ë©',
    
    # Services (ì„œë¹„ìŠ¤) - ê³„ì ˆì¡°ì •
    'WPS5111': 'ì™¸ë˜ ì˜ë£Œì„œë¹„ìŠ¤ (ê³„ì ˆì¡°ì •)',
    'WPS5121': 'ì…ì› ì˜ë£Œì„œë¹„ìŠ¤ (ê³„ì ˆì¡°ì •)',
    'WPS5811': 'ì‹í’ˆÂ·ì£¼ë¥˜ ì†Œë§¤ (ê³„ì ˆì¡°ì •)',
    'WPS5831': 'ì˜ë¥˜Â·ë³´ì„ ì†Œë§¤ (ê³„ì ˆì¡°ì •)',
    'WPS3022': 'í•­ê³µ ìŠ¹ê° ì„œë¹„ìŠ¤ (ê³„ì ˆì¡°ì •)',
    'WPS4011': 'ì¦ê¶Œì¤‘ê°œÂ·íˆ¬ì ê´€ë ¨ (ê³„ì ˆì¡°ì •)',
    'WPS3911': 'ê¸°ì—… ëŒ€ì¶œ(ë¶€ë¶„) (ê³„ì ˆì¡°ì •)',
    'WPS4511': 'ë²•ë¥  ì„œë¹„ìŠ¤ (ê³„ì ˆì¡°ì •)',
    'WPS301': 'í™”ë¬¼ íŠ¸ëŸ­ ìš´ì†¡ (ê³„ì ˆì¡°ì •)',
    'WPS057': 'ê¸°ê³„Â·ì¥ë¹„ ë„ë§¤ (ê³„ì ˆì¡°ì •)',
    
    # Services (ì„œë¹„ìŠ¤) - ê³„ì ˆë¯¸ì¡°ì •
    'WPU5111': 'ì™¸ë˜ ì˜ë£Œì„œë¹„ìŠ¤',
    'WPU5121': 'ì…ì› ì˜ë£Œì„œë¹„ìŠ¤',
    'WPU5811': 'ì‹í’ˆÂ·ì£¼ë¥˜ ì†Œë§¤',
    'WPU5831': 'ì˜ë¥˜Â·ë³´ì„ ì†Œë§¤',
    'WPU3022': 'í•­ê³µ ìŠ¹ê° ì„œë¹„ìŠ¤',
    'WPU4011': 'ì¦ê¶Œì¤‘ê°œÂ·íˆ¬ì ê´€ë ¨',
    'WPU3911': 'ê¸°ì—… ëŒ€ì¶œ(ë¶€ë¶„)',
    'WPU4511': 'ë²•ë¥  ì„œë¹„ìŠ¤',
    'WPU3012': 'í™”ë¬¼ íŠ¸ëŸ­ ìš´ì†¡',
    'WPU571': 'ê¸°ê³„Â·ì¥ë¹„ ë„ë§¤',
    
    # Finished Goods (ì™„ì œí’ˆ) - ê³„ì ˆì¡°ì •
    'WPSFD49207': 'ì™„ì œí’ˆ (ê³„ì ˆì¡°ì •)',
    'WPSFD4131': 'ì™„ì œí’ˆ ì½”ì–´ (ê³„ì ˆì¡°ì •)',
    
    # Finished Goods (ì™„ì œí’ˆ) - ê³„ì ˆë¯¸ì¡°ì •
    'WPUFD49207': 'ì™„ì œí’ˆ',
    'WPUFD4131': 'ì™„ì œí’ˆ ì½”ì–´',
    
    # All Commodities (ì „ì²´ ìƒí’ˆ) - ê³„ì ˆì¡°ì •
    'WPS00000000': 'ì „ì²´ ìƒí’ˆ (ê³„ì ˆì¡°ì •)',
    'WPS03THRU15': 'ì‚°ì—… ìƒí’ˆ (ê³„ì ˆì¡°ì •)',
    
    # All Commodities (ì „ì²´ ìƒí’ˆ) - ê³„ì ˆë¯¸ì¡°ì •
    'WPSSOP3000': 'ì „ì²´ ìƒí’ˆ',
    'WPU03THRU15': 'ì‚°ì—… ìƒí’ˆ'
}

# ìƒˆë¡œìš´ ë¶„ë¥˜ ì²´ê³„ (ê³„ì ˆì¡°ì •/ë¯¸ì¡°ì • êµ¬ë¶„)
PPI_CATEGORIES = {
    'ìµœì¢…ìˆ˜ìš”_ê³„ì ˆì¡°ì •': {
        'ìµœì¢…ìˆ˜ìš” ì „ì²´': ['WPSFD4'],
        'ìµœì¢…ìˆ˜ìš” ì¬í™”': ['WPSFD41', 'WPSFD411', 'WPSFD412'],
        'ìµœì¢…ìˆ˜ìš” ì„œë¹„ìŠ¤': ['WPSFD42', 'WPSFD422', 'WPSFD423', 'WPSFD421'],
        'ìµœì¢…ìˆ˜ìš” ê±´ì„¤': ['WPSFD43'],
        'ìµœì¢…ìˆ˜ìš” ì½”ì–´': ['WPSFD49104', 'WPSFD49116']
    },
    'ìµœì¢…ìˆ˜ìš”': {
        'ìµœì¢…ìˆ˜ìš” ì „ì²´': ['WPUFD4'],
        'ìµœì¢…ìˆ˜ìš” ì¬í™”': ['WPUFD41', 'WPUFD411', 'WPUFD412'],
        'ìµœì¢…ìˆ˜ìš” ì„œë¹„ìŠ¤': ['WPUFD42', 'WPUFD422', 'WPUFD423', 'WPUFD421'],
        'ìµœì¢…ìˆ˜ìš” ê±´ì„¤': ['WPUFD43'],
        'ìµœì¢…ìˆ˜ìš” ì½”ì–´': ['WPUFD49104', 'WPUFD49116']
    },
    'ì¤‘ê°„ìˆ˜ìš”_ê³„ì ˆì¡°ì •': {
        'ì¤‘ê°„ìˆ˜ìš” ê°€ê³µì¬': ['WPSID61'],
        'ì¤‘ê°„ìˆ˜ìš” ë¯¸ê°€ê³µì¬': ['WPSID62'],
        'ì¤‘ê°„ìˆ˜ìš” ì„œë¹„ìŠ¤': ['WPSID63'],
        'ì¤‘ê°„ìˆ˜ìš” ë‹¨ê³„ë³„': ['WPSID54', 'WPSID53', 'WPSID52', 'WPSID51']
    },
    'ì¤‘ê°„ìˆ˜ìš”': {
        'ì¤‘ê°„ìˆ˜ìš” ê°€ê³µì¬': ['WPUID61'],
        'ì¤‘ê°„ìˆ˜ìš” ë¯¸ê°€ê³µì¬': ['WPUID62'],
        'ì¤‘ê°„ìˆ˜ìš” ì„œë¹„ìŠ¤': ['WPUID63'],
        'ì¤‘ê°„ìˆ˜ìš” ë‹¨ê³„ë³„': ['WPUID54', 'WPUID53', 'WPUID52', 'WPUID51']
    },
    'ì£¼ìš”í’ˆëª©_ê³„ì ˆì¡°ì •': {
        'ì—ë„ˆì§€ ê´€ë ¨': ['WPS0571', 'WPS057303', 'WPS0561'],
        'ì œì¡°ì—…': ['WPS1411', 'WPS0638', 'WPS061', 'WPS081', 'WPS1017'],
        'ì‹í’ˆ ë†ì—…': ['WPS0221', 'WPS029', 'WPS012', 'WPS101211']
    },
    'ì£¼ìš”í’ˆëª©': {
        'ì—ë„ˆì§€ ê´€ë ¨': ['WPU0571', 'WPU057303', 'WPU0561'],
        'ì œì¡°ì—…': ['WPU1411', 'WPU0638', 'WPU061', 'WPU081', 'WPU1017'],
        'ì‹í’ˆ ë†ì—…': ['WPU0221', 'WPU029', 'WPU012', 'WPU101211']
    },
    'ì„œë¹„ìŠ¤_ê³„ì ˆì¡°ì •': {
        'ì˜ë£Œì„œë¹„ìŠ¤': ['WPS5111', 'WPS5121'],
        'ë¹„ì¦ˆë‹ˆìŠ¤ì„œë¹„ìŠ¤': ['WPS4011', 'WPS3911', 'WPS4511'],
        'ìš´ì†¡ì„œë¹„ìŠ¤': ['WPS3022', 'WPS3012'],
        'ì†Œë§¤ì„œë¹„ìŠ¤': ['WPS5811', 'WPS5831', 'WPS571']
    },
    'ì„œë¹„ìŠ¤': {
        'ì˜ë£Œì„œë¹„ìŠ¤': ['WPU5111', 'WPU5121'],
        'ë¹„ì¦ˆë‹ˆìŠ¤ì„œë¹„ìŠ¤': ['WPU4011', 'WPU3911', 'WPU4511'],
        'ìš´ì†¡ì„œë¹„ìŠ¤': ['WPU3022', 'WPU3012'],
        'ì†Œë§¤ì„œë¹„ìŠ¤': ['WPU5811', 'WPU5831', 'WPU571']
    },
    'ì™„ì œí’ˆ_ê³„ì ˆì¡°ì •': {
        'ì™„ì œí’ˆ ì „ì²´': ['WPSFD49207'],
        'ì™„ì œí’ˆ ì½”ì–´': ['WPSFD4131']
    },
    'ì™„ì œí’ˆ': {
        'ì™„ì œí’ˆ ì „ì²´': ['WPUFD49207'],
        'ì™„ì œí’ˆ ì½”ì–´': ['WPUFD4131']
    },
    'ì „ì²´ìƒí’ˆ_ê³„ì ˆì¡°ì •': {
        'ì „ì²´ ìƒí’ˆ': ['WPS00000000'],
        'ì‚°ì—… ìƒí’ˆ': ['WPS03THRU15']
    },
    'ì „ì²´ìƒí’ˆ': {
        'ì „ì²´ ìƒí’ˆ': ['WPU00000000'],
        'ì‚°ì—… ìƒí’ˆ': ['WPU03THRU15']
    }
}

# ê¸°ì¡´ PPI ê³„ì¸µ êµ¬ì¡° (í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)
PPI_HIERARCHY = {
    'ìµœìƒìœ„': {
        'ì „ì²´ ìƒí’ˆ': ['WPU00000000'],
        'ìµœì¢…ìˆ˜ìš”': ['WPUFD4'],
        'ì¤‘ê°„ìˆ˜ìš”': ['WPUID61', 'WPUID62', 'WPUID63']
    },
    'ìƒìœ„': {
        'ìµœì¢…ìˆ˜ìš” ì¬í™”': ['WPUFD41'],
        'ìµœì¢…ìˆ˜ìš” ì„œë¹„ìŠ¤': ['WPUFD42'],
        'ìµœì¢…ìˆ˜ìš” ê±´ì„¤': ['WPUFD43'],
        'ìµœì¢…ìˆ˜ìš” ì½”ì–´': ['WPUFD49104']
    },
    'ì¤‘ìœ„': {
        'ì‹í’ˆ': ['WPUFD411'],
        'ì—ë„ˆì§€': ['WPUFD412'],
        'ìë™ì°¨': ['WPU1411'],
        'ì˜ì•½í’ˆ': ['WPU0638'],
        'ê°€ì†”ë¦°': ['WPU0571']
    }
}

# %%
# === ì „ì—­ ë°ì´í„° ì €ì¥ì†Œ ===

# API ì„¤ì •
BLS_SESSION = None
API_INITIALIZED = False

# ì „ì—­ ë°ì´í„° ì €ì¥ì†Œ
PPI_DATA = {
    'raw_data': pd.DataFrame(),      # ì›ë³¸ ë ˆë²¨ ë°ì´í„°
    'yoy_data': pd.DataFrame(),      # ì „ë…„ë™ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ë°ì´í„°
    'mom_data': pd.DataFrame(),      # ì „ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ë°ì´í„°
    'latest_values': {},             # ìµœì‹  YoY ê°’ë“¤
    'load_info': {
        'loaded': False,
        'load_time': None,
        'start_date': None,
        'series_count': 0,
        'data_points': 0
    }
}

# %%
# === API ì´ˆê¸°í™” í•¨ìˆ˜ ===

def initialize_bls_api():
    """BLS API ì„¸ì…˜ ì´ˆê¸°í™”"""
    global BLS_SESSION
    
    if not BLS_API_AVAILABLE:
        print("âš ï¸ BLS API ì‚¬ìš© ë¶ˆê°€ (requests ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ)")
        return False
    
    try:
        BLS_SESSION = requests.Session()
        print("âœ“ BLS API ì„¸ì…˜ ì´ˆê¸°í™” ì„±ê³µ")
        return True
    except Exception as e:
        print(f"âš ï¸ BLS API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def switch_api_key():
    """API í‚¤ë¥¼ ì „í™˜í•˜ëŠ” í•¨ìˆ˜"""
    global CURRENT_API_KEY
    if CURRENT_API_KEY == BLS_API_KEY:
        CURRENT_API_KEY = BLS_API_KEY2
        print("ğŸ”„ BLS API í‚¤ë¥¼ BLS_API_KEY2ë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.")
    elif CURRENT_API_KEY == BLS_API_KEY2:
        CURRENT_API_KEY = BLS_API_KEY3
        print("ğŸ”„ BLS API í‚¤ë¥¼ BLS_API_KEY3ë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.")
    else:
        CURRENT_API_KEY = BLS_API_KEY
        print("ğŸ”„ BLS API í‚¤ë¥¼ BLS_API_KEYë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.")

def get_bls_data(series_id, start_year=2020, end_year=None):
    """
    BLS APIì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (API í‚¤ ì´ì¤‘í™” ì§€ì›)
    
    Args:
        series_id: BLS ì‹œë¦¬ì¦ˆ ID
        start_year: ì‹œì‘ ì—°ë„
        end_year: ì¢…ë£Œ ì—°ë„ (Noneì´ë©´ í˜„ì¬ ì—°ë„)
    
    Returns:
        pandas.Series: ë‚ ì§œë¥¼ ì¸ë±ìŠ¤ë¡œ í•˜ëŠ” ì‹œë¦¬ì¦ˆ ë°ì´í„°
    """
    global CURRENT_API_KEY
    
    if not BLS_API_AVAILABLE or BLS_SESSION is None:
        print(f"âŒ BLS API ì‚¬ìš© ë¶ˆê°€ - {series_id}")
        return None
    
    if end_year is None:
        end_year = datetime.datetime.now().year
    
    # BLS API ìš”ì²­ ë°ì´í„°
    data = {
        'seriesid': [series_id],
        'startyear': str(start_year),
        'endyear': str(end_year),
        'catalog': False,
        'calculations': False,
        'annualaverage': False
    }
    
    # í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ API í‚¤ ì¶”ê°€
    if CURRENT_API_KEY:
        data['registrationkey'] = CURRENT_API_KEY
    
    url = 'https://api.bls.gov/publicAPI/v2/timeseries/data/'
    headers = {'Content-type': 'application/json'}
    
    try:
        current_key_name = "ì£¼ìš”" if CURRENT_API_KEY == BLS_API_KEY else "ë°±ì—…"
        print(f"ğŸ“Š BLSì—ì„œ ë¡œë”© ({current_key_name}): {series_id}")
        response = BLS_SESSION.post(url, data=json.dumps(data), headers=headers, timeout=30)
        response.raise_for_status()
        
        json_data = response.json()
        
        if json_data.get('status') == 'REQUEST_SUCCEEDED':
            series_data = json_data['Results']['series'][0]['data']
            
            # ë°ì´í„° ì •ë¦¬
            dates = []
            values = []
            
            for item in series_data:
                try:
                    year = int(item['year'])
                    period = item['period']
                    if period.startswith('M'):
                        month = int(period[1:])
                        date = pd.Timestamp(year, month, 1)
                        value = float(item['value'])
                        
                        dates.append(date)
                        values.append(value)
                except (ValueError, KeyError):
                    continue
            
            if dates and values:
                # ë‚ ì§œìˆœ ì •ë ¬
                df = pd.DataFrame({'date': dates, 'value': values})
                df = df.sort_values('date')
                series = pd.Series(df['value'].values, index=df['date'], name=series_id)
                
                print(f"âœ“ BLS ì„±ê³µ: {series_id} ({len(series)}ê°œ í¬ì¸íŠ¸)")
                return series
            else:
                print(f"âŒ BLS ë°ì´í„° ì—†ìŒ: {series_id}")
                return None
        else:
            error_msg = json_data.get('message', 'Unknown error')
            print(f"âš ï¸ BLS API ì˜¤ë¥˜: {error_msg}")
            
            # Daily threshold ì´ˆê³¼ì¸ ê²½ìš° API í‚¤ ì „í™˜ ì‹œë„
            if 'daily threshold' in error_msg.lower() or 'daily quota' in error_msg.lower():
                print("ğŸ“ˆ Daily threshold ì´ˆê³¼ ê°ì§€ - API í‚¤ ì „í™˜ ì‹œë„")
                switch_api_key()
                
                # ìƒˆë¡œìš´ API í‚¤ë¡œ ì¬ì‹œë„
                data['registrationkey'] = CURRENT_API_KEY
                try:
                    print(f"ğŸ”„ ìƒˆ API í‚¤ë¡œ ì¬ì‹œë„: {series_id}")
                    response = BLS_SESSION.post(url, data=json.dumps(data), headers=headers, timeout=30)
                    response.raise_for_status()
                    
                    json_data = response.json()
                    if json_data.get('status') == 'REQUEST_SUCCEEDED':
                        series_data = json_data['Results']['series'][0]['data']
                        
                        dates = []
                        values = []
                        
                        for item in series_data:
                            try:
                                year = int(item['year'])
                                period = item['period']
                                if period.startswith('M'):
                                    month = int(period[1:])
                                    date = pd.Timestamp(year, month, 1)
                                    value = float(item['value'])
                                    
                                    dates.append(date)
                                    values.append(value)
                            except (ValueError, KeyError):
                                continue
                        
                        if dates and values:
                            df = pd.DataFrame({'date': dates, 'value': values})
                            df = df.sort_values('date')
                            series = pd.Series(df['value'].values, index=df['date'], name=series_id)
                            
                            print(f"âœ… ë°±ì—… API í‚¤ë¡œ ì„±ê³µ: {series_id} ({len(series)}ê°œ í¬ì¸íŠ¸)")
                            return series
                    
                    print(f"âŒ ë°±ì—… API í‚¤ë¡œë„ ì‹¤íŒ¨: {series_id}")
                    return None
                except Exception as e:
                    print(f"âŒ ë°±ì—… API í‚¤ ìš”ì²­ ì‹¤íŒ¨: {series_id} - {e}")
                    return None
            else:
                return None
            
    except Exception as e:
        print(f"âŒ BLS ìš”ì²­ ì‹¤íŒ¨: {series_id} - {e}")
        return None

# %%
# === ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ë“¤ ===

def get_series_data(series_id, start_date='2020-01-01', end_date=None, min_points=12, is_update=False):
    """BLS APIë¥¼ ì‚¬ìš©í•œ ê°œë³„ ì‹œë¦¬ì¦ˆ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    if not BLS_SESSION:
        print(f"âŒ BLS ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ: {series_id}")
        return None
    
    try:
        start_year = pd.to_datetime(start_date).year
        end_year = pd.to_datetime(end_date).year if end_date else None
        data = get_bls_data(series_id, start_year, end_year)
        
        if data is None or len(data) == 0:
            print(f"âŒ ë°ì´í„° ì—†ìŒ: {series_id}")
            return None
        
        # ë‚ ì§œ í•„í„°ë§
        if start_date:
            data = data[data.index >= start_date]
        if end_date:
            data = data[data.index <= end_date]
        
        # NaN ì œê±°
        data = data.dropna()
        
        # ì—…ë°ì´íŠ¸ ëª¨ë“œì¼ ë•ŒëŠ” ìµœì†Œ ë°ì´í„° í¬ì¸íŠ¸ ìš”êµ¬ëŸ‰ì„ ë‚®ì¶¤
        if is_update:
            min_required = 1  # ì—…ë°ì´íŠ¸ ì‹œì—ëŠ” 1ê°œ í¬ì¸íŠ¸ë§Œ ìˆì–´ë„ í—ˆìš©
        else:
            min_required = min_points
        
        if len(data) < min_required:
            print(f"âŒ ë°ì´í„° ë¶€ì¡±: {series_id} ({len(data)}ê°œ)")
            return None
        
        print(f"âœ“ ì„±ê³µ: {series_id} ({len(data)}ê°œ í¬ì¸íŠ¸)")
        return data
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {series_id} - {e}")
        return None

def calculate_yoy_change(data):
    """ì „ë…„ë™ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ê³„ì‚°"""
    return ((data / data.shift(12)) - 1) * 100

def calculate_mom_change(data):
    """ì „ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ê³„ì‚°"""
    return ((data / data.shift(1)) - 1) * 100

# %%
# === CSV ì €ì¥/ë¡œë“œ í•¨ìˆ˜ë“¤ ===

def save_ppi_data_to_csv(file_path='/home/jyp0615/us_eco/ppi_data.csv'):
    """
    í˜„ì¬ ë¡œë“œëœ PPI ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
    
    Args:
        file_path: ì €ì¥í•  CSV íŒŒì¼ ê²½ë¡œ
    """
    if not PPI_DATA['load_info']['loaded']:
        print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return False
    
    try:
        # raw_dataì™€ ë©”íƒ€ë°ì´í„°ë¥¼ í•¨ê»˜ ì €ì¥
        raw_data = PPI_DATA['raw_data']
        
        # ì €ì¥í•  ë°ì´í„° ì¤€ë¹„
        save_data = {
            'timestamp': raw_data.index.tolist(),
            **{col: raw_data[col].tolist() for col in raw_data.columns}
        }
        
        # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
        save_df = pd.DataFrame(save_data)
        save_df.to_csv(file_path, index=False, encoding='utf-8')
        
        # ë©”íƒ€ë°ì´í„°ë„ ë³„ë„ ì €ì¥
        meta_file = file_path.replace('.csv', '_meta.json')
        import json
        with open(meta_file, 'w', encoding='utf-8') as f:
            meta_data = {
                'load_time': PPI_DATA['load_info']['load_time'].isoformat() if PPI_DATA['load_info']['load_time'] else None,
                'start_date': PPI_DATA['load_info']['start_date'],
                'series_count': PPI_DATA['load_info']['series_count'],
                'data_points': PPI_DATA['load_info']['data_points'],
                'latest_values': PPI_DATA['latest_values']
            }
            json.dump(meta_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… PPI ë°ì´í„° ì €ì¥ ì™„ë£Œ: {file_path}")
        print(f"âœ… ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {meta_file}")
        return True
        
    except Exception as e:
        print(f"âŒ CSV ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def load_ppi_data_from_csv(file_path='/home/jyp0615/us_eco/ppi_data.csv'):
    """
    CSV íŒŒì¼ì—ì„œ PPI ë°ì´í„° ë¡œë“œ
    
    Args:
        file_path: ë¡œë“œí•  CSV íŒŒì¼ ê²½ë¡œ
    
    Returns:
        bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
    """
    global PPI_DATA
    
    import os
    if not os.path.exists(file_path):
        print(f"âš ï¸ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return False
    
    try:
        # CSV ë°ì´í„° ë¡œë“œ
        df = pd.read_csv(file_path, encoding='utf-8')
        
        # timestamp ì»¬ëŸ¼ì„ ë‚ ì§œ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df.set_index('timestamp', inplace=True)
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        meta_file = file_path.replace('.csv', '_meta.json')
        latest_values = {}
        if os.path.exists(meta_file):
            import json
            with open(meta_file, 'r', encoding='utf-8') as f:
                meta_data = json.load(f)
                latest_values = meta_data.get('latest_values', {})
        
        # ì „ì—­ ì €ì¥ì†Œì— ì €ì¥
        PPI_DATA['raw_data'] = df
        PPI_DATA['yoy_data'] = df.apply(calculate_yoy_change)
        PPI_DATA['mom_data'] = df.apply(calculate_mom_change)
        PPI_DATA['latest_values'] = latest_values
        PPI_DATA['load_info'] = {
            'loaded': True,
            'load_time': datetime.datetime.now(),
            'start_date': df.index[0].strftime('%Y-%m-%d') if len(df) > 0 else None,
            'series_count': len(df.columns),
            'data_points': len(df)
        }
        
        print(f"âœ… CSVì—ì„œ PPI ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {file_path}")
        print_load_info()
        return True
        
    except Exception as e:
        print(f"âŒ CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

def check_recent_data_consistency(series_list=None, check_count=3):
    """
    ìµœê·¼ Nê°œ ë°ì´í„°ì˜ ì¼ì¹˜ì„±ì„ í™•ì¸í•˜ëŠ” í•¨ìˆ˜ (ê°œì„ ëœ ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸)
    
    Args:
        series_list: í™•ì¸í•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ì£¼ìš” ì‹œë¦¬ì¦ˆë§Œ)
        check_count: í™•ì¸í•  ìµœê·¼ ë°ì´í„° ê°œìˆ˜
    
    Returns:
        dict: ì¼ì¹˜ì„± í™•ì¸ ê²°ê³¼ (need_update, reason, mismatches)
    """
    if not PPI_DATA['load_info']['loaded']:
        return {'need_update': True, 'reason': 'ê¸°ì¡´ ë°ì´í„° ì—†ìŒ'}
    
    if series_list is None:
        # ì£¼ìš” ì‹œë¦¬ì¦ˆë§Œ ì²´í¬ (ì†ë„ í–¥ìƒ) - ê³„ì ˆë¯¸ì¡°ì • ë°ì´í„° ìš°ì„ 
        series_list = ['WPUFD4', 'WPUFD49104', 'WPU00000000', 'WPUID61']
    
    # BLS API ì´ˆê¸°í™”
    if not initialize_bls_api():
        return {'need_update': True, 'reason': 'API ì´ˆê¸°í™” ì‹¤íŒ¨'}
    
    print(f"ğŸ“Š ìµœê·¼ {check_count}ê°œ ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸ ì¤‘...")
    
    mismatches = []
    new_data_available = False
    
    for series_id in series_list:
        if series_id not in PPI_DATA['raw_data'].columns:
            continue
        
        existing_data = PPI_DATA['raw_data'][series_id]
        
        # ìµœê·¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        current_year = datetime.datetime.now().year
        api_data = get_bls_data(series_id, current_year - 1, current_year)
        
        if api_data is None or len(api_data) == 0:
            mismatches.append({
                'series': series_id,
                'reason': 'API ë°ì´í„° ì—†ìŒ'
            })
            continue
        
        # ë¨¼ì € ìƒˆë¡œìš´ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        latest_existing = existing_data.index[-1]
        latest_api = api_data.index[-1]
        
        if latest_api > latest_existing:
            new_data_available = True
            mismatches.append({
                'series': series_id,
                'reason': 'ìƒˆë¡œìš´ ë°ì´í„° ì¡´ì¬',
                'existing_latest': latest_existing,
                'api_latest': latest_api
            })
            continue  # ìƒˆ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë‹¤ë¥¸ ì²´í¬ëŠ” ê±´ë„ˆëœ€
        
        # ìµœê·¼ Nê°œ ë°ì´í„° ë¹„êµ (ìƒˆ ë°ì´í„°ê°€ ì—†ì„ ë•Œë§Œ)
        existing_recent = existing_data.tail(check_count)
        api_recent = api_data.tail(check_count)
        
        # ë‚ ì§œì™€ ê°’ ëª¨ë‘ ë¹„êµ
        for date in existing_recent.index[-check_count:]:
            if date in api_recent.index:
                existing_val = existing_recent.loc[date]
                api_val = api_recent.loc[date]
                
                # ê°’ì´ ë‹¤ë¥´ë©´ ë¶ˆì¼ì¹˜
                if abs(existing_val - api_val) > 0.01:  # 0.01 ì´ìƒ ì°¨ì´
                    mismatches.append({
                        'series': series_id,
                        'date': date,
                        'existing': existing_val,
                        'api': api_val,
                        'diff': abs(existing_val - api_val)
                    })
            else:
                mismatches.append({
                    'series': series_id,
                    'date': date,
                    'existing': existing_recent.loc[date],
                    'api': None,
                    'reason': 'ë‚ ì§œ ì—†ìŒ'
                })
    
    # ê²°ê³¼ íŒì • ë¡œì§ ê°œì„ 
    if new_data_available:
        print(f"ğŸ†• ìƒˆë¡œìš´ ë°ì´í„° ê°ì§€: ì—…ë°ì´íŠ¸ í•„ìš”")
        for mismatch in mismatches[:3]:
            if 'reason' in mismatch and mismatch['reason'] == 'ìƒˆë¡œìš´ ë°ì´í„° ì¡´ì¬':
                print(f"   - {mismatch['series']}: {mismatch['existing_latest']} â†’ {mismatch['api_latest']}")
        return {'need_update': True, 'reason': 'ìƒˆë¡œìš´ ë°ì´í„°', 'mismatches': mismatches}
    elif any(m for m in mismatches if m.get('reason') != 'ìƒˆë¡œìš´ ë°ì´í„° ì¡´ì¬'):
        # ê°’ ë¶ˆì¼ì¹˜ê°€ ìˆëŠ” ê²½ìš°
        value_mismatches = [m for m in mismatches if m.get('reason') != 'ìƒˆë¡œìš´ ë°ì´í„° ì¡´ì¬']
        print(f"âš ï¸ ë°ì´í„° ë¶ˆì¼ì¹˜ ë°œê²¬: {len(value_mismatches)}ê°œ")
        for mismatch in value_mismatches[:3]:
            print(f"   - {mismatch}")
        return {'need_update': True, 'reason': 'ë°ì´í„° ë¶ˆì¼ì¹˜', 'mismatches': mismatches}
    else:
        print("âœ… ìµœê·¼ ë°ì´í„°ê°€ ì™„ì „íˆ ì¼ì¹˜í•©ë‹ˆë‹¤. ì—…ë°ì´íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return {'need_update': False, 'reason': 'ë°ì´í„° ì¼ì¹˜'}

def update_ppi_data_from_api(start_date=None, series_list=None, smart_update=True):
    """
    APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸ (ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì§€ì›)
    
    Args:
        start_date: ì—…ë°ì´íŠ¸ ì‹œì‘ ë‚ ì§œ (Noneì´ë©´ ë§ˆì§€ë§‰ ë°ì´í„° ì´í›„ë¶€í„°)
        series_list: ì—…ë°ì´íŠ¸í•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  ì‹œë¦¬ì¦ˆ)
        smart_update: ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì‚¬ìš© ì—¬ë¶€ (ìµœê·¼ 3ê°œ ë°ì´í„° ë¹„êµ)
    
    Returns:
        bool: ì—…ë°ì´íŠ¸ ì„±ê³µ ì—¬ë¶€
    """
    global PPI_DATA
    
    if not PPI_DATA['load_info']['loaded']:
        print("âš ï¸ ê¸°ì¡´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ë¡œë“œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
        return load_all_ppi_data()
    
    # ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ í™œì„±í™”ì‹œ ìµœê·¼ ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸
    if smart_update:
        consistency_check = check_recent_data_consistency()
        
        # ì—…ë°ì´íŠ¸ í•„ìš” ì—†ìœ¼ë©´ ë°”ë¡œ ì¢…ë£Œ
        if not consistency_check['need_update']:
            print("ğŸ¯ ë°ì´í„°ê°€ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤. API í˜¸ì¶œì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return True
        
        # ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•œ ê²½ìš° ì²˜ë¦¬
        if consistency_check['reason'] == 'ë°ì´í„° ë¶ˆì¼ì¹˜':
            print("âš ï¸ ìµœê·¼ 3ê°œ ë°ì´í„° ë¶ˆì¼ì¹˜ë¡œ ì¸í•œ ì „ì²´ ì¬ë¡œë“œ")
            # ìµœê·¼ 3ê°œì›” ë°ì´í„°ë¶€í„° ë‹¤ì‹œ ë¡œë“œ
            last_date = PPI_DATA['raw_data'].index[-1]
            start_date = (last_date - pd.DateOffset(months=3)).strftime('%Y-%m-01')
        elif consistency_check['reason'] == 'ê¸°ì¡´ ë°ì´í„° ì—†ìŒ':
            # ì „ì²´ ì¬ë¡œë“œ
            return load_all_ppi_data(force_reload=True)
        else:
            print(f"ğŸ”„ ì—…ë°ì´íŠ¸ ì§„í–‰: {consistency_check['reason']}")
    
    # BLS API ì´ˆê¸°í™”
    if not initialize_bls_api():
        print("âŒ BLS API ì´ˆê¸°í™” ì‹¤íŒ¨")
        return False
    
    # ì—…ë°ì´íŠ¸ ì‹œì‘ ë‚ ì§œ ê²°ì •
    if start_date is None:
        last_date = PPI_DATA['raw_data'].index[-1]
        # ë§ˆì§€ë§‰ ë‚ ì§œì˜ ë‹¤ìŒ ë‹¬ë¶€í„° ì—…ë°ì´íŠ¸
        start_date = (last_date + pd.DateOffset(months=1)).strftime('%Y-%m-01')
    
    print(f"ğŸ”„ PPI ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ ({start_date}ë¶€í„°)")
    print("="*50)
    
    if series_list is None:
        series_list = list(PPI_SERIES.keys())
    
    updated_data = {}
    new_count = 0
    
    for series_id in series_list:
        if series_id not in PPI_SERIES:
            continue
        
        # ìƒˆë¡œìš´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        start_year = pd.to_datetime(start_date).year
        new_data = get_bls_data(series_id, start_year)
        
        if new_data is not None and len(new_data) > 0:
            # ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©
            if series_id in PPI_DATA['raw_data'].columns:
                existing_data = PPI_DATA['raw_data'][series_id]
                original_count = existing_data.notna().sum()
                
                # ê°œì„ ëœ ë³‘í•© ë°©ì‹: ì¸ë±ìŠ¤ ë¨¼ì € í™•ì¥ í›„ ê°’ í• ë‹¹
                all_dates = existing_data.index.union(new_data.index).sort_values()
                combined_data = existing_data.reindex(all_dates)
                
                # ìƒˆ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ê°’ ë®ì–´ì“°ê¸°)
                for date, value in new_data.items():
                    combined_data.loc[date] = value
                
                updated_data[series_id] = combined_data
                
                # ì‹¤ì œ ì¶”ê°€ëœ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ ê³„ì‚°
                final_count = combined_data.notna().sum()
                new_points = final_count - original_count
                new_count += new_points
                
                if new_points > 0:
                    print(f"âœ… ì—…ë°ì´íŠ¸: {series_id} (ê¸°ì¡´ {original_count}ê°œ + ì‹ ê·œ {len(new_data)}ê°œ â†’ ì´ {final_count}ê°œ, ì‹¤ì œ ì¶”ê°€: {new_points}ê°œ)")
                else:
                    print(f"â„¹ï¸  ìµœì‹  ìƒíƒœ: {series_id}")
            else:
                updated_data[series_id] = new_data
                new_count += len(new_data)
                print(f"âœ… ì‹ ê·œ ì¶”ê°€: {series_id} ({len(new_data)}ê°œ í¬ì¸íŠ¸)")
    
    if updated_data:
        # ì „ì—­ ì €ì¥ì†Œ ì—…ë°ì´íŠ¸
        updated_df = pd.DataFrame(updated_data)
        PPI_DATA['raw_data'] = updated_df
        PPI_DATA['yoy_data'] = updated_df.apply(calculate_yoy_change)
        PPI_DATA['mom_data'] = updated_df.apply(calculate_mom_change)
        
        # ìµœì‹  ê°’ ì—…ë°ì´íŠ¸
        for series_id in updated_data.keys():
            if series_id in PPI_DATA['yoy_data'].columns:
                yoy_data = PPI_DATA['yoy_data'][series_id].dropna()
                if len(yoy_data) > 0:
                    PPI_DATA['latest_values'][series_id] = yoy_data.iloc[-1]
        
        # ë¡œë“œ ì •ë³´ ì—…ë°ì´íŠ¸
        PPI_DATA['load_info']['load_time'] = datetime.datetime.now()
        PPI_DATA['load_info']['series_count'] = len(updated_df.columns)
        PPI_DATA['load_info']['data_points'] = len(updated_df)
        
        print(f"\nâœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ! ìƒˆë¡œ ì¶”ê°€ëœ ë°ì´í„°: {new_count}ê°œ í¬ì¸íŠ¸")
        print_load_info()
        
        # ìë™ìœ¼ë¡œ CSVì— ì €ì¥
        save_ppi_data_to_csv()
        
        return True
    else:
        print("\nâš ï¸ ì—…ë°ì´íŠ¸í•  ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False

# === ë©”ì¸ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ===

def load_all_ppi_data(start_date='2020-01-01', series_list=None, force_reload=False, csv_file='/home/jyp0615/us_eco/ppi_data.csv'):
    """
    PPI ë°ì´í„° ë¡œë“œ (CSV ìš°ì„ , API ë°±ì—… ë°©ì‹)
    
    Args:
        start_date: ì‹œì‘ ë‚ ì§œ
        series_list: ë¡œë“œí•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  ì‹œë¦¬ì¦ˆ)
        force_reload: ê°•ì œ ì¬ë¡œë“œ ì—¬ë¶€
        csv_file: CSV íŒŒì¼ ê²½ë¡œ
    
    Returns:
        bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
    """
    global PPI_DATA
    
    # ì´ë¯¸ ë¡œë“œëœ ê²½ìš° ìŠ¤í‚µ
    if PPI_DATA['load_info']['loaded'] and not force_reload:
        print("ğŸ’¾ ì´ë¯¸ ë¡œë“œëœ ë°ì´í„° ì‚¬ìš© ì¤‘")
        print_load_info()
        return True
    
    # CSV íŒŒì¼ì´ ìˆìœ¼ë©´ ìš°ì„  ë¡œë“œ ì‹œë„
    import os
    if not force_reload and os.path.exists(csv_file):
        print("ğŸ“‚ ê¸°ì¡´ CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ ì‹œë„...")
        if load_ppi_data_from_csv(csv_file):
            print("ğŸ”„ CSV ë¡œë“œ í›„ ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì‹œë„...")
            # CSV ë¡œë“œ ì„±ê³µ í›„ ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸
            update_ppi_data_from_api(smart_update=True)
            return True
        else:
            print("âš ï¸ CSV ë¡œë“œ ì‹¤íŒ¨, APIì—ì„œ ì „ì²´ ë¡œë“œ ì‹œë„...")
    
    print("ğŸš€ PPI ë°ì´í„° ë¡œë”© ì‹œì‘... (BLS API ì „ìš©)")
    print("="*50)
    
    # BLS API ì´ˆê¸°í™”
    if not initialize_bls_api():
        print("âŒ BLS API ì´ˆê¸°í™” ì‹¤íŒ¨")
        return False
    
    if series_list is None:
        series_list = list(PPI_SERIES.keys())
    
    # ë°ì´í„° ìˆ˜ì§‘
    raw_data_dict = {}
    yoy_data_dict = {}
    mom_data_dict = {}
    latest_values = {}
    
    for series_id in series_list:
        if series_id not in PPI_SERIES:
            print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì‹œë¦¬ì¦ˆ: {series_id}")
            continue
        
        # ì›ë³¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        series_data = get_series_data(series_id, start_date)
        
        if series_data is not None and len(series_data) > 0:
            # ì›ë³¸ ë°ì´í„° ì €ì¥
            raw_data_dict[series_id] = series_data
            
            # YoY ê³„ì‚°
            yoy_data = calculate_yoy_change(series_data)
            yoy_data_dict[series_id] = yoy_data
            
            # MoM ê³„ì‚°
            mom_data = calculate_mom_change(series_data)
            mom_data_dict[series_id] = mom_data
            
            # ìµœì‹  ê°’ ì €ì¥
            if len(yoy_data.dropna()) > 0:
                latest_yoy = yoy_data.dropna().iloc[-1]
                latest_values[series_id] = latest_yoy
            else:
                print(f"âš ï¸ YoY ë°ì´í„° ì—†ìŒ: {series_id}")
        else:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {series_id}")
    
    # ë¡œë“œëœ ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì˜¤ë¥˜ ë°œìƒ
    if len(raw_data_dict) < 5:  # ìµœì†Œ 5ê°œ ì‹œë¦¬ì¦ˆëŠ” ìˆì–´ì•¼ í•¨
        error_msg = f"âŒ ë¡œë“œëœ ì‹œë¦¬ì¦ˆê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤: {len(raw_data_dict)}ê°œ (ìµœì†Œ 5ê°œ í•„ìš”)"
        print(error_msg)
        raise ValueError(error_msg)
    
    # ì „ì—­ ì €ì¥ì†Œì— ì €ì¥
    PPI_DATA['raw_data'] = pd.DataFrame(raw_data_dict)
    PPI_DATA['yoy_data'] = pd.DataFrame(yoy_data_dict)
    PPI_DATA['mom_data'] = pd.DataFrame(mom_data_dict)
    PPI_DATA['latest_values'] = latest_values
    PPI_DATA['load_info'] = {
        'loaded': True,
        'load_time': datetime.datetime.now(),
        'start_date': start_date,
        'series_count': len(raw_data_dict),
        'data_points': len(PPI_DATA['raw_data']) if not PPI_DATA['raw_data'].empty else 0
    }
    
    print("\nâœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
    print_load_info()
    
    # ìë™ìœ¼ë¡œ CSVì— ì €ì¥
    save_ppi_data_to_csv(csv_file)
    
    return True

def print_load_info():
    """ë¡œë“œ ì •ë³´ ì¶œë ¥"""
    info = PPI_DATA['load_info']
    if not info['loaded']:
        print("âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ")
        return
    
    print(f"ğŸ“Š ë¡œë“œëœ ë°ì´í„° ì •ë³´:")
    print(f"   ì‹œë¦¬ì¦ˆ ê°œìˆ˜: {info['series_count']}")
    print(f"   ë°ì´í„° í¬ì¸íŠ¸: {info['data_points']}")
    print(f"   ì‹œì‘ ë‚ ì§œ: {info['start_date']}")
    print(f"   ë¡œë“œ ì‹œê°„: {info['load_time'].strftime('%Y-%m-%d %H:%M:%S')}")
    
    if not PPI_DATA['raw_data'].empty:
        date_range = f"{PPI_DATA['raw_data'].index[0].strftime('%Y-%m')} ~ {PPI_DATA['raw_data'].index[-1].strftime('%Y-%m')}"
        print(f"   ë°ì´í„° ê¸°ê°„: {date_range}")

def clear_data():
    """ë°ì´í„° ì´ˆê¸°í™”"""
    global PPI_DATA
    PPI_DATA = {
        'raw_data': pd.DataFrame(),
        'yoy_data': pd.DataFrame(),
        'mom_data': pd.DataFrame(),
        'latest_values': {},
        'load_info': {'loaded': False, 'load_time': None, 'start_date': None, 'series_count': 0, 'data_points': 0}
    }
    print("ğŸ—‘ï¸ ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤")

# %%
# === ë°ì´í„° ì ‘ê·¼ í•¨ìˆ˜ë“¤ ===

def get_raw_data(series_names=None):
    """ì›ë³¸ ë ˆë²¨ ë°ì´í„° ë°˜í™˜"""
    if not PPI_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_ppi_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return pd.DataFrame()
    
    if series_names is None:
        return PPI_DATA['raw_data'].copy()
    
    available_series = [s for s in series_names if s in PPI_DATA['raw_data'].columns]
    if not available_series:
        print(f"âš ï¸ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤: {series_names}")
        return pd.DataFrame()
    
    return PPI_DATA['raw_data'][available_series].copy()

def get_yoy_data(series_names=None):
    """YoY ë³€í™”ìœ¨ ë°ì´í„° ë°˜í™˜"""
    if not PPI_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_ppi_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return pd.DataFrame()
    
    if series_names is None:
        return PPI_DATA['yoy_data'].copy()
    
    available_series = [s for s in series_names if s in PPI_DATA['yoy_data'].columns]
    if not available_series:
        print(f"âš ï¸ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤: {series_names}")
        return pd.DataFrame()
    
    return PPI_DATA['yoy_data'][available_series].copy()

def get_mom_data(series_names=None):
    """ì „ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ë°ì´í„° ë°˜í™˜"""
    if not PPI_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_ppi_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return pd.DataFrame()
    
    if series_names is None:
        return PPI_DATA['mom_data'].copy()
    
    available_series = [s for s in series_names if s in PPI_DATA['mom_data'].columns]
    if not available_series:
        print(f"âš ï¸ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤: {series_names}")
        return pd.DataFrame()
    
    return PPI_DATA['mom_data'][available_series].copy()

def get_latest_values(series_names=None):
    """ìµœì‹  YoY ê°’ë“¤ ë°˜í™˜"""
    if not PPI_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_ppi_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return {}
    
    if series_names is None:
        return PPI_DATA['latest_values'].copy()
    
    return {name: PPI_DATA['latest_values'].get(name, 0) for name in series_names if name in PPI_DATA['latest_values']}

def list_available_series():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œë¦¬ì¦ˆ ëª©ë¡ ë°˜í™˜"""
    if not PPI_DATA['load_info']['loaded']:
        return []
    return list(PPI_DATA['raw_data'].columns)

# %%
# === ì‹œê°í™” í•¨ìˆ˜ë“¤ ===

def filter_series_by_selection(selected_series=None, category_filter=None):
    """
    ì‚¬ìš©ì ì„ íƒì— ë”°ë¼ ì‹œë¦¬ì¦ˆ í•„í„°ë§
    
    Args:
        selected_series: ì‚¬ìš©ìê°€ ì§ì ‘ ì„ íƒí•œ ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸
        category_filter: ì¹´í…Œê³ ë¦¬ í•„í„° ('ìµœì¢…ìˆ˜ìš”', 'ì¤‘ê°„ìˆ˜ìš”', 'ì£¼ìš”í’ˆëª©', 'ì„œë¹„ìŠ¤', 'ì™„ì œí’ˆ', 'ì „ì²´ìƒí’ˆ')
    
    Returns:
        list: í•„í„°ë§ëœ ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸
    """
    if selected_series is not None:
        # ì‚¬ìš©ì ì§ì ‘ ì„ íƒ ìš°ì„ 
        return selected_series
    
    if category_filter and category_filter in PPI_CATEGORIES:
        # ì¹´í…Œê³ ë¦¬ í•„í„° ì ìš©
        series_list = []
        for group_series in PPI_CATEGORIES[category_filter].values():
            series_list.extend(group_series)
        return series_list
    
    # ê¸°ë³¸ê°’
    return ['WPUFD4', 'WPUFD49104']  # ìµœì¢…ìˆ˜ìš”, ì½”ì–´ ìµœì¢…ìˆ˜ìš” (ê³„ì ˆë¯¸ì¡°ì •)

def create_filtered_ppi_chart(selected_series=None, category_filter=None, chart_type='yoy'):
    """
    ì‚¬ìš©ì ì„ íƒì— ë”°ë¼ í•„í„°ë§ëœ PPI ì°¨íŠ¸ ìƒì„±
    
    Args:
        selected_series: ì‚¬ìš©ìê°€ ì§ì ‘ ì„ íƒí•œ ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸
        category_filter: ì¹´í…Œê³ ë¦¬ í•„í„° ('ìµœì¢…ìˆ˜ìš”', 'ì¤‘ê°„ìˆ˜ìš”', 'ì£¼ìš”í’ˆëª©', 'ì„œë¹„ìŠ¤', 'ì™„ì œí’ˆ', 'ì „ì²´ìƒí’ˆ')
        chart_type: ì°¨íŠ¸ íƒ€ì… ('yoy', 'mom', 'level')
        title: ì°¨íŠ¸ ì œëª©
    
    Returns:
        plotly figure
    """
    if not PPI_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_ppi_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ì‹œë¦¬ì¦ˆ í•„í„°ë§
    series_names = filter_series_by_selection(selected_series, category_filter)
    
    # ê¸°ì¡´ ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜ ì‚¬ìš©
    return create_ppi_timeseries_chart(series_names, chart_type)

def show_category_options():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ ì˜µì…˜ í‘œì‹œ
    """
    print("=== ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ ===")
    for category, groups in PPI_CATEGORIES.items():
        print(f"\n{category}:")
        for group_name, series_list in groups.items():
            print(f"  {group_name}: {len(series_list)}ê°œ ì‹œë¦¬ì¦ˆ")
            for series_id in series_list:
                korean_name = PPI_KOREAN_NAMES.get(series_id, series_id)
                print(f"    - {series_id}: {korean_name}")

def create_category_comparison_chart(categories=None, chart_type='yoy'):
    """
    ì—¬ëŸ¬ ì¹´í…Œê³ ë¦¬ ë¹„êµ ì°¨íŠ¸
    
    Args:
        categories: ë¹„êµí•  ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸
        chart_type: ì°¨íŠ¸ íƒ€ì… ('yoy', 'mom')
        title: ì°¨íŠ¸ ì œëª©
    
    Returns:
        plotly figure
    """
    if not PPI_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_ppi_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    if categories is None:
        categories = ['ìµœì¢…ìˆ˜ìš”', 'ì¤‘ê°„ìˆ˜ìš”', 'ì£¼ìš”í’ˆëª©']
    
    # ê° ì¹´í…Œê³ ë¦¬ì—ì„œ ëŒ€í‘œ ì‹œë¦¬ì¦ˆ ì„ íƒ
    representative_series = {
        'ìµœì¢…ìˆ˜ìš”': 'WPUFD4',
        'ìµœì¢…ìˆ˜ìš”_ê³„ì ˆì¡°ì •': 'WPSFD4',
        'ì¤‘ê°„ìˆ˜ìš”': 'WPUID61',
        'ì¤‘ê°„ìˆ˜ìš”_ê³„ì ˆì¡°ì •': 'WPSID61',
        'ì£¼ìš”í’ˆëª©': 'WPU1411',
        'ì£¼ìš”í’ˆëª©_ê³„ì ˆì¡°ì •': 'WPS1411',
        'ì„œë¹„ìŠ¤': 'WPU5111',
        'ì„œë¹„ìŠ¤_ê³„ì ˆì¡°ì •': 'WPS5111',
        'ì™„ì œí’ˆ': 'WPUFD49207',
        'ì™„ì œí’ˆ_ê³„ì ˆì¡°ì •': 'WPSFD49207',
        'ì „ì²´ìƒí’ˆ': 'WPU00000000',
        'ì „ì²´ìƒí’ˆ_ê³„ì ˆì¡°ì •': 'WPS00000000'
    }
    
    selected_series = [representative_series.get(cat) for cat in categories if cat in representative_series]
    selected_series = [s for s in selected_series if s is not None]
    
    if not selected_series:
        print("âš ï¸ ì„ íƒëœ ì¹´í…Œê³ ë¦¬ì— ëŒ€í•œ ëŒ€í‘œ ì‹œë¦¬ì¦ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    print(f"PPI ì¹´í…Œê³ ë¦¬ ë¹„êµ - {chart_type.upper()}")
    return create_ppi_timeseries_chart(selected_series, chart_type)

def create_ppi_timeseries_chart(series_names=None, chart_type='yoy', category_filter=None):
    """
    ì €ì¥ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ PPI ì‹œê³„ì—´ ì°¨íŠ¸ ìƒì„±
    
    Args:
        series_names: ì°¨íŠ¸ì— í‘œì‹œí•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸
        chart_type: 'yoy' (ì „ë…„ë™ê¸°ëŒ€ë¹„), 'mom' (ì „ì›”ëŒ€ë¹„), ë˜ëŠ” 'level' (ìˆ˜ì¤€)
        category_filter: ìƒˆë¡œìš´ ë¶„ë¥˜ ì²´ê³„ì—ì„œ ì„ íƒí•  ì¹´í…Œê³ ë¦¬ ('ìµœì¢…ìˆ˜ìš”', 'ì¤‘ê°„ìˆ˜ìš”', 'ì£¼ìš”í’ˆëª©', 'ì„œë¹„ìŠ¤', 'ì™„ì œí’ˆ', 'ì „ì²´ìƒí’ˆ')
    """
    if not PPI_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_ppi_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ì¹´í…Œê³ ë¦¬ í•„í„° ì ìš©
    if category_filter and category_filter in PPI_CATEGORIES:
        series_names = []
        for group_series in PPI_CATEGORIES[category_filter].values():
            series_names.extend(group_series)
    elif series_names is None:
        series_names = ['WPUFD4', 'WPUFD49104']  # ìµœì¢…ìˆ˜ìš”, ì½”ì–´ ìµœì¢…ìˆ˜ìš” (ê³„ì ˆë¯¸ì¡°ì •)
    
    # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    if chart_type == 'yoy':
        df = get_yoy_data(series_names)
        ytitle = "Percent change from year ago"
        print("Producer Price Index - Year-over-Year Change")
    elif chart_type == 'mom':
        df = get_mom_data(series_names)
        ytitle = "Percent change from month ago"
        print("Producer Price Index - Month-over-Month Change")
    else:
        df = get_raw_data(series_names)
        ytitle = "Index Level"
        print("Producer Price Index - Level")
    
    if df.empty:
        print("âš ï¸ ìš”ì²­í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ë¼ë²¨ ë§¤í•‘ (í•œêµ­ì–´)
    label_mapping = {}
    for series_id in series_names:
        label_mapping[series_id] = PPI_KOREAN_NAMES.get(series_id, PPI_SERIES.get(series_id, series_id))
    
    # ë°ì´í„° ì¤€ë¹„
    chart_data = {}
    for col in df.columns:
        label = label_mapping.get(col, col)
        chart_data[label] = df[col].dropna()
    
    # KPDS í¬ë§· ì‚¬ìš©í•˜ì—¬ ì°¨íŠ¸ ìƒì„±
    chart_df = pd.DataFrame(chart_data)
    
    if chart_type in ['yoy', 'mom']:
        fig = df_multi_line_chart(chart_df, ytitle=ytitle)
        fig.add_hline(y=0, line_width=1, line_color="black", opacity=0.5)
    else:
        fig = df_multi_line_chart(chart_df, ytitle=ytitle)
        fig.add_hline(y=0, line_width=1, line_color="black", opacity=0.5)
    
    return fig

def create_ppi_component_comparison(category='ìƒìœ„', chart_type='yoy', use_new_categories=False):
    """
    PPI êµ¬ì„±ìš”ì†Œ ë¹„êµ ì°¨íŠ¸
    
    Args:
        category: PPI_HIERARCHYì˜ ì¹´í…Œê³ ë¦¬ ('ìµœìƒìœ„', 'ìƒìœ„', 'ì¤‘ìœ„') ë˜ëŠ” PPI_CATEGORIESì˜ ì¹´í…Œê³ ë¦¬
        chart_type: ì°¨íŠ¸ íƒ€ì… ('yoy', 'mom')
        use_new_categories: ìƒˆë¡œìš´ ë¶„ë¥˜ ì²´ê³„ ì‚¬ìš© ì—¬ë¶€
    """
    if not PPI_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_ppi_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ìƒˆë¡œìš´ ë¶„ë¥˜ ì²´ê³„ ì‚¬ìš© ì—¬ë¶€ì— ë”°ë¼ ì‹œë¦¬ì¦ˆ ìˆ˜ì§‘
    if use_new_categories:
        if category not in PPI_CATEGORIES:
            print(f"âš ï¸ ì˜ëª»ëœ ì¹´í…Œê³ ë¦¬: {category}")
            return None
        
        # ëª¨ë“  ì‹œë¦¬ì¦ˆ ìˆ˜ì§‘
        all_series = []
        for group in PPI_CATEGORIES[category].values():
            all_series.extend(group)
    else:
        if category not in PPI_HIERARCHY:
            print(f"âš ï¸ ì˜ëª»ëœ ì¹´í…Œê³ ë¦¬: {category}")
            return None
        
        # ëª¨ë“  ì‹œë¦¬ì¦ˆ ìˆ˜ì§‘
        all_series = []
        for group in PPI_HIERARCHY[category].values():
            all_series.extend(group)
    
    # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    if chart_type == 'yoy':
        df = get_yoy_data(all_series)
    else:
        df = get_mom_data(all_series)
    
    if df.empty:
        print("âš ï¸ ìš”ì²­í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ë¼ë²¨ ë§¤í•‘
    chart_data = {}
    for col in df.columns:
        label = PPI_KOREAN_NAMES.get(col, PPI_SERIES.get(col, col))
        chart_data[label] = df[col].dropna()
    
    category_type = "ìƒˆë¡œìš´ ë¶„ë¥˜" if use_new_categories else "ê¸°ì¡´ ë¶„ë¥˜"
    print(f"PPI {category} ì¹´í…Œê³ ë¦¬ ({category_type}) - {chart_type.upper()} ë³€í™”ìœ¨")
    
    # KPDS í¬ë§· ì‚¬ìš©í•˜ì—¬ ì°¨íŠ¸ ìƒì„±
    chart_df = pd.DataFrame(chart_data)
    fig = df_multi_line_chart(chart_df, 
                             ytitle="Percent change from year ago" if chart_type == 'yoy' else "Percent change from month ago")
    
    # 0ì„  ì¶”ê°€
    fig.add_hline(y=0, line_width=1, line_color="black", opacity=0.5)
    
    return fig

def create_ppi_bar_chart(selected_components=None):
    """
    PPI ë°” ì°¨íŠ¸ ìƒì„±
    
    Args:
        selected_components: ì„ íƒí•  êµ¬ì„±ìš”ì†Œ ë¦¬ìŠ¤íŠ¸
    """
    if not PPI_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_ppi_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    if selected_components is None:
        selected_components = ['WPUFD4', 'WPUFD411', 'WPUFD412', 'WPUFD49104']
    
    # ìµœì‹  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    latest_data = get_latest_values(selected_components)
    
    if not latest_data:
        print("âš ï¸ ìš”ì²­í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ë¼ë²¨ ì„¤ì •
    labels = {series_id: PPI_KOREAN_NAMES.get(series_id, PPI_SERIES.get(series_id, series_id)) 
              for series_id in selected_components}
    
    # ì°¨íŠ¸ ë°ì´í„° ì¤€ë¹„
    chart_data = {}
    for comp in selected_components:
        if comp in latest_data:
            label = labels.get(comp, comp)
            chart_data[label] = latest_data[comp]
    
    if not PPI_DATA['raw_data'].empty:
        latest_date = PPI_DATA['raw_data'].index[-1].strftime('%B %Y')
        print(f"12-month percentage change, Producer Price Index, selected categories, {latest_date}")
    else:
        print("12-month percentage change, Producer Price Index")
    
    # KPDS í¬ë§· ì‚¬ìš©í•˜ì—¬ ë°” ì°¨íŠ¸ ìƒì„±
    fig = create_kpds_cpi_bar_chart(chart_data)
    
    return fig

def create_ppi_contribution_chart(months_back=6):
    """
    PPI ìµœì¢…ìˆ˜ìš” ê¸°ì—¬ë„ ì°¨íŠ¸ ìƒì„±
    
    Args:
        months_back: í‘œì‹œí•  ê³¼ê±° ê°œì›” ìˆ˜
    
    Returns:
        plotly figure
    """
    if not PPI_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_ppi_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ìµœì‹  MoM ë°ì´í„°
    mom_data = get_mom_data(['WPUFD41', 'WPUFD411', 'WPUFD412', 'WPUFD42', 'WPUFD43'])
    
    if mom_data.empty:
        print("âš ï¸ í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ìµœê·¼ Nê°œì›” ë°ì´í„°
    recent_data = mom_data.tail(months_back)
    
    # ë¼ë²¨ ë§¤í•‘
    components_mapping = {
        'WPUFD41': 'ìµœì¢…ìˆ˜ìš” ì¬í™”',
        'WPUFD411': 'ìµœì¢…ìˆ˜ìš” ì‹í’ˆ',
        'WPUFD412': 'ìµœì¢…ìˆ˜ìš” ì—ë„ˆì§€',
        'WPUFD42': 'ìµœì¢…ìˆ˜ìš” ì„œë¹„ìŠ¤',
        'WPUFD43': 'ìµœì¢…ìˆ˜ìš” ê±´ì„¤ì—…'
    }
    
    # ë°ì´í„° ì¤€ë¹„
    chart_data = {}
    for comp, label in components_mapping.items():
        if comp in recent_data.columns:
            chart_data[label] = recent_data[comp].dropna()
    
    # ì›”ë³„ë¡œ ë°” ì°¨íŠ¸ ìƒì„±
    months = recent_data.index[-months_back:]
    month_labels = [month.strftime('%b') for month in months]
    
    fig = go.Figure()
    
    # ê° ì»´í¬ë„ŒíŠ¸ë³„ë¡œ ë°” ì¶”ê°€
    for i, (label, data) in enumerate(chart_data.items()):
        color = get_kpds_color(i)
        values = [data.loc[month] if month in data.index and not pd.isna(data.loc[month]) else 0 
                 for month in months]
        
        fig.add_trace(go.Bar(
            name=label,
            x=month_labels,
            y=values,
            marker_color=color,
            text=[f'{v:.2f}' for v in values],
            textposition='auto'
        ))
    
    print("US: PPI Final Demand Components % M/M")
    
    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    fig.update_layout(
        paper_bgcolor='white',
        plot_bgcolor='white',
        width=686,
        height=500,
        font=dict(family='NanumGothic', size=FONT_SIZE_GENERAL, color="black"),
        xaxis=dict(
            showline=True, linewidth=1.3, linecolor='lightgrey',
            tickwidth=1.3, tickcolor='lightgrey',
            ticks='outside'
        ),
        yaxis=dict(
            showline=False,
            tickcolor='white',
            tickformat='.2f',
            title=dict(text='ë³€í™”ìœ¨ (%)', font=dict(family='NanumGothic', size=FONT_SIZE_AXIS_TITLE))
        ),
        legend=dict(
            orientation="v",
            yanchor="top", y=1,
            xanchor="left", x=1.02,
            font=dict(family='NanumGothic', size=FONT_SIZE_LEGEND)
        ),
        margin=dict(l=80, r=150, t=80, b=60)
    )
    
    # 0ì„  ì¶”ê°€
    fig.add_hline(y=0, line_width=1, line_color="black", opacity=0.7)
    
    fig.show()
    return fig

def create_ppi_horizontal_bar_chart(data_series=None, series_ids=None, num_categories=20, 
                                    korean_names_dict=None, special_highlight=None):
    """
    PPI ê°€ë¡œ ë°” ì°¨íŠ¸ ìƒì„± (ì‹œë¦¬ì¦ˆ ID ì§ì ‘ ì…ë ¥ ì§€ì›)
    
    Args:
        data_series: ì™¸ë¶€ì—ì„œ ì œê³µí•˜ëŠ” ë°ì´í„° (pandas Series ë˜ëŠ” dict). 
                    Noneì´ë©´ ë‚´ë¶€ MoM ë°ì´í„° ì‚¬ìš©
        series_ids: ì‹œë¦¬ì¦ˆ ID ë¦¬ìŠ¤íŠ¸ (ì´ ê²½ìš° ë‚´ë¶€ ë°ì´í„°ì—ì„œ í•´ë‹¹ ì‹œë¦¬ì¦ˆë§Œ ì¶”ì¶œ)
        num_categories: í‘œì‹œí•  ì¹´í…Œê³ ë¦¬ ìˆ˜
        korean_names_dict: í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ (ì„ íƒì‚¬í•­)
        special_highlight: íŠ¹ë³„ ê°•ì¡°í•  ì‹œë¦¬ì¦ˆ ID ë¦¬ìŠ¤íŠ¸ (ì£¼í™©ìƒ‰ í‘œì‹œ)
    
    Returns:
        plotly figure
    """
    # ë°ì´í„° ì¤€ë¹„
    if data_series is not None:
        # ì™¸ë¶€ ë°ì´í„° ì‚¬ìš©
        if isinstance(data_series, dict):
            latest_data = pd.Series(data_series)
        elif isinstance(data_series, list):
            # ë¦¬ìŠ¤íŠ¸ê°€ ë“¤ì–´ì˜¨ ê²½ìš° series_idsë¡œ ì²˜ë¦¬
            series_ids = data_series
            data_series = None
        else:
            latest_data = data_series.copy()
        
        # í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘
        if korean_names_dict is None:
            korean_names_dict = {}
    
    # series_idsê°€ ì œê³µëœ ê²½ìš° ë‚´ë¶€ ë°ì´í„°ì—ì„œ í•´ë‹¹ ì‹œë¦¬ì¦ˆë§Œ ì¶”ì¶œ
    if series_ids is not None or data_series is None:
        if not PPI_DATA['load_info']['loaded']:
            print("âš ï¸ ë¨¼ì € load_all_ppi_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
            return None
        
        # ìµœì‹  MoM ë°ì´í„°
        mom_data = get_mom_data()
        
        if series_ids is not None:
            # íŠ¹ì • ì‹œë¦¬ì¦ˆë§Œ ì„ íƒ
            available_series = [s for s in series_ids if s in mom_data.columns]
            if not available_series:
                print(f"âš ï¸ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤: {series_ids}")
                return None
            latest_data = mom_data[available_series].iloc[-1].dropna()
        else:
            # ëª¨ë“  ì‹œë¦¬ì¦ˆ ì‚¬ìš©
            latest_data = mom_data.iloc[-1].dropna()
        
        korean_names_dict = PPI_KOREAN_NAMES
    
    # NaN ê°’ ì œê±°
    latest_data = latest_data.dropna()
    
    if len(latest_data) == 0:
        print("âš ï¸ í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ë¼ë²¨ ë§¤í•‘ëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ìƒì„±
    labeled_data = {}
    series_to_label_map = {}  # ì‹œë¦¬ì¦ˆ IDì™€ ë¼ë²¨ ë§¤í•‘
    
    for series_id, value in latest_data.items():
        if korean_names_dict:
            label = korean_names_dict.get(series_id, PPI_SERIES.get(series_id, series_id))
        else:
            label = str(series_id)
        labeled_data[label] = value
        series_to_label_map[series_id] = label
    
    # íŠ¹ë³„ ê°•ì¡° ìƒ‰ìƒ ì„¤ì •
    if special_highlight is None:
        special_highlight = ['WPSFD4', 'WPS00000000']  # ê¸°ë³¸ ê°•ì¡° ì‹œë¦¬ì¦ˆ
    
    print("PPI Categories (m/m % change)")
    
    # ì¼ë°˜í™”ëœ í•¨ìˆ˜ ì‚¬ìš©í•˜ì—¬ ì°¨íŠ¸ ìƒì„±
    fig = create_horizontal_bar_chart(
        data_dict=labeled_data,
        num_categories=num_categories,
        sort_data=True,
        ascending=True  # ê°€ë¡œ ë°”ì°¨íŠ¸ì—ì„œëŠ” ì‘ì€ ê°’ì´ ì•„ë˜ìª½
    )
    
    # íŠ¹ë³„ ê°•ì¡° ìƒ‰ìƒ ì ìš© (ê¸°ì¡´ ì°¨íŠ¸ì— ìƒ‰ìƒ ì¬ì„¤ì •)
    if fig and special_highlight:
        colors = []
        
        for i, trace_label in enumerate(fig.data[0].y):
            # ë¼ë²¨ì„ í†µí•´ ì›ë˜ ì‹œë¦¬ì¦ˆ ID ì°¾ê¸°
            original_series = None
            for series_id, label in series_to_label_map.items():
                if label == trace_label:
                    original_series = series_id
                    break
            
            value = fig.data[0].x[i]
            
            # íŠ¹ë³„ ê°•ì¡° ì‹œë¦¬ì¦ˆì¸ì§€ í™•ì¸
            if original_series and original_series in special_highlight:
                colors.append('#FFA500')  # ì£¼í™©ìƒ‰
            elif value >= 0:
                colors.append(deepred_pds)  # ìƒìŠ¹: deepred_pds
            else:
                colors.append(deepblue_pds)  # í•˜ë½: deepblue_pds
        
        # ìƒ‰ìƒ ì—…ë°ì´íŠ¸
        fig.data[0].marker.color = colors
    
    return fig

# %%
# === í†µí•© ë¶„ì„ í•¨ìˆ˜ ===

def run_complete_ppi_analysis(start_date='2020-01-01', force_reload=False):
    """
    ì™„ì „í•œ PPI ë¶„ì„ ì‹¤í–‰ - ë°ì´í„° ë¡œë“œ í›„ ëª¨ë“  ì°¨íŠ¸ ìƒì„±
    
    Args:
        start_date: ë°ì´í„° ì‹œì‘ ë‚ ì§œ
        force_reload: ê°•ì œ ì¬ë¡œë“œ ì—¬ë¶€
    
    Returns:
        dict: ìƒì„±ëœ ì°¨íŠ¸ë“¤
    """
    print("ğŸš€ ì™„ì „í•œ PPI ë¶„ì„ ì‹œì‘")
    print("="*50)
    
    # 1. ë°ì´í„° ë¡œë“œ (í•œ ë²ˆë§Œ!)
    print("\n1ï¸âƒ£ ë°ì´í„° ë¡œë”©")
    success = load_all_ppi_data(start_date=start_date, force_reload=force_reload)
    
    if not success:
        print("âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨")
        return None
    
    # 2. ì‹œê°í™” ìƒì„± (ì €ì¥ëœ ë°ì´í„° ì‚¬ìš©)
    print("\n2ï¸âƒ£ ì‹œê°í™” ìƒì„±")
    
    results = {}
    
    try:
        # ìµœì‹  ë°” ì°¨íŠ¸
        print("   ğŸ“Š ìµœì‹  PPI ë°” ì°¨íŠ¸...")
        results['bar_chart'] = create_ppi_bar_chart(['WPUFD4', 'WPUFD411', 'WPUFD412', 'WPUFD49104'])
        
        # ì£¼ìš” ì§€í‘œ ì‹œê³„ì—´
        print("   ğŸ“ˆ ì£¼ìš” PPI ì§€í‘œ ì‹œê³„ì—´...")
        results['main_timeseries'] = create_ppi_timeseries_chart(['WPUFD4', 'WPUFD49104'], 'yoy')
        
        # êµ¬ì„±ìš”ì†Œ ë¹„êµ
        print("   ğŸ” PPI êµ¬ì„±ìš”ì†Œ ë¹„êµ...")
        results['components_comparison'] = create_ppi_component_comparison('ìƒìœ„', 'yoy')
        
        # ê¸°ì—¬ë„ ì°¨íŠ¸
        print("   ğŸ“Š PPI ê¸°ì—¬ë„ ì°¨íŠ¸...")
        results['contribution_chart'] = create_ppi_contribution_chart()
        
        # ê°€ë¡œ ë°” ì°¨íŠ¸
        print("   ğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ ê°€ë¡œ ë°” ì°¨íŠ¸...")
        results['horizontal_bar_chart'] = create_ppi_horizontal_bar_chart()
        
    except Exception as e:
        print(f"âš ï¸ ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
    
    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ! ìƒì„±ëœ ì°¨íŠ¸: {len(results)}ê°œ")
    return results

def run_detailed_ppi_analysis():
    """
    ì„¸ë¶€ PPI ë¶„ì„ ì‹¤í–‰ - ê³„ì¸µë³„ ì°¨íŠ¸
    
    Returns:
        dict: ìƒì„±ëœ ì°¨íŠ¸ë“¤
    """
    print("ğŸš€ ì„¸ë¶€ PPI ë¶„ì„ ì‹œì‘")
    print("="*50)
    
    # 1. ë°ì´í„° ë¡œë“œ í™•ì¸
    if not PPI_DATA['load_info']['loaded']:
        print("\n1ï¸âƒ£ ë°ì´í„° ë¡œë”©")
        success = load_all_ppi_data()
        if not success:
            print("âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨")
            return None
    else:
        print("âœ… ë°ì´í„°ê°€ ì´ë¯¸ ë¡œë“œë¨")
    
    results = {}
    
    try:
        # 2. ê³„ì¸µë³„ ì°¨íŠ¸
        print("\n2ï¸âƒ£ ê³„ì¸µë³„ ë¶„ì„...")
        
        # ìµœìƒìœ„ ê³„ì¸µ
        print("   ğŸ“Š ìµœìƒìœ„ ê³„ì¸µ...")
        results['top_level'] = create_ppi_component_comparison('ìµœìƒìœ„', 'yoy')
        
        # ìƒìœ„ ê³„ì¸µ
        print("   ğŸ“ˆ ìƒìœ„ ê³„ì¸µ...")
        results['upper_level'] = create_ppi_component_comparison('ìƒìœ„', 'mom')
        
        # ì¤‘ìœ„ ê³„ì¸µ
        print("   ğŸ” ì¤‘ìœ„ ê³„ì¸µ...")
        results['mid_level'] = create_ppi_component_comparison('ì¤‘ìœ„', 'yoy')
        
    except Exception as e:
        print(f"âš ï¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
    
    print(f"\nâœ… ì„¸ë¶€ ë¶„ì„ ì™„ë£Œ! ìƒì„±ëœ í•­ëª©: {len(results)}ê°œ")
    return results

# %%
# === ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ===

def show_available_components():
    """ì‚¬ìš© ê°€ëŠ¥í•œ PPI êµ¬ì„±ìš”ì†Œ í‘œì‹œ"""
    print("=== ì‚¬ìš© ê°€ëŠ¥í•œ PPI êµ¬ì„±ìš”ì†Œ ===")
    
    for series_id, description in PPI_SERIES.items():
        korean_name = PPI_KOREAN_NAMES.get(series_id, description)
        print(f"  '{series_id}': {korean_name} ({description})")

def get_data_status():
    """í˜„ì¬ ë°ì´í„° ìƒíƒœ ë°˜í™˜"""
    return {
        'loaded': PPI_DATA['load_info']['loaded'],
        'series_count': PPI_DATA['load_info']['series_count'],
        'available_series': list_available_series(),
        'load_info': PPI_DATA['load_info']
    }

def show_ppi_hierarchy():
    """PPI ê³„ì¸µ êµ¬ì¡° í‘œì‹œ"""
    print("=== PPI ê³„ì¸µ êµ¬ì¡° ===\n")
    
    for level, groups in PPI_HIERARCHY.items():
        print(f"### {level} ###")
        for group_name, series_list in groups.items():
            print(f"  {group_name}:")
            for series_id in series_list:
                korean_name = PPI_KOREAN_NAMES.get(series_id, PPI_SERIES.get(series_id, series_id))
                print(f"    - {series_id}: {korean_name}")
        print()

# %%
# === ì‚¬ìš© ì˜ˆì‹œ ===

def check_mom_all_commodities_issue():
    """
    MoM ì „ì²´ ìƒí’ˆ ìƒìŠ¹ë¥  ë¬¸ì œ í™•ì¸
    """
    if not PPI_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_ppi_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return False
    
    # ìµœê·¼ MoM ë°ì´í„° í™•ì¸
    mom_data = get_mom_data()
    if mom_data.empty:
        print("âš ï¸ MoM ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    latest_mom = mom_data.iloc[-1].dropna()
    latest_date = mom_data.index[-1]
    
    print(f"=== {latest_date.strftime('%Y-%m')} MoM ë°ì´í„° ë¶„ì„ ===")
    print(f"\nì „ì²´ ìƒí’ˆ (WPU00000000): {latest_mom.get('WPU00000000', 'N/A'):.2f}%")
    
    # ìµœì¢…ìˆ˜ìš” ê´€ë ¨ ì§€í‘œë“¤
    final_demand_series = {
        'WPUFD4': 'ìµœì¢…ìˆ˜ìš”',
        'WPUFD41': 'ìµœì¢…ìˆ˜ìš” ì¬í™”',
        'WPUFD42': 'ìµœì¢…ìˆ˜ìš” ì„œë¹„ìŠ¤',
        'WPUFD412': 'ìµœì¢…ìˆ˜ìš” ì—ë„ˆì§€',
        'WPUFD49104': 'ìµœì¢…ìˆ˜ìš” ì½”ì–´'
    }
    
    print("\nìµœì¢…ìˆ˜ìš” ê´€ë ¨ ì§€í‘œ:")
    for series_id, name in final_demand_series.items():
        value = latest_mom.get(series_id, None)
        if value is not None:
            print(f"  {name} ({series_id}): {value:.2f}%")
    
    # ìƒìŠ¹ë¥  ì •ë ¬
    sorted_mom = latest_mom.sort_values(ascending=False)
    
    print("\nìƒìœ„ 10ê°œ MoM ìƒìŠ¹ë¥ :")
    for i, (series, value) in enumerate(sorted_mom.head(10).items(), 1):
        korean_name = PPI_KOREAN_NAMES.get(series, series)
        print(f"  {i:2d}. {korean_name} ({series}): {value:.2f}%")
    
    print("\ní•˜ìœ„ 10ê°œ MoM ìƒìŠ¹ë¥ :")
    for i, (series, value) in enumerate(sorted_mom.tail(10).items(), 1):
        korean_name = PPI_KOREAN_NAMES.get(series, series)
        print(f"  {i:2d}. {korean_name} ({series}): {value:.2f}%")
    
    # ì „ì²´ ìƒí’ˆì˜ ìˆœìœ„ í™•ì¸
    all_commodities_value = latest_mom.get('WPU00000000', None)
    if all_commodities_value is not None:
        rank = (sorted_mom > all_commodities_value).sum() + 1
        print(f"\nì „ì²´ ìƒí’ˆ ìˆœìœ„: {len(sorted_mom)}ê°œ ì¤‘ {rank}ìœ„")
        print(f"ì „ì²´ ìƒí’ˆë³´ë‹¤ ë†’ì€ ìƒìŠ¹ë¥ : {(sorted_mom > all_commodities_value).sum()}ê°œ")
        print(f"ì „ì²´ ìƒí’ˆë³´ë‹¤ ë‚®ì€ ìƒìŠ¹ë¥ : {(sorted_mom < all_commodities_value).sum()}ê°œ")
    
    # ì „ì²´ ìƒí’ˆì´ ê°€ì¥ ë‚®ì€ ìƒìŠ¹ë¥ ì¸ì§€ í™•ì¸
    if all_commodities_value is not None:
        is_lowest = all_commodities_value == sorted_mom.iloc[-1]
        print(f"\nì „ì²´ ìƒí’ˆì´ ê°€ì¥ ë‚®ì€ ìƒìŠ¹ë¥ ì¸ê°€? {is_lowest}")
        
        if is_lowest:
            print("âš ï¸ ì´ìƒí•©ë‹ˆë‹¤! ì „ì²´ ìƒí’ˆì´ ê°€ì¥ ë‚®ì€ ìƒìŠ¹ë¥ ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.")
            print("ì „ì²´ ìƒí’ˆì€ ì¼ë°˜ì ìœ¼ë¡œ ê° êµ¬ì„±ìš”ì†Œì˜ ê°€ì¤‘í‰ê· ì´ë¯€ë¡œ ê°€ì¥ ë‚®ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # ì›ì¸ ë¶„ì„
            print("\nê°€ëŠ¥í•œ ì›ì¸:")
            print("1. ë°ì´í„° ì˜¤ë¥˜ ë˜ëŠ” ê³„ì‚° ì˜¤ë¥˜")
            print("2. ì¼ë¶€ êµ¬ì„±ìš”ì†Œì˜ ê°€ì¤‘ì¹˜ê°€ ìŒìˆ˜ì¼ ê°€ëŠ¥ì„±")
            print("3. ì „ì²´ ìƒí’ˆ ì§€ìˆ˜ì˜ ê³„ì‚° ë°©ì‹ ë¬¸ì œ")
            
            return True
        else:
            print("âœ… ì •ìƒì ì¸ ë²”ìœ„ ë‚´ì— ìˆìŠµë‹ˆë‹¤.")
            return False
    
    return False

print("\n=== PPI ë¶„ì„ ë„êµ¬ ì‚¬ìš©ë²• ===")
print("\nâœ¨ ìƒˆë¡œìš´ ê¸°ëŠ¥:")
print("   show_category_options()  # ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ ì˜µì…˜ í‘œì‹œ")
print("   create_filtered_ppi_chart(selected_series=['WPUFD4', 'WPUFD41'])  # ì‚¬ìš©ì ì„ íƒ ì‹œë¦¬ì¦ˆ")
print("   create_filtered_ppi_chart(category_filter='ìµœì¢…ìˆ˜ìš”')  # ì¹´í…Œê³ ë¦¬ í•„í„° (ê³„ì ˆë¯¸ì¡°ì •)")
print("   create_filtered_ppi_chart(category_filter='ìµœì¢…ìˆ˜ìš”_ê³„ì ˆì¡°ì •')  # ê³„ì ˆì¡°ì • ë°ì´í„°")
print("   create_category_comparison_chart(['ìµœì¢…ìˆ˜ìš”', 'ì¤‘ê°„ìˆ˜ìš”'])  # ì¹´í…Œê³ ë¦¬ ë¹„êµ")
print("   create_ppi_horizontal_bar_chart(series_ids=['WPUFD4', 'WPUFD41'])  # ì‹œë¦¬ì¦ˆ IDë¡œ ë°” ì°¨íŠ¸")
print("   check_mom_all_commodities_issue()  # MoM ì „ì²´ ìƒí’ˆ ë¬¸ì œ í™•ì¸")
print("1. ë°ì´í„° ë¡œë“œ (CSV ìš°ì„ , API ë°±ì—…):")
print("   load_all_ppi_data()  # CSVê°€ ìˆìœ¼ë©´ ë¡œë“œ í›„ ì—…ë°ì´íŠ¸")
print("   load_ppi_data_from_csv()  # CSVì—ì„œë§Œ ë¡œë“œ")
print("   update_ppi_data_from_api()  # ìµœì‹  ë°ì´í„°ë§Œ APIë¡œ ì—…ë°ì´íŠ¸")
print()
print("2. ë°ì´í„° ì €ì¥:")
print("   save_ppi_data_to_csv()  # í˜„ì¬ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥")
print()
print("3. API í‚¤ ê´€ë¦¬:")
print("   switch_api_key()  # API í‚¤ ìˆ˜ë™ ì „í™˜")
print()
print("4. ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸:")
print("   check_recent_data_consistency()  # ìµœê·¼ 3ê°œ ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸")
print("   update_ppi_data_from_api(smart_update=True)  # ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸")
print("   update_ppi_data_from_api(smart_update=False)  # ê°•ì œ ì—…ë°ì´íŠ¸")
print()
print("5. ì°¨íŠ¸ ìƒì„±:")
print("   create_ppi_bar_chart()")
print("   create_ppi_timeseries_chart(['WPUFD4', 'WPUFD49104'])  # ê³„ì ˆë¯¸ì¡°ì •")
print("   create_ppi_timeseries_chart(['WPSFD4', 'WPSFD49104'])  # ê³„ì ˆì¡°ì •")
print("   create_ppi_component_comparison('ìƒìœ„', 'yoy')")
print("   create_ppi_component_comparison('ìµœì¢…ìˆ˜ìš”', 'yoy', use_new_categories=True)  # ìƒˆë¡œìš´ ë¶„ë¥˜ ì‚¬ìš©")
print("   create_ppi_contribution_chart()")
print("   create_ppi_horizontal_bar_chart()  # ì „ì²´ MoM ë°ì´í„°")
print("   create_ppi_horizontal_bar_chart(series_ids=['WPUFD4', 'WPUFD41'])  # íŠ¹ì • ì‹œë¦¬ì¦ˆë§Œ")
print()
print("6. í†µí•© ë¶„ì„:")
print("   run_complete_ppi_analysis()")
print("   run_detailed_ppi_analysis()")
print()
print("7. ë°ì´í„° ìƒíƒœ í™•ì¸:")
print("   get_data_status()")
print("   show_available_components()")
print("   show_ppi_hierarchy()")
print("   show_category_options()  # ìƒˆë¡œìš´ ë¶„ë¥˜ ì²´ê³„ ì˜µì…˜")

# %%
# ì‚¬ìš© ê°€ëŠ¥í•œ êµ¬ì„±ìš”ì†Œ í‘œì‹œ
# show_available_components()

# %%
# PPI ê³„ì¸µ êµ¬ì¡° í‘œì‹œ
# show_ppi_hierarchy()

# %%
# ê¸°ë³¸ PPI ë¶„ì„ ì‹¤í–‰
run_complete_ppi_analysis()

# %%
# ìƒˆë¡œìš´ ë¶„ë¥˜ ì²´ê³„ë¥¼ ì‚¬ìš©í•œ êµ¬ì„±ìš”ì†Œ ë¹„êµ
# print("\n=== ìƒˆë¡œìš´ ë¶„ë¥˜ ì²´ê³„ ì‚¬ìš© ì˜ˆì‹œ ===")
# create_ppi_component_comparison('ìµœì¢…ìˆ˜ìš”', 'yoy', use_new_categories=True)

# %%
# create_ppi_component_comparison('ìµœìƒìœ„', 'yoy')

# %%
# create_ppi_contribution_chart()

# %%
# MoM ì „ì²´ ìƒí’ˆ ìƒìŠ¹ë¥  ë¬¸ì œ í™•ì¸
# check_mom_all_commodities_issue()

# %%
# ìƒˆë¡œìš´ ë¶„ë¥˜ ì²´ê³„ ì˜µì…˜ í‘œì‹œ
# show_category_options()

# %%
# ìƒˆë¡œìš´ ë¶„ë¥˜ ì²´ê³„ë¥¼ ì‚¬ìš©í•œ ì°¨íŠ¸ ì˜ˆì‹œ
# print("\n=== ìƒˆë¡œìš´ ë¶„ë¥˜ ì²´ê³„ ì‚¬ìš© ì˜ˆì‹œ ===")
# print("1. ìµœì¢…ìˆ˜ìš” ì¹´í…Œê³ ë¦¬ ì‹œê°í™” (ê³„ì ˆë¯¸ì¡°ì •):")
create_filtered_ppi_chart(category_filter='ìµœì¢…ìˆ˜ìš”', chart_type='yoy')

# print("\n2. ìµœì¢…ìˆ˜ìš” ì¹´í…Œê³ ë¦¬ ì‹œê°í™” (ê³„ì ˆì¡°ì •):")
create_filtered_ppi_chart(category_filter='ìµœì¢…ìˆ˜ìš”_ê³„ì ˆì¡°ì •', chart_type='mom')

# print("\n3. ì‚¬ìš©ì ì„ íƒ ì‹œë¦¬ì¦ˆ ì‹œê°í™”:")
# create_filtered_ppi_chart(selected_series=['WPUFD4', 'WPU00000000', 'WPUID61'], chart_type='mom')

# print("\n4. ì¹´í…Œê³ ë¦¬ ë¹„êµ ì°¨íŠ¸:")
create_category_comparison_chart(['ìµœì¢…ìˆ˜ìš”', 'ì¤‘ê°„ìˆ˜ìš”', 'ì „ì²´ìƒí’ˆ'], 'yoy')

# %%
create_ppi_horizontal_bar_chart(num_categories=100)
# %%
# create_ppi_bar_chart()

# %%
# create_ppi_bar_chart(['WPU1411', 'WPU0638', 'WPU0571', 'WPU0221', 'WPU061',
#                        'WPU081', 'WPU1017', 'WPU057303', 'WPU029', 'WPU0561', 'WPU012', 'WPU101211'])
# %%
# ì‹œë¦¬ì¦ˆ IDë¡œ ì§ì ‘ ê°€ë¡œ ë°” ì°¨íŠ¸ ìƒì„± (ìƒˆë¡œìš´ ê¸°ëŠ¥)
create_ppi_horizontal_bar_chart(series_ids=['WPU1411', 'WPU0638', 'WPU0571', 'WPU0221', 'WPU061',
                       'WPU081', 'WPU1017', 'WPU057303', 'WPU029', 'WPU0561', 'WPU012', 'WPU101211'],
                       num_categories=12)
# %%
