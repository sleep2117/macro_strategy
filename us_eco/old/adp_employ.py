# %%
"""
FRED API ì „ìš© ADP Employment ë¶„ì„ ë° ì‹œê°í™” ë„êµ¬
- FRED APIë¥¼ ì‚¬ìš©í•˜ì—¬ ADP Employment ë°ì´í„° ìˆ˜ì§‘
- ì‚¬ì—… ê·œëª¨ë³„/ì‚°ì—…ë³„ ë°ì´í„° ë¶„ë¥˜
- MoM/3M/6M/1Y ê¸°ì¤€ ì‹œê°í™” ì§€ì›
"""
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import sys
import warnings
import os
warnings.filterwarnings('ignore')

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    import requests
    import json
    FRED_API_AVAILABLE = True
    print("âœ“ FRED API ì—°ë™ ê°€ëŠ¥ (requests ë¼ì´ë¸ŒëŸ¬ë¦¬)")
except ImportError:
    print("âš ï¸ requests ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜í•˜ì„¸ìš”: pip install requests")
    FRED_API_AVAILABLE = False

# FRED API í‚¤ ì„¤ì • (ì—¬ê¸°ì— ì‹¤ì œ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”)
FRED_API_KEY = 'f4bd434811e42e42287a0e5ccf400fff'  # https://fred.stlouisfed.org/docs/api/api_key.html ì—ì„œ ë°œê¸‰

# KPDS ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸° (í•„ìˆ˜)
sys.path.append('/home/jyp0615')
from kpds_fig_format_enhanced import *

print("âœ“ KPDS ì‹œê°í™” í¬ë§· ë¡œë“œë¨")

# %%
# === ADP ë°ì´í„° ê³„ì¸µ êµ¬ì¡° ì •ì˜ ===
# ì—…ë°ì´íŠ¸ ì²´í¬

# ADP ì‹œë¦¬ì¦ˆ ë§µ - ì‚¬ì—… ê·œëª¨ë³„
ADP_SIZE_SERIES = {
    'total': 'ADPMNUSNERSA',  # Total nonfarm private
    'size_1_19': 'ADPMES1T19ENERSA',  # 1-19 employees
    'size_20_49': 'ADPMES20T49ENERSA',  # 20-49 employees
    'size_50_249': 'ADPMES50T249ENERSA',  # 50-249 employees
    'size_250_499': 'ADPMES250T499ENERSA',  # 250-499 employees
    'size_500_plus': 'ADPMES500PENERSA'  # 500+ employees
}

# ADP ì‹œë¦¬ì¦ˆ ë§µ - ì‚°ì—…ë³„
ADP_INDUSTRY_SERIES = {
    'construction': 'ADPMINDCONNERSA',
    'education_health': 'ADPMINDEDHLTNERSA',
    'financial': 'ADPMINDFINNERSA',
    'information': 'ADPMINDINFONERSA',
    'leisure_hospitality': 'ADPMINDLSHPNERSA',
    'manufacturing': 'ADPMINDMANNERSA',
    'natural_resources': 'ADPMINDNRMINNERSA',
    'other_services': 'ADPMINDOTHSRVNERSA',
    'professional_business': 'ADPMINDPROBUSNERSA',
    'trade_transport_utilities': 'ADPMINDTTUNERSA'
}

# ëª¨ë“  ADP ì‹œë¦¬ì¦ˆ í†µí•©
ALL_ADP_SERIES = {**ADP_SIZE_SERIES, **ADP_INDUSTRY_SERIES}

# í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘
ADP_KOREAN_NAMES = {
    # ì‚¬ì—… ê·œëª¨ë³„
    'total': 'ì „ì²´ ë¯¼ê°„ ê³ ìš©',
    'size_1_19': '1-19ëª…',
    'size_20_49': '20-49ëª…',
    'size_50_249': '50-249ëª…',
    'size_250_499': '250-499ëª…',
    'size_500_plus': '500ëª… ì´ìƒ',
    
    # ì‚°ì—…ë³„
    'construction': 'ê±´ì„¤ì—…',
    'education_health': 'êµìœ¡Â·ë³´ê±´',
    'financial': 'ê¸ˆìœµ',
    'information': 'ì •ë³´',
    'leisure_hospitality': 'ë ˆì €Â·ìˆ™ë°•',
    'manufacturing': 'ì œì¡°ì—…',
    'natural_resources': 'ì²œì—°ìì›Â·ì±„êµ´',
    'other_services': 'ê¸°íƒ€ ì„œë¹„ìŠ¤',
    'professional_business': 'ì „ë¬¸Â·ë¹„ì¦ˆë‹ˆìŠ¤ ì„œë¹„ìŠ¤',
    'trade_transport_utilities': 'ë¬´ì—­Â·ìš´ì†¡Â·ìœ í‹¸ë¦¬í‹°'
}

# %%
# === ì „ì—­ ë°ì´í„° ì €ì¥ì†Œ ===

# FRED ì„¸ì…˜
FRED_SESSION = None

# CSV íŒŒì¼ ê²½ë¡œ
CSV_FILE_PATH = '/home/jyp0615/us_eco/data/adp_employ_data.csv'

# ì „ì—­ ë°ì´í„° ì €ì¥ì†Œ
ADP_DATA = {
    'raw_data': pd.DataFrame(),      # ì›ë³¸ ë ˆë²¨ ë°ì´í„° (ì²œ ëª… ë‹¨ìœ„)
    'mom_data': pd.DataFrame(),      # ì „ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ë°ì´í„°
    'mom_change': pd.DataFrame(),    # ì „ì›”ëŒ€ë¹„ ë³€í™”ëŸ‰ ë°ì´í„° (ì²œ ëª…)
    'latest_values': {},             # ìµœì‹  ê°’ë“¤
    'load_info': {
        'loaded': False,
        'load_time': None,
        'start_date': None,
        'series_count': 0,
        'data_points': 0
    }
}

# %%
# === CSV ë°ì´í„° ê´€ë¦¬ í•¨ìˆ˜ë“¤ ===

def ensure_data_directory():
    """ë°ì´í„° ë””ë ‰í„°ë¦¬ ìƒì„± í™•ì¸"""
    data_dir = os.path.dirname(CSV_FILE_PATH)
    if not os.path.exists(data_dir):
        os.makedirs(data_dir)
        print(f"ğŸ“ ë°ì´í„° ë””ë ‰í„°ë¦¬ ìƒì„±: {data_dir}")

def save_data_to_csv():
    """í˜„ì¬ ë°ì´í„°ë¥¼ CSVì— ì €ì¥"""
    if ADP_DATA['raw_data'].empty:
        print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    ensure_data_directory()
    
    try:
        # ë‚ ì§œë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€í•˜ì—¬ ì €ì¥
        df_to_save = ADP_DATA['raw_data'].copy()
        df_to_save.index.name = 'date'
        df_to_save.to_csv(CSV_FILE_PATH)
        print(f"ğŸ’¾ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {CSV_FILE_PATH}")
        return True
    except Exception as e:
        print(f"âŒ CSV ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def load_data_from_csv():
    """CSVì—ì„œ ë°ì´í„° ë¡œë“œ"""
    if not os.path.exists(CSV_FILE_PATH):
        print("ğŸ“‚ ì €ì¥ëœ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    try:
        df = pd.read_csv(CSV_FILE_PATH, index_col=0, parse_dates=True)
        print(f"ğŸ“‚ CSV ë°ì´í„° ë¡œë“œ: {len(df)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
        return df
    except Exception as e:
        print(f"âŒ CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def check_recent_data_consistency(csv_data=None, tolerance=1000.0):
    """
    ìµœê·¼ ë°ì´í„°ì˜ ì¼ì¹˜ì„± í™•ì¸ (ADP ê³ ìš© ë°ì´í„°ìš© - ì²œëª… ë‹¨ìœ„)
    
    Args:
        csv_data: CSVì—ì„œ ë¡œë“œëœ ë°ì´í„° (Noneì´ë©´ ìë™ ë¡œë“œ)
        tolerance: í—ˆìš© ì˜¤ì°¨ (ì²œëª… ë‹¨ìœ„, ê¸°ë³¸ê°’: 1000ì²œëª… = 100ë§Œëª…)
    
    Returns:
        dict: ì¼ì¹˜ì„± í™•ì¸ ê²°ê³¼
    """
    if csv_data is None:
        csv_data = load_data_from_csv()
    
    if csv_data is None or csv_data.empty:
        return {'needs_update': True, 'reason': 'CSV ë°ì´í„° ì—†ìŒ'}
    
    # ìµœê·¼ 3ê°œì›” ë°ì´í„° í™•ì¸
    try:
        # ë‚ ì§œ ì •ê·œí™” (ë…„-ì›”)
        csv_data.index = pd.to_datetime(csv_data.index)
        csv_latest = csv_data.tail(3)
        
        # ë™ì¼í•œ ê¸°ê°„ì˜ API ë°ì´í„°ì™€ ë¹„êµ
        if ADP_DATA['raw_data'].empty:
            return {'needs_update': True, 'reason': 'API ë°ì´í„° ì—†ìŒ'}
        
        api_data = ADP_DATA['raw_data']
        api_data.index = pd.to_datetime(api_data.index)
        
        # ê³µí†µ ë‚ ì§œ ì°¾ê¸°
        common_dates = csv_latest.index.intersection(api_data.index)
        
        if len(common_dates) == 0:
            return {'needs_update': True, 'reason': 'ê³µí†µ ë‚ ì§œ ì—†ìŒ'}
        
        # ìµœê·¼ ë°ì´í„° ë¹„êµ
        inconsistencies = []
        
        for date in common_dates[-3:]:  # ìµœê·¼ 3ê°œ ë°ì´í„°ë§Œ í™•ì¸
            csv_row = csv_latest.loc[date]
            api_row = api_data.loc[date]
            
            for column in csv_row.index:
                if column in api_row.index:
                    csv_val = csv_row[column]
                    api_val = api_row[column]
                    
                    # NaN ê°’ ì²˜ë¦¬
                    if pd.isna(csv_val) and pd.isna(api_val):
                        continue
                    if pd.isna(csv_val) or pd.isna(api_val):
                        inconsistencies.append({
                            'date': date.strftime('%Y-%m'),
                            'series': column,
                            'csv_value': csv_val,
                            'api_value': api_val,
                            'difference': 'NaN ë¶ˆì¼ì¹˜',
                            'significant': True
                        })
                        continue
                    
                    # ì°¨ì´ ê³„ì‚° (ì²œëª… ë‹¨ìœ„)
                    diff = abs(csv_val - api_val)
                    
                    # ìœ ì˜ë¯¸í•œ ì°¨ì´ì¸ì§€ í™•ì¸ (tolerance ì´ìƒ)
                    is_significant = diff > tolerance
                    
                    if is_significant:
                        inconsistencies.append({
                            'date': date.strftime('%Y-%m'),
                            'series': column,
                            'csv_value': csv_val,
                            'api_value': api_val,
                            'difference': diff,
                            'significant': True
                        })
        
        # ìœ ì˜ë¯¸í•œ ë¶ˆì¼ì¹˜ê°€ ìˆëŠ”ì§€ í™•ì¸
        significant_inconsistencies = [inc for inc in inconsistencies if inc['significant']]
        
        result = {
            'needs_update': len(significant_inconsistencies) > 0,
            'inconsistencies': inconsistencies,
            'significant_count': len(significant_inconsistencies),
            'total_compared': len(common_dates),
            'tolerance': tolerance
        }
        
        if result['needs_update']:
            result['reason'] = f'ìœ ì˜ë¯¸í•œ ë°ì´í„° ë¶ˆì¼ì¹˜ {len(significant_inconsistencies)}ê±´ ë°œê²¬'
        else:
            result['reason'] = 'ìµœê·¼ ë°ì´í„° ì¼ì¹˜'
        
        return result
        
    except Exception as e:
        print(f"âš ï¸ ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return {'needs_update': True, 'reason': f'í™•ì¸ ì˜¤ë¥˜: {str(e)}'}

def print_consistency_results(consistency_result):
    """ì¼ì¹˜ì„± í™•ì¸ ê²°ê³¼ ì¶œë ¥"""
    result = consistency_result
    
    print(f"\nğŸ” ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸ ê²°ê³¼")
    print(f"   ì—…ë°ì´íŠ¸ í•„ìš”: {result['needs_update']}")
    print(f"   ì‚¬ìœ : {result['reason']}")
    
    if 'inconsistencies' in result and result['inconsistencies']:
        print(f"   í—ˆìš© ì˜¤ì°¨: {result['tolerance']:,.0f}ì²œëª…")
        print(f"   ë¹„êµ ê¸°ê°„: {result['total_compared']}ê°œì›”")
        print(f"   ì „ì²´ ë¶ˆì¼ì¹˜: {len(result['inconsistencies'])}ê±´")
        print(f"   ìœ ì˜ë¯¸í•œ ë¶ˆì¼ì¹˜: {result['significant_count']}ê±´")
        
        if result['significant_count'] > 0:
            print(f"\n   ğŸ“Š ìœ ì˜ë¯¸í•œ ì°¨ì´ ì„¸ë¶€ ë‚´ìš©:")
            for inc in result['inconsistencies']:
                if inc['significant']:
                    if isinstance(inc['difference'], str):
                        print(f"   - {inc['date']} {inc['series']}: {inc['difference']}")
                    else:
                        csv_val = inc['csv_value']
                        api_val = inc['api_value']
                        diff = inc['difference']
                        print(f"   - {inc['date']} {inc['series']}: CSV={csv_val:,.0f} vs API={api_val:,.0f} (ì°¨ì´: {diff:,.0f}ì²œëª…)")

# %%
# === FRED API ì´ˆê¸°í™” ë° ë°ì´í„° ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜ ===

def initialize_fred_api():
    """FRED API ì„¸ì…˜ ì´ˆê¸°í™”"""
    global FRED_SESSION
    
    if not FRED_API_AVAILABLE:
        print("âš ï¸ FRED API ì‚¬ìš© ë¶ˆê°€ (requests ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ)")
        return False
    
    if not FRED_API_KEY or FRED_API_KEY == 'YOUR_FRED_API_KEY_HERE':
        print("âš ï¸ FRED API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. FRED_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        print("  https://fred.stlouisfed.org/docs/api/api_key.html ì—ì„œ ë¬´ë£Œë¡œ ë°œê¸‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        return False
    
    try:
        FRED_SESSION = requests.Session()
        print("âœ“ FRED API ì„¸ì…˜ ì´ˆê¸°í™” ì„±ê³µ")
        return True
    except Exception as e:
        print(f"âš ï¸ FRED API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def get_fred_data(series_id, start_date='2020-01-01', end_date=None):
    """
    FRED APIì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    
    Args:
        series_id: FRED ì‹œë¦¬ì¦ˆ ID
        start_date: ì‹œì‘ ë‚ ì§œ
        end_date: ì¢…ë£Œ ë‚ ì§œ (Noneì´ë©´ í˜„ì¬)
    
    Returns:
        pandas.Series: ë‚ ì§œë¥¼ ì¸ë±ìŠ¤ë¡œ í•˜ëŠ” ì‹œë¦¬ì¦ˆ ë°ì´í„°
    """
    if not FRED_API_AVAILABLE or FRED_SESSION is None:
        print(f"âŒ FRED API ì‚¬ìš© ë¶ˆê°€ - {series_id}")
        return None
    
    if end_date is None:
        end_date = datetime.datetime.now().strftime('%Y-%m-%d')
    
    # FRED API URL êµ¬ì„±
    url = f'https://api.stlouisfed.org/fred/series/observations'
    params = {
        'series_id': series_id,
        'api_key': FRED_API_KEY,
        'file_type': 'json',
        'observation_start': start_date,
        'observation_end': end_date,
        'sort_order': 'asc'
    }
    
    try:
        print(f"ğŸ“Š FREDì—ì„œ ë¡œë”©: {series_id}")
        response = FRED_SESSION.get(url, params=params, timeout=30)
        response.raise_for_status()
        
        data = response.json()
        
        if 'observations' in data:
            observations = data['observations']
            
            # ë°ì´í„° ì •ë¦¬
            dates = []
            values = []
            
            for obs in observations:
                try:
                    date = pd.to_datetime(obs['date'])
                    value = float(obs['value'])
                    
                    dates.append(date)
                    values.append(value)
                except (ValueError, KeyError):
                    continue
            
            if dates and values:
                series = pd.Series(values, index=dates, name=series_id)
                series = series.sort_index()
                
                print(f"âœ“ FRED ì„±ê³µ: {series_id} ({len(series)}ê°œ í¬ì¸íŠ¸)")
                return series
            else:
                print(f"âŒ FRED ë°ì´í„° ì—†ìŒ: {series_id}")
                return None
        else:
            print(f"âŒ FRED ì‘ë‹µì— ë°ì´í„° ì—†ìŒ: {series_id}")
            return None
            
    except Exception as e:
        print(f"âŒ FRED ìš”ì²­ ì‹¤íŒ¨: {series_id} - {e}")
        return None

# %%
# === ë°ì´í„° ê³„ì‚° í•¨ìˆ˜ë“¤ ===

def calculate_mom_change(data):
    """ì „ì›”ëŒ€ë¹„ ë³€í™”ëŸ‰ ê³„ì‚° (ì²œ ëª… ë‹¨ìœ„)"""
    return data.diff()

def calculate_mom_percent(data):
    """ì „ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ê³„ì‚° (%)"""
    return (data.pct_change() * 100)

def calculate_average_change(data, months):
    """íŠ¹ì • ê¸°ê°„ í‰ê·  ëŒ€ë¹„ ë³€í™”ëŸ‰ ê³„ì‚°"""
    avg = data.rolling(window=months).mean()
    return data - avg.shift(1)

def calculate_average_percent_change(data, months):
    """íŠ¹ì • ê¸°ê°„ í‰ê·  ëŒ€ë¹„ ë³€í™”ìœ¨ ê³„ì‚°"""
    avg = data.rolling(window=months).mean()
    return ((data / avg.shift(1)) - 1) * 100

# %%
# === ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ë“¤ ===

def load_all_adp_data(start_date='2020-01-01', force_reload=False, smart_update=True):
    """
    ëª¨ë“  ADP ë°ì´í„° ë¡œë“œ (ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì§€ì›)
    
    Args:
        start_date: ì‹œì‘ ë‚ ì§œ
        force_reload: ê°•ì œ ì¬ë¡œë“œ ì—¬ë¶€
        smart_update: ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
    
    Returns:
        bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
    """
    global ADP_DATA
    
    # ì´ë¯¸ ë¡œë“œëœ ê²½ìš° ìŠ¤í‚µ (ê°•ì œ ì¬ë¡œë“œê°€ ì•„ë‹Œ ê²½ìš°)
    if ADP_DATA['load_info']['loaded'] and not force_reload and not smart_update:
        print("ğŸ’¾ ì´ë¯¸ ë¡œë“œëœ ë°ì´í„° ì‚¬ìš© ì¤‘")
        print_load_info()
        return True
    
    # ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ë¡œì§
    needs_api_call = True
    consistency_result = None
    
    if smart_update and not force_reload:
        print("ğŸ¤– ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ëª¨ë“œ í™œì„±í™”")
        
        # ë¨¼ì € CSVì—ì„œ ë°ì´í„° ë¡œë“œ ì‹œë„
        csv_data = load_data_from_csv()
        
        if csv_data is not None and not csv_data.empty:
            # CSV ë°ì´í„°ë¥¼ ì„ì‹œë¡œ ì „ì—­ ì €ì¥ì†Œì— ë¡œë“œ
            ADP_DATA['raw_data'] = csv_data
            ADP_DATA['mom_change'] = calculate_mom_change(ADP_DATA['raw_data'])
            ADP_DATA['mom_data'] = calculate_mom_percent(ADP_DATA['raw_data'])
            
            # ìµœì‹  ëª‡ ê°œ ë°ì´í„°ë§Œ APIë¡œ ê°€ì ¸ì™€ì„œ ë¹„êµ
            print("ğŸ” ìµœê·¼ ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸ ì¤‘...")
            
            # FRED API ì´ˆê¸°í™”
            if initialize_fred_api():
                # ìµœê·¼ 3ê°œì›” ë°ì´í„°ë§Œ APIì—ì„œ ê°€ì ¸ì˜¤ê¸°
                recent_start = (datetime.datetime.now() - timedelta(days=90)).strftime('%Y-%m-%d')
                
                recent_data_dict = {}
                # ì „ì²´ ë°ì´í„°ë§Œ ìš°ì„  í™•ì¸ (ë¹ ë¥¸ ì²´í¬)
                series_data = get_fred_data(ADP_SIZE_SERIES['total'], recent_start)
                if series_data is not None:
                    recent_data_dict['total'] = series_data
                    
                    # ì„ì‹œë¡œ API ë°ì´í„°ë¥¼ ì €ì¥
                    temp_api_data = ADP_DATA['raw_data'].copy()
                    
                    # ìµœì‹  API ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸
                    for date in series_data.index:
                        if 'total' in temp_api_data.columns:
                            temp_api_data.loc[date, 'total'] = series_data[date]
                    
                    # ì„ì‹œë¡œ API ë°ì´í„°ë¥¼ ì „ì—­ ì €ì¥ì†Œì— ì €ì¥
                    original_raw_data = ADP_DATA['raw_data'].copy()
                    ADP_DATA['raw_data'] = temp_api_data
                    
                    # ì¼ì¹˜ì„± í™•ì¸ (ADP ê³ ìš© ë°ì´í„°ëŠ” í° ìˆ˜ì¹˜ì´ë¯€ë¡œ 1000ì²œëª…=100ë§Œëª…ì„ í—ˆìš© ì˜¤ì°¨ë¡œ ì„¤ì •)
                    consistency_result = check_recent_data_consistency(csv_data, tolerance=1000.0)
                    
                    # ì›ë³¸ ë°ì´í„° ë³µì›
                    ADP_DATA['raw_data'] = original_raw_data
                    
                    print_consistency_results(consistency_result)
                    
                    needs_api_call = consistency_result['needs_update']
                    
                    if not needs_api_call:
                        print("âœ… ìµœê·¼ ë°ì´í„°ê°€ ì¼ì¹˜í•¨ - API í˜¸ì¶œ ê±´ë„ˆë›°ê¸°")
                        # CSV ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
                        latest_values = {}
                        for col in ADP_DATA['raw_data'].columns:
                            latest_values[col] = {
                                'value': ADP_DATA['raw_data'][col].iloc[-1],
                                'mom_change': ADP_DATA['mom_change'][col].iloc[-1],
                                'mom_percent': ADP_DATA['mom_data'][col].iloc[-1]
                            }
                        
                        ADP_DATA['latest_values'] = latest_values
                        ADP_DATA['load_info'] = {
                            'loaded': True,
                            'load_time': datetime.datetime.now(),
                            'start_date': start_date,
                            'series_count': len(ADP_DATA['raw_data'].columns),
                            'data_points': len(ADP_DATA['raw_data']),
                            'source': 'CSV (ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸)',
                            'consistency_check': consistency_result
                        }
                        
                        print("ğŸ’¾ CSV ë°ì´í„° ì‚¬ìš© (ì¼ì¹˜ì„± í™•ì¸ë¨)")
                        print_load_info()
                        return True
                    else:
                        print("ğŸ“¡ ë°ì´í„° ë¶ˆì¼ì¹˜ ê°ì§€ - ì „ì²´ API í˜¸ì¶œ ì§„í–‰")
    
    # APIë¥¼ í†µí•œ ì „ì²´ ë°ì´í„° ë¡œë“œ
    if needs_api_call:
        print("ğŸš€ ADP ë°ì´í„° ë¡œë”© ì‹œì‘... (FRED API)")
        print("="*50)
        
        # FRED API ì´ˆê¸°í™”
        if not initialize_fred_api():
            print("âŒ FRED API ì´ˆê¸°í™” ì‹¤íŒ¨")
            return False
        
        # ë°ì´í„° ìˆ˜ì§‘
        raw_data_dict = {}
        
        # ì‚¬ì—… ê·œëª¨ë³„ ë°ì´í„° ë¡œë“œ
        print("\nğŸ“Š ì‚¬ì—… ê·œëª¨ë³„ ë°ì´í„° ë¡œë”©...")
        for series_name, series_id in ADP_SIZE_SERIES.items():
            series_data = get_fred_data(series_id, start_date)
            if series_data is not None and len(series_data) > 0:
                raw_data_dict[series_name] = series_data
            else:
                print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {series_name}")
        
        # ì‚°ì—…ë³„ ë°ì´í„° ë¡œë“œ
        print("\nğŸ­ ì‚°ì—…ë³„ ë°ì´í„° ë¡œë”©...")
        for series_name, series_id in ADP_INDUSTRY_SERIES.items():
            series_data = get_fred_data(series_id, start_date)
            if series_data is not None and len(series_data) > 0:
                raw_data_dict[series_name] = series_data
            else:
                print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {series_name}")
        
        if len(raw_data_dict) < 5:  # ìµœì†Œ 5ê°œ ì‹œë¦¬ì¦ˆëŠ” ìˆì–´ì•¼ í•¨
            error_msg = f"âŒ ë¡œë“œëœ ì‹œë¦¬ì¦ˆê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤: {len(raw_data_dict)}ê°œ"
            print(error_msg)
            return False
        
        # ì „ì—­ ì €ì¥ì†Œì— ì €ì¥
        ADP_DATA['raw_data'] = pd.DataFrame(raw_data_dict)
        ADP_DATA['mom_change'] = calculate_mom_change(ADP_DATA['raw_data'])
        ADP_DATA['mom_data'] = calculate_mom_percent(ADP_DATA['raw_data'])
        
        # ìµœì‹  ê°’ ì €ì¥
        latest_values = {}
        for col in ADP_DATA['raw_data'].columns:
            latest_values[col] = {
                'value': ADP_DATA['raw_data'][col].iloc[-1],
                'mom_change': ADP_DATA['mom_change'][col].iloc[-1],
                'mom_percent': ADP_DATA['mom_data'][col].iloc[-1]
            }
        
        ADP_DATA['latest_values'] = latest_values
        ADP_DATA['load_info'] = {
            'loaded': True,
            'load_time': datetime.datetime.now(),
            'start_date': start_date,
            'series_count': len(raw_data_dict),
            'data_points': len(ADP_DATA['raw_data']),
            'source': 'API (ì „ì²´ ë¡œë“œ)'
        }
        
        if consistency_result:
            ADP_DATA['load_info']['consistency_check'] = consistency_result
        
        # CSVì— ì €ì¥
        save_data_to_csv()
        
        print("\nâœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
        print_load_info()
        
        return True
    
    return False

def print_load_info():
    """ë¡œë“œ ì •ë³´ ì¶œë ¥"""
    info = ADP_DATA['load_info']
    if not info['loaded']:
        print("âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ")
        return
    
    print(f"ğŸ“Š ë¡œë“œëœ ë°ì´í„° ì •ë³´:")
    print(f"   ì‹œë¦¬ì¦ˆ ê°œìˆ˜: {info['series_count']}")
    print(f"   ë°ì´í„° í¬ì¸íŠ¸: {info['data_points']}")
    print(f"   ì‹œì‘ ë‚ ì§œ: {info['start_date']}")
    print(f"   ë¡œë“œ ì‹œê°„: {info['load_time'].strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"   ë°ì´í„° ì†ŒìŠ¤: {info.get('source', 'API')}")
    
    if not ADP_DATA['raw_data'].empty:
        date_range = f"{ADP_DATA['raw_data'].index[0].strftime('%Y-%m')} ~ {ADP_DATA['raw_data'].index[-1].strftime('%Y-%m')}"
        print(f"   ë°ì´í„° ê¸°ê°„: {date_range}")
    
    if 'consistency_check' in info:
        consistency = info['consistency_check']
        print(f"   ì¼ì¹˜ì„± í™•ì¸: {consistency.get('reason', 'N/A')}")

# %%
# === ë°ì´í„° ì ‘ê·¼ í•¨ìˆ˜ë“¤ ===

def get_raw_data(series_names=None):
    """ì›ë³¸ ë°ì´í„° ë°˜í™˜"""
    if not ADP_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_adp_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return pd.DataFrame()
    
    if series_names is None:
        return ADP_DATA['raw_data'].copy()
    
    available_series = [s for s in series_names if s in ADP_DATA['raw_data'].columns]
    if not available_series:
        print(f"âš ï¸ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤: {series_names}")
        return pd.DataFrame()
    
    return ADP_DATA['raw_data'][available_series].copy()

def get_mom_data(series_names=None):
    """ì „ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ë°ì´í„° ë°˜í™˜"""
    if not ADP_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    
    if series_names is None:
        return ADP_DATA['mom_data'].copy()
    
    available_series = [s for s in series_names if s in ADP_DATA['mom_data'].columns]
    return ADP_DATA['mom_data'][available_series].copy()

def get_latest_values(series_names=None):
    """ìµœì‹  ê°’ë“¤ ë°˜í™˜"""
    if not ADP_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return {}
    
    if series_names is None:
        return ADP_DATA['latest_values'].copy()
    
    return {name: ADP_DATA['latest_values'].get(name) for name in series_names if name in ADP_DATA['latest_values']}

# %%
# === ì‹œê°í™” í•¨ìˆ˜ë“¤ ===

def create_adp_timeseries_chart(series_names=None, chart_type='level'):
    """
    ADP ì‹œê³„ì—´ ì°¨íŠ¸ ìƒì„± (KPDS í¬ë§·)
    
    Args:
        series_names: ì°¨íŠ¸ì— í‘œì‹œí•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸
        chart_type: 'level' (ì²œ ëª…), 'mom' (ì „ì›”ëŒ€ë¹„ %), 'mom_change' (ì „ì›”ëŒ€ë¹„ ì²œ ëª…)
        title: ì°¨íŠ¸ ì œëª©
    """
    if not ADP_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_adp_data()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return None
    
    if series_names is None:
        series_names = ['total']
    
    # ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ë° ì œëª© ì„¤ì •
    if chart_type == 'level':
        df = get_raw_data(series_names)
        ytitle = "ê³ ìš©ì ìˆ˜ (ì²œ ëª…)"
        title = "ADP ê³ ìš© - ìˆ˜ì¤€"
    elif chart_type == 'mom':
        df = get_mom_data(series_names)
        ytitle = "ì „ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ (%)"
        title = "ADP ê³ ìš© - ì „ì›”ëŒ€ë¹„ ë³€í™”ìœ¨"
    else:  # mom_change
        df = ADP_DATA['mom_change'][series_names].copy()
        ytitle = "ì „ì›”ëŒ€ë¹„ ë³€í™” (ì²œ ëª…)"
        title = "ADP ê³ ìš© - ì „ì›”ëŒ€ë¹„ ë³€í™”"
    
    print(title)
    
    if df.empty:
        print("âš ï¸ ìš”ì²­í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ì‹œë¦¬ì¦ˆ ê°œìˆ˜ì— ë”°ë¥¸ ì°¨íŠ¸ í•¨ìˆ˜ ì„ íƒ
    if len(df.columns) == 1:
        # ë‹¨ì¼ ì‹œë¦¬ì¦ˆ
        fig = df_line_chart(df, df.columns[0], ytitle=ytitle)
    else:
        # ë‹¤ì¤‘ ì‹œë¦¬ì¦ˆ
        labels = {col: ADP_KOREAN_NAMES.get(col, col) for col in df.columns}
        fig = df_multi_line_chart(df, df.columns.tolist(), ytitle=ytitle, labels=labels)
    
    # 0ì„  ì¶”ê°€ (ë³€í™”ìœ¨/ë³€í™”ëŸ‰ ì°¨íŠ¸ì¸ ê²½ìš°)
    if chart_type in ['mom', 'mom_change']:
        fig.add_hline(y=0, line_width=1, line_color="black", opacity=0.5)
    
    return fig

def create_adp_comparison_chart(comparison_type='size', periods=[1, 3, 6, 12]):
    """
    ADP ë¹„êµ ì°¨íŠ¸ ìƒì„± (KPDS í¬ë§· ê°€ë¡œ ë°” ì°¨íŠ¸)
    
    Args:
        comparison_type: 'size' (ì‚¬ì—… ê·œëª¨ë³„) ë˜ëŠ” 'industry' (ì‚°ì—…ë³„)
        periods: ë¹„êµí•  ê¸°ê°„ë“¤ (ê°œì›” ìˆ˜) [1, 3, 6, 12]
        title: ì°¨íŠ¸ ì œëª©
    """
    if not ADP_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_adp_data()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return None
    
    # ìµœì‹  ë‚ ì§œ
    latest_date = ADP_DATA['raw_data'].index[-1]
    
    # ì‹œë¦¬ì¦ˆ ì„ íƒ ë° ì œëª© ì„¤ì •
    if comparison_type == 'size':
        series_list = list(ADP_SIZE_SERIES.keys())
        title = f"ADP ê³ ìš© ë³€í™” - ì‚¬ì—… ê·œëª¨ë³„ ({latest_date.strftime('%Yë…„ %mì›”')})"
    else:
        series_list = list(ADP_INDUSTRY_SERIES.keys())
        title = f"ADP ê³ ìš© ë³€í™” - ì‚°ì—…ë³„ ({latest_date.strftime('%Yë…„ %mì›”')})"
    
    print(title)
    
    # ì„œë¸Œí”Œë¡¯ ìƒì„±
    fig = make_subplots(
        rows=1, cols=len(periods),
        subplot_titles=[f"vs {p}ê°œì›” ì „" if p == 1 else f"vs {p}ê°œì›” í‰ê· " for p in periods],
        shared_yaxes=True,
        horizontal_spacing=0.05
    )
    
    for i, period in enumerate(periods):
        # ë°ì´í„° ê³„ì‚°
        categories = []
        values = []
        colors = []
        
        for series in series_list:
            if series not in ADP_DATA['raw_data'].columns:
                continue
            
            series_data = ADP_DATA['raw_data'][series]
            latest_value = series_data.iloc[-1]
            
            if period == 1:
                # ì „ì›” ëŒ€ë¹„
                prev_value = series_data.iloc[-2] if len(series_data) > 1 else latest_value
                change = ((latest_value / prev_value) - 1) * 100
            else:
                # Nê°œì›” í‰ê·  ëŒ€ë¹„
                avg_value = series_data.iloc[-(period+1):-1].mean()
                change = ((latest_value / avg_value) - 1) * 100
            
            korean_name = ADP_KOREAN_NAMES.get(series, series)
            categories.append(korean_name)
            values.append(change)
            colors.append(deepred_pds if change >= 0 else deepblue_pds)
        
        # ì •ë ¬
        sorted_data = sorted(zip(categories, values, colors), key=lambda x: x[1])
        categories, values, colors = zip(*sorted_data)
        
        # ë°” ì°¨íŠ¸ ì¶”ê°€
        fig.add_trace(
            go.Bar(
                y=list(categories),
                x=list(values),
                orientation='h',
                marker_color=list(colors),
                text=[f'{v:+.1f}%' for v in values],
                textposition='outside',
                showlegend=False
            ),
            row=1, col=i+1
        )
        
        # xì¶• ë²”ìœ„ ì„¤ì •
        max_val = max(abs(min(values)), max(values)) * 1.2
        fig.update_xaxes(range=[-max_val, max_val], row=1, col=i+1)
        
        # 0ì„  ì¶”ê°€
        fig.add_vline(x=0, line_width=1, line_color="black", row=1, col=i+1)
    
    # KPDS í°íŠ¸ ì„¤ì •
    font_family = 'NanumGothic'
    
    # ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸
    fig.update_layout(
        height=max(400, len(categories) * 40),
        width=1200,
        paper_bgcolor='white',
        plot_bgcolor='white',
        font=dict(family=font_family, size=FONT_SIZE_GENERAL, color="black")
    )
    
    # xì¶• ë¼ë²¨
    for i in range(len(periods)):
        fig.update_xaxes(
            title_text="ë³€í™”ìœ¨ (%)",
            title_font=dict(family=font_family, size=FONT_SIZE_AXIS_TITLE),
            showline=True, linewidth=1.3, linecolor='lightgrey',
            tickwidth=1.3, tickcolor='lightgrey',
            ticks='outside',
            row=1, col=i+1
        )
    
    return fig

def create_adp_heatmap():
    """
    ADP ë³€í™”ìœ¨ íˆíŠ¸ë§µ ìƒì„± (KPDS í¬ë§·)
    
    Returns:
        plotly figure
    """
    if not ADP_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_adp_data()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return None
    
    # ìµœê·¼ 12ê°œì›” ë°ì´í„°
    mom_data = ADP_DATA['mom_data'].tail(12)
    
    # ì¹´í…Œê³ ë¦¬ ì •ë ¬
    size_cols = [col for col in ADP_SIZE_SERIES.keys() if col in mom_data.columns]
    industry_cols = [col for col in ADP_INDUSTRY_SERIES.keys() if col in mom_data.columns]
    
    # ë°ì´í„° ì¤€ë¹„
    all_cols = size_cols + industry_cols
    heatmap_data = mom_data[all_cols].T
    
    # ë¼ë²¨ ë³€í™˜
    y_labels = [ADP_KOREAN_NAMES.get(col, col) for col in all_cols]
    x_labels = [date.strftime('%Y-%m') for date in heatmap_data.columns]
    
    # KPDS í°íŠ¸ ì„¤ì •
    font_family = 'NanumGothic'
    
    # íˆíŠ¸ë§µ ìƒì„±
    fig = go.Figure(data=go.Heatmap(
        z=heatmap_data.values,
        x=x_labels,
        y=y_labels,
        colorscale='RdBu_r',
        zmid=0,
        text=heatmap_data.values,
        texttemplate='%{text:.1f}%',
        textfont={"size": 10, "family": font_family},
        colorbar=dict(title="ì „ì›”ëŒ€ë¹„ %", titlefont=dict(family=font_family, size=FONT_SIZE_AXIS_TITLE))
    ))
    
    # êµ¬ë¶„ì„  ì¶”ê°€
    if size_cols and industry_cols:
        fig.add_shape(
            type="line",
            x0=-0.5, x1=len(x_labels)-0.5,
            y0=len(size_cols)-0.5, y1=len(size_cols)-0.5,
            line=dict(color="black", width=2)
        )
    
    # ì œëª© ì¶œë ¥
    title = "ADP ê³ ìš© - ì›”ë³„ ë³€í™”ìœ¨ íˆíŠ¸ë§µ (%)"
    print(title)
    
    fig.update_layout(
        xaxis=dict(
            title="ì›”",
            title_font=dict(family=font_family, size=FONT_SIZE_AXIS_TITLE),
            side="bottom",
            tickfont=dict(family=font_family, size=FONT_SIZE_GENERAL)
        ),
        yaxis=dict(
            title="ì¹´í…Œê³ ë¦¬",
            title_font=dict(family=font_family, size=FONT_SIZE_AXIS_TITLE),
            tickfont=dict(family=font_family, size=FONT_SIZE_GENERAL)
        ),
        width=1000,
        height=600,
        paper_bgcolor='white',
        plot_bgcolor='white',
        font=dict(family=font_family, size=FONT_SIZE_GENERAL, color="black")
    )
    
    return fig

# %%
# === ë¶„ì„ í•¨ìˆ˜ë“¤ ===

def analyze_adp_trends():
    """
    ADP ê³ ìš© íŠ¸ë Œë“œ ë¶„ì„
    """
    if not ADP_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_adp_data()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return None
    
    latest_date = ADP_DATA['raw_data'].index[-1]
    
    print(f"\nğŸ“Š ADP ê³ ìš© íŠ¸ë Œë“œ ë¶„ì„ ({latest_date.strftime('%Yë…„ %mì›”')})")
    print("="*60)
    
    # 1. ì „ì²´ ê³ ìš© í˜„í™©
    total_employment = ADP_DATA['latest_values']['total']
    print(f"\n1. ì „ì²´ ë¯¼ê°„ ê³ ìš©: {total_employment['value']:,.0f}ì²œëª…")
    print(f"   - ì „ì›”ëŒ€ë¹„: {total_employment['mom_change']:+.0f}ì²œëª… ({total_employment['mom_percent']:+.1f}%)")
    
    # 2. ì‚¬ì—… ê·œëª¨ë³„ ë¶„ì„
    print("\n2. ì‚¬ì—… ê·œëª¨ë³„ ê³ ìš© ë³€í™” (ì „ì›”ëŒ€ë¹„)")
    for size_key in ADP_SIZE_SERIES.keys():
        if size_key == 'total':
            continue
        if size_key in ADP_DATA['latest_values']:
            data = ADP_DATA['latest_values'][size_key]
            name = ADP_KOREAN_NAMES[size_key]
            print(f"   {name}: {data['mom_change']:+.0f}ì²œëª… ({data['mom_percent']:+.1f}%)")
    
    # 3. ì‚°ì—…ë³„ ë¶„ì„
    print("\n3. ì‚°ì—…ë³„ ê³ ìš© ë³€í™” (ì „ì›”ëŒ€ë¹„)")
    industry_changes = []
    for ind_key in ADP_INDUSTRY_SERIES.keys():
        if ind_key in ADP_DATA['latest_values']:
            data = ADP_DATA['latest_values'][ind_key]
            name = ADP_KOREAN_NAMES[ind_key]
            industry_changes.append((name, data['mom_change'], data['mom_percent']))
    
    # ë³€í™”ëŸ‰ ê¸°ì¤€ ì •ë ¬
    industry_changes.sort(key=lambda x: x[1], reverse=True)
    
    print("\n   ìƒìœ„ ì¦ê°€ ì‚°ì—…:")
    for name, change, percent in industry_changes[:3]:
        print(f"   - {name}: {change:+.0f}ì²œëª… ({percent:+.1f}%)")
    
    print("\n   í•˜ìœ„ ì¦ê°€/ê°ì†Œ ì‚°ì—…:")
    for name, change, percent in industry_changes[-3:]:
        print(f"   - {name}: {change:+.0f}ì²œëª… ({percent:+.1f}%)")
    
    # 4. ì¥ê¸° íŠ¸ë Œë“œ
    print("\n4. ì¥ê¸° íŠ¸ë Œë“œ (6ê°œì›” í‰ê·  ëŒ€ë¹„)")
    total_6m_avg = ADP_DATA['raw_data']['total'].iloc[-7:-1].mean()
    total_current = ADP_DATA['raw_data']['total'].iloc[-1]
    total_6m_change = ((total_current / total_6m_avg) - 1) * 100
    
    print(f"   ì „ì²´ ê³ ìš©: {total_6m_change:+.1f}% (6ê°œì›” í‰ê·  ëŒ€ë¹„)")
    
    return {
        'latest_date': latest_date,
        'total_employment': total_employment,
        'industry_changes': industry_changes
    }

# %%
# === í†µí•© ì‹¤í–‰ í•¨ìˆ˜ ===

def run_adp_analysis(start_date='2020-01-01', force_reload=False, smart_update=True):
    """
    ì™„ì „í•œ ADP ë¶„ì„ ì‹¤í–‰ (ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì§€ì›)
    
    Args:
        start_date: ë°ì´í„° ì‹œì‘ ë‚ ì§œ
        force_reload: ê°•ì œ ì¬ë¡œë“œ ì—¬ë¶€
        smart_update: ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
    
    Returns:
        dict: ìƒì„±ëœ ì°¨íŠ¸ë“¤ê³¼ ë¶„ì„ ê²°ê³¼
    """
    print("ğŸš€ ADP Employment ë¶„ì„ ì‹œì‘")
    print("="*50)
    
    # 1. ë°ì´í„° ë¡œë“œ
    print("\n1ï¸âƒ£ ë°ì´í„° ë¡œë”©")
    success = load_all_adp_data(start_date=start_date, force_reload=force_reload, smart_update=smart_update)
    
    if not success:
        print("âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨")
        return None
    
    # 2. ë¶„ì„ ì‹¤í–‰
    print("\n2ï¸âƒ£ íŠ¸ë Œë“œ ë¶„ì„")
    analysis_results = analyze_adp_trends()
    
    # 3. ì‹œê°í™” ìƒì„±
    print("\n3ï¸âƒ£ ì‹œê°í™” ìƒì„±")
    
    results = {
        'analysis': analysis_results,
        'charts': {}
    }
    
    try:
        # ì „ì²´ ê³ ìš© ì‹œê³„ì—´
        print("   ğŸ“ˆ ì „ì²´ ê³ ìš© ì‹œê³„ì—´...")
        results['charts']['total_timeseries'] = create_adp_timeseries_chart(['total'], 'level')
        
        # ì „ì›”ëŒ€ë¹„ ë³€í™” ì‹œê³„ì—´
        print("   ğŸ“Š ì „ì›”ëŒ€ë¹„ ë³€í™” ì‹œê³„ì—´...")
        results['charts']['mom_timeseries'] = create_adp_timeseries_chart(['total'], 'mom_change')
        
        # ì‚¬ì—… ê·œëª¨ë³„ ë¹„êµ
        print("   ğŸ¢ ì‚¬ì—… ê·œëª¨ë³„ ë¹„êµ...")
        results['charts']['size_comparison'] = create_adp_comparison_chart('size', [1, 3, 6, 12])
        
        # ì‚°ì—…ë³„ ë¹„êµ
        print("   ğŸ­ ì‚°ì—…ë³„ ë¹„êµ...")
        results['charts']['industry_comparison'] = create_adp_comparison_chart('industry', [1, 3, 6, 12])
        
        # íˆíŠ¸ë§µ
        print("   ğŸ—ºï¸ ë³€í™”ìœ¨ íˆíŠ¸ë§µ...")
        results['charts']['heatmap'] = create_adp_heatmap()
        
        # ì‚¬ì—… ê·œëª¨ë³„ ì‹œê³„ì—´ (KPDS í¬ë§·)
        print("   ğŸ“ˆ ì‚¬ì—… ê·œëª¨ë³„ ì‹œê³„ì—´...")
        size_series = [k for k in ADP_SIZE_SERIES.keys() if k != 'total']
        results['charts']['size_timeseries'] = create_adp_timeseries_chart(size_series[:3], 'mom')
        
    except Exception as e:
        print(f"âš ï¸ ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
    
    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ! ìƒì„±ëœ ì°¨íŠ¸: {len(results['charts'])}ê°œ")
    
    # ì°¨íŠ¸ í‘œì‹œ
    for chart_name, chart in results['charts'].items():
        if chart is not None:
            print(f"\nğŸ“Š {chart_name} í‘œì‹œ ì¤‘...")
            chart.show()
    
    return results

# %%
# === ì‚¬ìš© ì˜ˆì‹œ ===

print("\n=== ADP Employment ë¶„ì„ ë„êµ¬ ì‚¬ìš©ë²• (KPDS í¬ë§·) ===")
print("1. API í‚¤ ì„¤ì •:")
print("   FRED_API_KEY = 'your_api_key_here'")
print("   # https://fred.stlouisfed.org/docs/api/api_key.html ì—ì„œ ë¬´ë£Œ ë°œê¸‰")
print()
print("2. ë°ì´í„° ë¡œë“œ:")
print("   load_all_adp_data()  # ëª¨ë“  ADP ë°ì´í„° ë¡œë“œ")
print()
print("3. ì‹œê³„ì—´ ì°¨íŠ¸ (KPDS í¬ë§·):")
print("   create_adp_timeseries_chart(['total'], 'level')     # ê³ ìš© ìˆ˜ì¤€")
print("   create_adp_timeseries_chart(['total'], 'mom')       # ì „ì›”ëŒ€ë¹„ %")
print("   create_adp_timeseries_chart(['total'], 'mom_change') # ì „ì›”ëŒ€ë¹„ ì²œëª…")
print()
print("4. ë¹„êµ ì°¨íŠ¸ (KPDS í¬ë§·):")
print("   create_adp_comparison_chart('size', [1, 3, 6, 12])     # ì‚¬ì—… ê·œëª¨ë³„")
print("   create_adp_comparison_chart('industry', [1, 3, 6, 12]) # ì‚°ì—…ë³„")
print()
print("5. íˆíŠ¸ë§µ (KPDS í¬ë§·):")
print("   create_adp_heatmap()  # ì „ì²´ ë³€í™”ìœ¨ íˆíŠ¸ë§µ")
print()
print("6. í†µí•© ë¶„ì„:")
print("   run_adp_analysis()  # ì „ì²´ ë¶„ì„ ë° ì‹œê°í™” (KPDS í¬ë§·)")
print("   run_adp_analysis(smart_update=False)  # ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ë¹„í™œì„±í™”")
print()
print("7. íŠ¸ë Œë“œ ë¶„ì„:")
print("   analyze_adp_trends()  # ìƒì„¸ íŠ¸ë Œë“œ ë¶„ì„")
print()
print("8. ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ê¸°ëŠ¥:")
print("   - ë°ì´í„° ì¼ì¹˜ì„± ìë™ í™•ì¸ (í—ˆìš© ì˜¤ì°¨: 1,000ì²œëª…)")
print("   - CSV ê¸°ë°˜ ë¡œì»¬ ìºì‹±")
print("   - ë¶ˆí•„ìš”í•œ API í˜¸ì¶œ ìµœì†Œí™”")
print()
print("âœ… ëª¨ë“  ì‹œê°í™”ê°€ KPDS í¬ë§·(/home/jyp0615/kpds_fig_format_enhanced.py)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

# %%
# ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œë¦¬ì¦ˆ í‘œì‹œ
def show_available_series():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ADP ì‹œë¦¬ì¦ˆ í‘œì‹œ"""
    print("\n=== ì‚¬ìš© ê°€ëŠ¥í•œ ADP ì‹œë¦¬ì¦ˆ ===")
    
    print("\nğŸ“Š ì‚¬ì—… ê·œëª¨ë³„:")
    for key, series_id in ADP_SIZE_SERIES.items():
        korean_name = ADP_KOREAN_NAMES.get(key, key)
        print(f"  '{key}': {korean_name} ({series_id})")
    
    print("\nğŸ­ ì‚°ì—…ë³„:")
    for key, series_id in ADP_INDUSTRY_SERIES.items():
        korean_name = ADP_KOREAN_NAMES.get(key, key)
        print(f"  '{key}': {korean_name} ({series_id})")

show_available_series()

# %%
# ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ í™œì„±í™”í•˜ì—¬ ë¶„ì„ ì‹¤í–‰
run_adp_analysis(smart_update=True)

# %%
