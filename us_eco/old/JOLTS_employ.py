# %%
"""
BLS API ì „ìš© JOLTS ë¶„ì„ ë° ì‹œê°í™” ë„êµ¬ (KPDS í¬ë§· ì ìš©)
- BLS APIë§Œ ì‚¬ìš©í•˜ì—¬ JOLTS ë°ì´í„° ìˆ˜ì§‘
- CSV ì €ì¥/ë¡œë“œ ë° ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ (PPI ë°©ì‹ ì ìš©)
- ë…¸ë™ì‹œì¥ ë¶„ì„ì„ ìœ„í•œ ì „ë¬¸ ì‹œê°í™” (KPDS í¬ë§·)
- IB/ì´ì½”ë…¸ë¯¸ìŠ¤íŠ¸ ê´€ì ì˜ ë¶„ì„ ê¸°ëŠ¥
"""
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import sys
import warnings
warnings.filterwarnings('ignore')

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    import requests
    import json
    BLS_API_AVAILABLE = True
    print("âœ“ BLS API ì—°ë™ ê°€ëŠ¥ (requests ë¼ì´ë¸ŒëŸ¬ë¦¬)")
except ImportError:
    print("âš ï¸ requests ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜í•˜ì„¸ìš”: pip install requests")
    BLS_API_AVAILABLE = False

# BLS API í‚¤ ì„¤ì •
BLS_API_KEY = '56b193612b614cdc9416359fd1c73a74'
BLS_API_KEY2 = '0450ef37363c48b5bedd2ae6fc92dd6e'
BLS_API_KEY3 = 'daf1ca7970b74e81b6a5c7a80a8b8a7f'
CURRENT_API_KEY = BLS_API_KEY3

# ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
sys.path.append('/home/jyp0615')
from kpds_fig_format_enhanced import *

# í•œê¸€ í°íŠ¸ ì„¤ì •
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
plt.rcParams['font.family'] = 'NanumGothic'
plt.rcParams['axes.unicode_minus'] = False

# %%
# === JOLTS ì‹œë¦¬ì¦ˆ IDì™€ ì´ë¦„ ë§¤í•‘ ===

# JOLTS ì‹œë¦¬ì¦ˆ IDì™€ ì˜ì–´ ì´ë¦„ ë§¤í•‘
JOLTS_SERIES = {
    # Total nonfarm
    'JTS000000000000000HIL': 'Total nonfarm - Hires',
    'JTS000000000000000JOL': 'Total nonfarm - Job openings',
    'JTS000000000000000LDL': 'Total nonfarm - Layoffs and discharges',
    
    # Total private
    'JTS100000000000000HIL': 'Total private - Hires',
    'JTS100000000000000JOL': 'Total private - Job openings',
    'JTS100000000000000LDL': 'Total private - Layoffs and discharges',
    
    # Mining and logging
    'JTS110099000000000HIL': 'Mining and logging - Hires',
    'JTS110099000000000JOL': 'Mining and logging - Job openings',
    'JTS110099000000000LDL': 'Mining and logging - Layoffs and discharges',
    
    # Construction
    'JTS230000000000000HIL': 'Construction - Hires',
    'JTS230000000000000JOL': 'Construction - Job openings',
    'JTS230000000000000LDL': 'Construction - Layoffs and discharges',
    
    # Manufacturing
    'JTS300000000000000HIL': 'Manufacturing - Hires',
    'JTS300000000000000JOL': 'Manufacturing - Job openings',
    'JTS300000000000000LDL': 'Manufacturing - Layoffs and discharges',
    
    # Trade, transportation, and utilities
    'JTS400000000000000HIL': 'Trade, transportation, and utilities - Hires',
    'JTS400000000000000JOL': 'Trade, transportation, and utilities - Job openings',
    'JTS400000000000000LDL': 'Trade, transportation, and utilities - Layoffs and discharges',
    
    # Information
    'JTS510000000000000HIL': 'Information - Hires',
    'JTS510000000000000JOL': 'Information - Job openings',
    'JTS510000000000000LDL': 'Information - Layoffs and discharges',
    
    # Financial activities
    'JTS510099000000000HIL': 'Financial activities - Hires',
    'JTS510099000000000JOL': 'Financial activities - Job openings',
    'JTS510099000000000LDL': 'Financial activities - Layoffs and discharges',
    
    # Professional and business services
    'JTS540099000000000HIL': 'Professional and business services - Hires',
    'JTS540099000000000JOL': 'Professional and business services - Job openings',
    'JTS540099000000000LDL': 'Professional and business services - Layoffs and discharges',
    
    # Private education and health services
    'JTS600000000000000HIL': 'Private education and health services - Hires',
    'JTS600000000000000JOL': 'Private education and health services - Job openings',
    'JTS600000000000000LDL': 'Private education and health services - Layoffs and discharges',
    
    # Leisure and hospitality
    'JTS700000000000000HIL': 'Leisure and hospitality - Hires',
    'JTS700000000000000JOL': 'Leisure and hospitality - Job openings',
    'JTS700000000000000LDL': 'Leisure and hospitality - Layoffs and discharges',
    
    # Other services
    'JTS810000000000000HIL': 'Other services - Hires',
    'JTS810000000000000JOL': 'Other services - Job openings',
    'JTS810000000000000LDL': 'Other services - Layoffs and discharges',
    
    # Government
    'JTS900000000000000HIL': 'Government - Hires',
    'JTS900000000000000JOL': 'Government - Job openings',
    'JTS900000000000000LDL': 'Government - Layoffs and discharges'
}

# í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘
JOLTS_KOREAN_NAMES = {
    # Total nonfarm
    'JTS000000000000000HIL': 'ì „ì²´ ë¹„ë†ì—… - ì±„ìš©',
    'JTS000000000000000JOL': 'ì „ì²´ ë¹„ë†ì—… - êµ¬ì¸',
    'JTS000000000000000LDL': 'ì „ì²´ ë¹„ë†ì—… - í•´ê³  ë° í‡´ì§',
    
    # Total private
    'JTS100000000000000HIL': 'ì „ì²´ ë¯¼ê°„ - ì±„ìš©',
    'JTS100000000000000JOL': 'ì „ì²´ ë¯¼ê°„ - êµ¬ì¸',
    'JTS100000000000000LDL': 'ì „ì²´ ë¯¼ê°„ - í•´ê³  ë° í‡´ì§',
    
    # Sectors
    'JTS110099000000000HIL': 'ê´‘ì—… ë° ë²Œëª©ì—… - ì±„ìš©',
    'JTS110099000000000JOL': 'ê´‘ì—… ë° ë²Œëª©ì—… - êµ¬ì¸',
    'JTS110099000000000LDL': 'ê´‘ì—… ë° ë²Œëª©ì—… - í•´ê³  ë° í‡´ì§',
    
    'JTS230000000000000HIL': 'ê±´ì„¤ì—… - ì±„ìš©',
    'JTS230000000000000JOL': 'ê±´ì„¤ì—… - êµ¬ì¸',
    'JTS230000000000000LDL': 'ê±´ì„¤ì—… - í•´ê³  ë° í‡´ì§',
    
    'JTS300000000000000HIL': 'ì œì¡°ì—… - ì±„ìš©',
    'JTS300000000000000JOL': 'ì œì¡°ì—… - êµ¬ì¸',
    'JTS300000000000000LDL': 'ì œì¡°ì—… - í•´ê³  ë° í‡´ì§',
    
    'JTS400000000000000HIL': 'ë¬´ì—­/ìš´ì†¡/ìœ í‹¸ë¦¬í‹° - ì±„ìš©',
    'JTS400000000000000JOL': 'ë¬´ì—­/ìš´ì†¡/ìœ í‹¸ë¦¬í‹° - êµ¬ì¸',
    'JTS400000000000000LDL': 'ë¬´ì—­/ìš´ì†¡/ìœ í‹¸ë¦¬í‹° - í•´ê³  ë° í‡´ì§',
    
    'JTS510000000000000HIL': 'ì •ë³´ì‚°ì—… - ì±„ìš©',
    'JTS510000000000000JOL': 'ì •ë³´ì‚°ì—… - êµ¬ì¸',
    'JTS510000000000000LDL': 'ì •ë³´ì‚°ì—… - í•´ê³  ë° í‡´ì§',
    
    'JTS510099000000000HIL': 'ê¸ˆìœµì—… - ì±„ìš©',
    'JTS510099000000000JOL': 'ê¸ˆìœµì—… - êµ¬ì¸',
    'JTS510099000000000LDL': 'ê¸ˆìœµì—… - í•´ê³  ë° í‡´ì§',
    
    'JTS540099000000000HIL': 'ì „ë¬¸/ë¹„ì¦ˆë‹ˆìŠ¤ ì„œë¹„ìŠ¤ - ì±„ìš©',
    'JTS540099000000000JOL': 'ì „ë¬¸/ë¹„ì¦ˆë‹ˆìŠ¤ ì„œë¹„ìŠ¤ - êµ¬ì¸',
    'JTS540099000000000LDL': 'ì „ë¬¸/ë¹„ì¦ˆë‹ˆìŠ¤ ì„œë¹„ìŠ¤ - í•´ê³  ë° í‡´ì§',
    
    'JTS600000000000000HIL': 'êµìœ¡/ì˜ë£Œ ì„œë¹„ìŠ¤(ë¯¼ê°„) - ì±„ìš©',
    'JTS600000000000000JOL': 'êµìœ¡/ì˜ë£Œ ì„œë¹„ìŠ¤(ë¯¼ê°„) - êµ¬ì¸',
    'JTS600000000000000LDL': 'êµìœ¡/ì˜ë£Œ ì„œë¹„ìŠ¤(ë¯¼ê°„) - í•´ê³  ë° í‡´ì§',
    
    'JTS700000000000000HIL': 'ë ˆì €/ìˆ™ë°•ì—… - ì±„ìš©',
    'JTS700000000000000JOL': 'ë ˆì €/ìˆ™ë°•ì—… - êµ¬ì¸',
    'JTS700000000000000LDL': 'ë ˆì €/ìˆ™ë°•ì—… - í•´ê³  ë° í‡´ì§',
    
    'JTS810000000000000HIL': 'ê¸°íƒ€ ì„œë¹„ìŠ¤ - ì±„ìš©',
    'JTS810000000000000JOL': 'ê¸°íƒ€ ì„œë¹„ìŠ¤ - êµ¬ì¸',
    'JTS810000000000000LDL': 'ê¸°íƒ€ ì„œë¹„ìŠ¤ - í•´ê³  ë° í‡´ì§',
    
    'JTS900000000000000HIL': 'ì •ë¶€ - ì±„ìš©',
    'JTS900000000000000JOL': 'ì •ë¶€ - êµ¬ì¸',
    'JTS900000000000000LDL': 'ì •ë¶€ - í•´ê³  ë° í‡´ì§'
}

# JOLTS ê³„ì¸µ êµ¬ì¡°
JOLTS_HIERARCHY = {
    'ì´ê³„': {
        'Total': ['JTS000000000000000HIL', 'JTS000000000000000JOL', 'JTS000000000000000LDL'],
        'Private': ['JTS100000000000000HIL', 'JTS100000000000000JOL', 'JTS100000000000000LDL'],
        'Government': ['JTS900000000000000HIL', 'JTS900000000000000JOL', 'JTS900000000000000LDL']
    },
    'ì‚°ì—…ë³„': {
        'Goods': ['JTS110099000000000JOL', 'JTS230000000000000JOL', 'JTS300000000000000JOL'],
        'Services': ['JTS400000000000000JOL', 'JTS510000000000000JOL', 'JTS510099000000000JOL', 
                    'JTS540099000000000JOL', 'JTS600000000000000JOL', 'JTS700000000000000JOL', 
                    'JTS810000000000000JOL'],
        'Tech & Finance': ['JTS510000000000000JOL', 'JTS510099000000000JOL', 'JTS540099000000000JOL']
    },
    'ì§€í‘œë³„': {
        'Job Openings': ['JTS000000000000000JOL', 'JTS100000000000000JOL', 'JTS900000000000000JOL'],
        'Hires': ['JTS000000000000000HIL', 'JTS100000000000000HIL', 'JTS900000000000000HIL'],
        'Layoffs': ['JTS000000000000000LDL', 'JTS100000000000000LDL', 'JTS900000000000000LDL']
    }
}

# %%
# === ì „ì—­ ë°ì´í„° ì €ì¥ì†Œ ===

# API ì„¤ì •
BLS_SESSION = None
API_INITIALIZED = False

# ì „ì—­ ë°ì´í„° ì €ì¥ì†Œ
JOLTS_DATA = {
    'raw_data': pd.DataFrame(),      # ì›ë³¸ ë ˆë²¨ ë°ì´í„°
    'yoy_data': pd.DataFrame(),      # ì „ë…„ë™ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ë°ì´í„°
    'mom_data': pd.DataFrame(),      # ì „ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ë°ì´í„°
    'rates_data': pd.DataFrame(),    # ë¹„ìœ¨ ë°ì´í„° (êµ¬ì¸ë¥ , ì±„ìš©ë¥  ë“±)
    'latest_values': {},             # ìµœì‹  ê°’ë“¤
    'load_info': {
        'loaded': False,
        'load_time': None,
        'start_date': None,
        'series_count': 0,
        'data_points': 0
    }
}

# %%
# === API ì´ˆê¸°í™” í•¨ìˆ˜ ===

def initialize_bls_api():
    """BLS API ì„¸ì…˜ ì´ˆê¸°í™”"""
    global BLS_SESSION
    
    if not BLS_API_AVAILABLE:
        print("âš ï¸ BLS API ì‚¬ìš© ë¶ˆê°€ (requests ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ)")
        return False
    
    try:
        BLS_SESSION = requests.Session()
        print("âœ“ BLS API ì„¸ì…˜ ì´ˆê¸°í™” ì„±ê³µ")
        return True
    except Exception as e:
        print(f"âš ï¸ BLS API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def switch_api_key():
    """API í‚¤ë¥¼ ì „í™˜í•˜ëŠ” í•¨ìˆ˜"""
    global CURRENT_API_KEY
    if CURRENT_API_KEY == BLS_API_KEY:
        CURRENT_API_KEY = BLS_API_KEY2
        print("ğŸ”„ BLS API í‚¤ë¥¼ BLS_API_KEY2ë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.")
    elif CURRENT_API_KEY == BLS_API_KEY2:
        CURRENT_API_KEY = BLS_API_KEY3
        print("ğŸ”„ BLS API í‚¤ë¥¼ BLS_API_KEY3ë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.")
    else:
        CURRENT_API_KEY = BLS_API_KEY
        print("ğŸ”„ BLS API í‚¤ë¥¼ BLS_API_KEYë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.")

def get_bls_data(series_id, start_year=2020, end_year=None):
    """
    BLS APIì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (API í‚¤ ì´ì¤‘í™” ì§€ì›)
    
    Args:
        series_id: BLS ì‹œë¦¬ì¦ˆ ID
        start_year: ì‹œì‘ ì—°ë„
        end_year: ì¢…ë£Œ ì—°ë„ (Noneì´ë©´ í˜„ì¬ ì—°ë„)
    
    Returns:
        pandas.Series: ë‚ ì§œë¥¼ ì¸ë±ìŠ¤ë¡œ í•˜ëŠ” ì‹œë¦¬ì¦ˆ ë°ì´í„°
    """
    global CURRENT_API_KEY
    
    if not BLS_API_AVAILABLE or BLS_SESSION is None:
        print(f"âŒ BLS API ì‚¬ìš© ë¶ˆê°€ - {series_id}")
        return None
    
    if end_year is None:
        end_year = datetime.datetime.now().year
    
    # BLS API ìš”ì²­ ë°ì´í„°
    data = {
        'seriesid': [series_id],
        'startyear': str(start_year),
        'endyear': str(end_year),
        'catalog': False,
        'calculations': False,
        'annualaverage': False
    }
    
    # í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ API í‚¤ ì¶”ê°€
    if CURRENT_API_KEY:
        data['registrationkey'] = CURRENT_API_KEY
    
    url = 'https://api.bls.gov/publicAPI/v2/timeseries/data/'
    headers = {'Content-type': 'application/json'}
    
    try:
        current_key_name = "ì£¼ìš”" if CURRENT_API_KEY == BLS_API_KEY else "ë°±ì—…"
        print(f"ğŸ“Š BLSì—ì„œ ë¡œë”© ({current_key_name}): {series_id}")
        response = BLS_SESSION.post(url, data=json.dumps(data), headers=headers, timeout=30)
        response.raise_for_status()
        
        json_data = response.json()
        
        if json_data.get('status') == 'REQUEST_SUCCEEDED':
            series_data = json_data['Results']['series'][0]['data']
            
            # ë°ì´í„° ì •ë¦¬
            dates = []
            values = []
            
            for item in series_data:
                try:
                    year = int(item['year'])
                    period = item['period']
                    if period.startswith('M'):
                        month = int(period[1:])
                        date = pd.Timestamp(year, month, 1)
                        value = float(item['value'])
                        
                        dates.append(date)
                        values.append(value)
                except (ValueError, KeyError):
                    continue
            
            if dates and values:
                # ë‚ ì§œìˆœ ì •ë ¬
                df = pd.DataFrame({'date': dates, 'value': values})
                df = df.sort_values('date')
                series = pd.Series(df['value'].values, index=df['date'], name=series_id)
                
                print(f"âœ“ BLS ì„±ê³µ: {series_id} ({len(series)}ê°œ í¬ì¸íŠ¸)")
                return series
            else:
                print(f"âŒ BLS ë°ì´í„° ì—†ìŒ: {series_id}")
                return None
        else:
            error_msg = json_data.get('message', 'Unknown error')
            print(f"âš ï¸ BLS API ì˜¤ë¥˜: {error_msg}")
            
            # Daily threshold ì´ˆê³¼ì¸ ê²½ìš° API í‚¤ ì „í™˜ ì‹œë„
            if 'daily threshold' in error_msg.lower() or 'daily quota' in error_msg.lower():
                print("ğŸ“ˆ Daily threshold ì´ˆê³¼ ê°ì§€ - API í‚¤ ì „í™˜ ì‹œë„")
                switch_api_key()
                
                # ìƒˆë¡œìš´ API í‚¤ë¡œ ì¬ì‹œë„
                data['registrationkey'] = CURRENT_API_KEY
                try:
                    print(f"ğŸ”„ ìƒˆ API í‚¤ë¡œ ì¬ì‹œë„: {series_id}")
                    response = BLS_SESSION.post(url, data=json.dumps(data), headers=headers, timeout=30)
                    response.raise_for_status()
                    
                    json_data = response.json()
                    if json_data.get('status') == 'REQUEST_SUCCEEDED':
                        series_data = json_data['Results']['series'][0]['data']
                        
                        dates = []
                        values = []
                        
                        for item in series_data:
                            try:
                                year = int(item['year'])
                                period = item['period']
                                if period.startswith('M'):
                                    month = int(period[1:])
                                    date = pd.Timestamp(year, month, 1)
                                    value = float(item['value'])
                                    
                                    dates.append(date)
                                    values.append(value)
                            except (ValueError, KeyError):
                                continue
                        
                        if dates and values:
                            df = pd.DataFrame({'date': dates, 'value': values})
                            df = df.sort_values('date')
                            series = pd.Series(df['value'].values, index=df['date'], name=series_id)
                            
                            print(f"âœ… ë°±ì—… API í‚¤ë¡œ ì„±ê³µ: {series_id} ({len(series)}ê°œ í¬ì¸íŠ¸)")
                            return series
                    
                    print(f"âŒ ë°±ì—… API í‚¤ë¡œë„ ì‹¤íŒ¨: {series_id}")
                    return None
                except Exception as e:
                    print(f"âŒ ë°±ì—… API í‚¤ ìš”ì²­ ì‹¤íŒ¨: {series_id} - {e}")
                    return None
            else:
                return None
            
    except Exception as e:
        print(f"âŒ BLS ìš”ì²­ ì‹¤íŒ¨: {series_id} - {e}")
        return None

# %%
# === ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ===

def calculate_yoy_change(data):
    """ì „ë…„ë™ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ê³„ì‚°"""
    return ((data / data.shift(12)) - 1) * 100

def calculate_mom_change(data):
    """ì „ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ê³„ì‚°"""
    return ((data / data.shift(1)) - 1) * 100

def calculate_3m_avg(data):
    """3ê°œì›” ì´ë™í‰ê·  ê³„ì‚°"""
    return data.rolling(window=3).mean()

def calculate_6m_avg(data):
    """6ê°œì›” ì´ë™í‰ê·  ê³„ì‚°"""
    return data.rolling(window=6).mean()

# %%
# === ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ í•¨ìˆ˜ (PPI ë°©ì‹ ì ìš©) ===

def check_recent_data_consistency(series_list=None, check_count=3):
    """
    ìµœê·¼ Nê°œ ë°ì´í„°ì˜ ì¼ì¹˜ì„±ì„ í™•ì¸í•˜ëŠ” í•¨ìˆ˜ (ê°œì„ ëœ ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸)
    
    Args:
        series_list: í™•ì¸í•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ì£¼ìš” ì‹œë¦¬ì¦ˆë§Œ)
        check_count: í™•ì¸í•  ìµœê·¼ ë°ì´í„° ê°œìˆ˜
    
    Returns:
        dict: ì¼ì¹˜ì„± í™•ì¸ ê²°ê³¼ (need_update, reason, mismatches)
    """
    if not JOLTS_DATA['load_info']['loaded']:
        return {'need_update': True, 'reason': 'ê¸°ì¡´ ë°ì´í„° ì—†ìŒ'}
    
    if series_list is None:
        # ì£¼ìš” ì‹œë¦¬ì¦ˆë§Œ ì²´í¬ (ì†ë„ í–¥ìƒ)
        series_list = ['JTS000000000000000JOL', 'JTS000000000000000HIL', 'JTS000000000000000LDL']
    
    # BLS API ì´ˆê¸°í™”
    if not initialize_bls_api():
        return {'need_update': True, 'reason': 'API ì´ˆê¸°í™” ì‹¤íŒ¨'}
    
    print(f"ğŸ“Š ìµœê·¼ {check_count}ê°œ ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸ ì¤‘...")
    
    mismatches = []
    new_data_available = False
    all_data_identical = True
    
    for series_id in series_list:
        if series_id not in JOLTS_DATA['raw_data'].columns:
            continue
        
        existing_data = JOLTS_DATA['raw_data'][series_id].dropna()
        if len(existing_data) == 0:
            continue
        
        # ìµœê·¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        current_year = datetime.datetime.now().year
        api_data = get_bls_data(series_id, current_year - 1, current_year)
        
        if api_data is None or len(api_data) == 0:
            mismatches.append({
                'series': series_id,
                'reason': 'API ë°ì´í„° ì—†ìŒ'
            })
            all_data_identical = False
            continue
        
        # ë¨¼ì € ìƒˆë¡œìš´ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        latest_existing = existing_data.index[-1]
        latest_api = api_data.index[-1]
        
        if latest_api > latest_existing:
            new_data_available = True
            mismatches.append({
                'series': series_id,
                'reason': 'ìƒˆë¡œìš´ ë°ì´í„° ì¡´ì¬',
                'existing_latest': latest_existing,
                'api_latest': latest_api
            })
            all_data_identical = False
            continue  # ìƒˆ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë‹¤ë¥¸ ì²´í¬ëŠ” ê±´ë„ˆëœ€
        
        # ìµœê·¼ Nê°œ ë°ì´í„° ë¹„êµ (ìƒˆ ë°ì´í„°ê°€ ì—†ì„ ë•Œë§Œ)
        existing_recent = existing_data.tail(check_count)
        api_recent = api_data.tail(check_count)
        
        # ë‚ ì§œì™€ ê°’ ëª¨ë‘ ë¹„êµ
        for date in existing_recent.index[-check_count:]:
            if date in api_recent.index:
                existing_val = existing_recent.loc[date]
                api_val = api_recent.loc[date]
                
                # ê°’ì´ ë‹¤ë¥´ë©´ ë¶ˆì¼ì¹˜ (1000.0 ì´ìƒ ì°¨ì´ - JOLTS ê³ ìš© ë°ì´í„° íŠ¹ì„± ê³ ë ¤, ì²œëª… ë‹¨ìœ„)
                if abs(existing_val - api_val) > 1000.0:
                    mismatches.append({
                        'series': series_id,
                        'date': date,
                        'existing': existing_val,
                        'api': api_val,
                        'diff': abs(existing_val - api_val)
                    })
                    all_data_identical = False
            else:
                mismatches.append({
                    'series': series_id,
                    'date': date,
                    'existing': existing_recent.loc[date],
                    'api': None,
                    'reason': 'ë‚ ì§œ ì—†ìŒ'
                })
                all_data_identical = False
    
    # ê²°ê³¼ íŒì • ë¡œì§ ê°œì„ 
    if new_data_available:
        print(f"ğŸ†• ìƒˆë¡œìš´ ë°ì´í„° ê°ì§€: ì—…ë°ì´íŠ¸ í•„ìš”")
        for mismatch in mismatches[:3]:
            if 'reason' in mismatch and mismatch['reason'] == 'ìƒˆë¡œìš´ ë°ì´í„° ì¡´ì¬':
                print(f"   - {mismatch['series']}: {mismatch['existing_latest']} â†’ {mismatch['api_latest']}")
        return {'need_update': True, 'reason': 'ìƒˆë¡œìš´ ë°ì´í„°', 'mismatches': mismatches}
    elif not all_data_identical:
        # ê°’ ë¶ˆì¼ì¹˜ê°€ ìˆëŠ” ê²½ìš°
        value_mismatches = [m for m in mismatches if m.get('reason') != 'ìƒˆë¡œìš´ ë°ì´í„° ì¡´ì¬']
        print(f"âš ï¸ ë°ì´í„° ë¶ˆì¼ì¹˜ ë°œê²¬: {len(value_mismatches)}ê°œ")
        
        # ë””ë²„ê¹…: ì‹¤ì œ ë¶ˆì¼ì¹˜ ë‚´ìš© ì¶œë ¥
        print("ğŸ” ë¶ˆì¼ì¹˜ ì„¸ë¶€ ë‚´ìš© (ìµœëŒ€ 3ê°œ):")
        for i, mismatch in enumerate(value_mismatches[:3]):
            if 'existing' in mismatch and 'api' in mismatch:
                print(f"   {i+1}. {mismatch.get('series', 'unknown')} ({mismatch.get('date', 'unknown')}): CSV={mismatch['existing']:.1f}, API={mismatch['api']:.1f}, ì°¨ì´={mismatch['diff']:.1f}")
            else:
                print(f"   {i+1}. {mismatch}")
        
        # JOLTS íŠ¹í™”: 1000.0 ì´ìƒë§Œ ì‹¤ì œ ë¶ˆì¼ì¹˜ë¡œ ê°„ì£¼ (ì²œëª… ë‹¨ìœ„)
        significant_mismatches = [m for m in value_mismatches if m.get('diff', 0) > 1000.0]
        if len(significant_mismatches) == 0:
            print("ğŸ“ ëª¨ë“  ì°¨ì´ê°€ 1000.0 ë¯¸ë§Œì…ë‹ˆë‹¤. ì €ì¥ ì •ë°€ë„ ì°¨ì´ë¡œ ê°„ì£¼í•˜ì—¬ ì—…ë°ì´íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return {'need_update': False, 'reason': 'ë¯¸ì„¸í•œ ì •ë°€ë„ ì°¨ì´', 'mismatches': mismatches}
        else:
            print(f"ğŸš¨ ìœ ì˜ë¯¸í•œ ì°¨ì´ ë°œê²¬: {len(significant_mismatches)}ê°œ (1000.0 ì´ìƒ)")
            return {'need_update': True, 'reason': 'ë°ì´í„° ë¶ˆì¼ì¹˜', 'mismatches': mismatches}
    else:
        print("âœ… ìµœê·¼ ë°ì´í„°ê°€ ì™„ì „íˆ ì¼ì¹˜í•©ë‹ˆë‹¤. ì—…ë°ì´íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return {'need_update': False, 'reason': 'ë°ì´í„° ì¼ì¹˜', 'mismatches': []}

def update_jolts_data_from_api(start_date=None, series_list=None, smart_update=True):
    """
    APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸ (ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì§€ì›)
    
    Args:
        start_date: ì—…ë°ì´íŠ¸ ì‹œì‘ ë‚ ì§œ (Noneì´ë©´ ë§ˆì§€ë§‰ ë°ì´í„° ì´í›„ë¶€í„°)
        series_list: ì—…ë°ì´íŠ¸í•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  ì‹œë¦¬ì¦ˆ)
        smart_update: ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì‚¬ìš© ì—¬ë¶€ (ìµœê·¼ 3ê°œ ë°ì´í„° ë¹„êµ)
    
    Returns:
        bool: ì—…ë°ì´íŠ¸ ì„±ê³µ ì—¬ë¶€
    """
    global JOLTS_DATA
    
    if not JOLTS_DATA['load_info']['loaded']:
        print("âš ï¸ ê¸°ì¡´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ë¡œë“œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
        return load_all_jolts_data()
    
    # ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ í™œì„±í™”ì‹œ ìµœê·¼ ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸
    if smart_update:
        consistency_check = check_recent_data_consistency()
        
        # ì—…ë°ì´íŠ¸ í•„ìš” ì—†ìœ¼ë©´ ë°”ë¡œ ì¢…ë£Œ
        if not consistency_check['need_update']:
            print("ğŸ¯ ë°ì´í„°ê°€ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤. API í˜¸ì¶œì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return True
        
        # ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•œ ê²½ìš° ì²˜ë¦¬
        if consistency_check['reason'] == 'ë°ì´í„° ë¶ˆì¼ì¹˜':
            print("âš ï¸ ìµœê·¼ 3ê°œ ë°ì´í„° ë¶ˆì¼ì¹˜ë¡œ ì¸í•œ ì „ì²´ ì¬ë¡œë“œ")
            # ìµœê·¼ 3ê°œì›” ë°ì´í„°ë¶€í„° ë‹¤ì‹œ ë¡œë“œ
            last_date = JOLTS_DATA['raw_data'].index[-1]
            start_date = (last_date - pd.DateOffset(months=3)).strftime('%Y-%m-01')
        elif consistency_check['reason'] == 'ê¸°ì¡´ ë°ì´í„° ì—†ìŒ':
            # ì „ì²´ ì¬ë¡œë“œ
            return load_all_jolts_data(force_reload=True)
        else:
            print(f"ğŸ”„ ì—…ë°ì´íŠ¸ ì§„í–‰: {consistency_check['reason']}")
    
    # BLS API ì´ˆê¸°í™”
    if not initialize_bls_api():
        print("âŒ BLS API ì´ˆê¸°í™” ì‹¤íŒ¨")
        return False
    
    # ì—…ë°ì´íŠ¸ ì‹œì‘ ë‚ ì§œ ê²°ì •
    if start_date is None:
        last_date = JOLTS_DATA['raw_data'].index[-1]
        # ë§ˆì§€ë§‰ ë‚ ì§œì˜ ë‹¤ìŒ ë‹¬ë¶€í„° ì—…ë°ì´íŠ¸
        start_date = (last_date + pd.DateOffset(months=1)).strftime('%Y-%m-01')
    
    print(f"ğŸ”„ JOLTS ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ ({start_date}ë¶€í„°)")
    print("="*50)
    
    if series_list is None:
        series_list = list(JOLTS_SERIES.keys())
    
    updated_data = {}
    new_count = 0
    
    for series_id in series_list:
        if series_id not in JOLTS_SERIES:
            continue
        
        # ìƒˆë¡œìš´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        start_year = pd.to_datetime(start_date).year
        new_data = get_bls_data(series_id, start_year)
        
        if new_data is not None and len(new_data) > 0:
            # ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©
            if series_id in JOLTS_DATA['raw_data'].columns:
                existing_data = JOLTS_DATA['raw_data'][series_id]
                original_count = existing_data.notna().sum()
                
                # ê°œì„ ëœ ë³‘í•© ë°©ì‹: ì¸ë±ìŠ¤ ë¨¼ì € í™•ì¥ í›„ ê°’ í• ë‹¹
                all_dates = existing_data.index.union(new_data.index).sort_values()
                combined_data = existing_data.reindex(all_dates)
                
                # ìƒˆ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ê°’ ë®ì–´ì“°ê¸°)
                for date, value in new_data.items():
                    combined_data.loc[date] = value
                
                updated_data[series_id] = combined_data
                
                # ì‹¤ì œ ì¶”ê°€ëœ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ ê³„ì‚°
                final_count = combined_data.notna().sum()
                new_points = final_count - original_count
                new_count += new_points
                
                if new_points > 0:
                    print(f"âœ… ì—…ë°ì´íŠ¸: {series_id} (ê¸°ì¡´ {original_count}ê°œ + ì‹ ê·œ {len(new_data)}ê°œ â†’ ì´ {final_count}ê°œ, ì‹¤ì œ ì¶”ê°€: {new_points}ê°œ)")
                else:
                    print(f"â„¹ï¸  ìµœì‹  ìƒíƒœ: {series_id}")
            else:
                updated_data[series_id] = new_data
                new_count += len(new_data)
                print(f"âœ… ì‹ ê·œ ì¶”ê°€: {series_id} ({len(new_data)}ê°œ í¬ì¸íŠ¸)")
    
    if updated_data:
        # ì „ì—­ ì €ì¥ì†Œ ì—…ë°ì´íŠ¸
        updated_df = pd.DataFrame(updated_data)
        JOLTS_DATA['raw_data'] = updated_df
        JOLTS_DATA['yoy_data'] = updated_df.apply(calculate_yoy_change)
        JOLTS_DATA['mom_data'] = updated_df.apply(calculate_mom_change)
        
        # ìµœì‹  ê°’ ì—…ë°ì´íŠ¸
        for series_id in updated_data.keys():
            if series_id in JOLTS_DATA['raw_data'].columns:
                raw_data = JOLTS_DATA['raw_data'][series_id].dropna()
                if len(raw_data) > 0:
                    JOLTS_DATA['latest_values'][series_id] = raw_data.iloc[-1]
        
        # ë¡œë“œ ì •ë³´ ì—…ë°ì´íŠ¸
        JOLTS_DATA['load_info']['load_time'] = datetime.datetime.now()
        JOLTS_DATA['load_info']['series_count'] = len(updated_df.columns)
        JOLTS_DATA['load_info']['data_points'] = len(updated_df)
        
        print(f"\nâœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ! ìƒˆë¡œ ì¶”ê°€ëœ ë°ì´í„°: {new_count}ê°œ í¬ì¸íŠ¸")
        print_load_info()
        
        # ìë™ìœ¼ë¡œ CSVì— ì €ì¥
        save_jolts_data_to_csv()
        
        return True
    else:
        print("\nâš ï¸ ì—…ë°ì´íŠ¸í•  ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False

# %%
# === CSV ì €ì¥/ë¡œë“œ í•¨ìˆ˜ë“¤ ===

def save_jolts_data_to_csv(file_path='/home/jyp0615/us_eco/jolts_data.csv'):
    """
    í˜„ì¬ ë¡œë“œëœ JOLTS ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
    
    Args:
        file_path: ì €ì¥í•  CSV íŒŒì¼ ê²½ë¡œ
    """
    if not JOLTS_DATA['load_info']['loaded']:
        print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return False
    
    try:
        # raw_dataì™€ ë©”íƒ€ë°ì´í„°ë¥¼ í•¨ê»˜ ì €ì¥
        raw_data = JOLTS_DATA['raw_data']
        
        # ì €ì¥í•  ë°ì´í„° ì¤€ë¹„
        save_data = {
            'timestamp': raw_data.index.tolist(),
            **{col: raw_data[col].tolist() for col in raw_data.columns}
        }
        
        # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
        save_df = pd.DataFrame(save_data)
        save_df.to_csv(file_path, index=False, encoding='utf-8')
        
        # ë©”íƒ€ë°ì´í„°ë„ ë³„ë„ ì €ì¥
        meta_file = file_path.replace('.csv', '_meta.json')
        import json
        with open(meta_file, 'w', encoding='utf-8') as f:
            meta_data = {
                'load_time': JOLTS_DATA['load_info']['load_time'].isoformat() if JOLTS_DATA['load_info']['load_time'] else None,
                'start_date': JOLTS_DATA['load_info']['start_date'],
                'series_count': JOLTS_DATA['load_info']['series_count'],
                'data_points': JOLTS_DATA['load_info']['data_points'],
                'latest_values': JOLTS_DATA['latest_values']
            }
            json.dump(meta_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… JOLTS ë°ì´í„° ì €ì¥ ì™„ë£Œ: {file_path}")
        print(f"âœ… ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {meta_file}")
        return True
        
    except Exception as e:
        print(f"âŒ CSV ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def load_jolts_data_from_csv(file_path='/home/jyp0615/us_eco/jolts_data.csv'):
    """
    CSV íŒŒì¼ì—ì„œ JOLTS ë°ì´í„° ë¡œë“œ
    
    Args:
        file_path: ë¡œë“œí•  CSV íŒŒì¼ ê²½ë¡œ
    
    Returns:
        bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
    """
    global JOLTS_DATA
    
    import os
    if not os.path.exists(file_path):
        print(f"âš ï¸ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return False
    
    try:
        # CSV ë°ì´í„° ë¡œë“œ
        df = pd.read_csv(file_path, encoding='utf-8')
        
        # timestamp ì»¬ëŸ¼ì„ ë‚ ì§œ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df.set_index('timestamp', inplace=True)
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        meta_file = file_path.replace('.csv', '_meta.json')
        latest_values = {}
        if os.path.exists(meta_file):
            import json
            with open(meta_file, 'r', encoding='utf-8') as f:
                meta_data = json.load(f)
                latest_values = meta_data.get('latest_values', {})
        
        # ì „ì—­ ì €ì¥ì†Œì— ì €ì¥
        JOLTS_DATA['raw_data'] = df
        JOLTS_DATA['yoy_data'] = df.apply(calculate_yoy_change)
        JOLTS_DATA['mom_data'] = df.apply(calculate_mom_change)
        JOLTS_DATA['latest_values'] = latest_values
        JOLTS_DATA['load_info'] = {
            'loaded': True,
            'load_time': datetime.datetime.now(),
            'start_date': df.index[0].strftime('%Y-%m-%d') if len(df) > 0 else None,
            'series_count': len(df.columns),
            'data_points': len(df)
        }
        
        print(f"âœ… CSVì—ì„œ JOLTS ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {file_path}")
        print_load_info()
        return True
        
    except Exception as e:
        print(f"âŒ CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

# %%
# === ë©”ì¸ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ===

def load_all_jolts_data(start_date='2020-01-01', series_list=None, force_reload=False, csv_file='/home/jyp0615/us_eco/jolts_data.csv'):
    """
    JOLTS ë°ì´í„° ë¡œë“œ (CSV ìš°ì„ , API ë°±ì—… ë°©ì‹)
    
    Args:
        start_date: ì‹œì‘ ë‚ ì§œ
        series_list: ë¡œë“œí•  ì‹œë¦¬ì¦ˆ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  ì‹œë¦¬ì¦ˆ)
        force_reload: ê°•ì œ ì¬ë¡œë“œ ì—¬ë¶€
        csv_file: CSV íŒŒì¼ ê²½ë¡œ
    
    Returns:
        bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
    """
    global JOLTS_DATA
    
    # ì´ë¯¸ ë¡œë“œëœ ê²½ìš° ìŠ¤í‚µ
    if JOLTS_DATA['load_info']['loaded'] and not force_reload:
        print("ğŸ’¾ ì´ë¯¸ ë¡œë“œëœ ë°ì´í„° ì‚¬ìš© ì¤‘")
        print_load_info()
        return True
    
    # CSV íŒŒì¼ì´ ìˆìœ¼ë©´ ìš°ì„  ë¡œë“œ ì‹œë„
    import os
    if not force_reload and os.path.exists(csv_file):
        print("ğŸ“‚ ê¸°ì¡´ CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ ì‹œë„...")
        if load_jolts_data_from_csv(csv_file):
            print("ğŸ”„ CSV ë¡œë“œ í›„ ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸ ì‹œë„...")
            # CSV ë¡œë“œ ì„±ê³µ í›„ ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸
            update_jolts_data_from_api(smart_update=True)
            return True
        else:
            print("âš ï¸ CSV ë¡œë“œ ì‹¤íŒ¨, APIì—ì„œ ì „ì²´ ë¡œë“œ ì‹œë„...")
    
    print("ğŸš€ JOLTS ë°ì´í„° ë¡œë”© ì‹œì‘... (BLS API ì „ìš©)")
    print("="*50)
    
    # BLS API ì´ˆê¸°í™”
    if not initialize_bls_api():
        print("âŒ BLS API ì´ˆê¸°í™” ì‹¤íŒ¨")
        return False
    
    if series_list is None:
        series_list = list(JOLTS_SERIES.keys())
    
    # ë°ì´í„° ìˆ˜ì§‘
    raw_data_dict = {}
    yoy_data_dict = {}
    mom_data_dict = {}
    latest_values = {}
    
    for series_id in series_list:
        if series_id not in JOLTS_SERIES:
            print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì‹œë¦¬ì¦ˆ: {series_id}")
            continue
        
        # ì›ë³¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        start_year = pd.to_datetime(start_date).year
        series_data = get_bls_data(series_id, start_year)
        
        if series_data is not None and len(series_data) > 0:
            # ë‚ ì§œ í•„í„°ë§
            if start_date:
                series_data = series_data[series_data.index >= start_date]
            
            # NaN ì œê±°
            series_data = series_data.dropna()
            
            # ì „ì²´ ë¡œë“œì—ì„œëŠ” ìµœì†Œ 12ê°œ í•„ìš” (ì—…ë°ì´íŠ¸ê°€ ì•„ë‹ˆë¯€ë¡œ)
            if len(series_data) < 12:
                print(f"âŒ ë°ì´í„° ë¶€ì¡±: {series_id} ({len(series_data)}ê°œ)")
                continue
            
            # ì›ë³¸ ë°ì´í„° ì €ì¥
            raw_data_dict[series_id] = series_data
            
            # YoY ê³„ì‚°
            yoy_data = calculate_yoy_change(series_data)
            yoy_data_dict[series_id] = yoy_data
            
            # MoM ê³„ì‚°
            mom_data = calculate_mom_change(series_data)
            mom_data_dict[series_id] = mom_data
            
            # ìµœì‹  ê°’ ì €ì¥
            if len(series_data.dropna()) > 0:
                latest_val = series_data.dropna().iloc[-1]
                latest_values[series_id] = latest_val
            else:
                print(f"âš ï¸ ë°ì´í„° ì—†ìŒ: {series_id}")
        else:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {series_id}")
    
    # ë¡œë“œëœ ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì˜¤ë¥˜ ë°œìƒ
    if len(raw_data_dict) < 6:  # ìµœì†Œ 6ê°œ ì‹œë¦¬ì¦ˆëŠ” ìˆì–´ì•¼ í•¨
        error_msg = f"âŒ ë¡œë“œëœ ì‹œë¦¬ì¦ˆê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤: {len(raw_data_dict)}ê°œ (ìµœì†Œ 6ê°œ í•„ìš”)"
        print(error_msg)
        raise ValueError(error_msg)
    
    # ì „ì—­ ì €ì¥ì†Œì— ì €ì¥
    JOLTS_DATA['raw_data'] = pd.DataFrame(raw_data_dict)
    JOLTS_DATA['yoy_data'] = pd.DataFrame(yoy_data_dict)
    JOLTS_DATA['mom_data'] = pd.DataFrame(mom_data_dict)
    JOLTS_DATA['latest_values'] = latest_values
    JOLTS_DATA['load_info'] = {
        'loaded': True,
        'load_time': datetime.datetime.now(),
        'start_date': start_date,
        'series_count': len(raw_data_dict),
        'data_points': len(JOLTS_DATA['raw_data']) if not JOLTS_DATA['raw_data'].empty else 0
    }
    
    print("\nâœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
    print_load_info()
    
    # ìë™ìœ¼ë¡œ CSVì— ì €ì¥
    save_jolts_data_to_csv(csv_file)
    
    return True

def print_load_info():
    """ë¡œë“œ ì •ë³´ ì¶œë ¥"""
    info = JOLTS_DATA['load_info']
    if not info['loaded']:
        print("âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ")
        return
    
    print(f"ğŸ“Š ë¡œë“œëœ ë°ì´í„° ì •ë³´:")
    print(f"   ì‹œë¦¬ì¦ˆ ê°œìˆ˜: {info['series_count']}")
    print(f"   ë°ì´í„° í¬ì¸íŠ¸: {info['data_points']}")
    print(f"   ì‹œì‘ ë‚ ì§œ: {info['start_date']}")
    print(f"   ë¡œë“œ ì‹œê°„: {info['load_time'].strftime('%Y-%m-%d %H:%M:%S')}")
    
    if not JOLTS_DATA['raw_data'].empty:
        date_range = f"{JOLTS_DATA['raw_data'].index[0].strftime('%Y-%m')} ~ {JOLTS_DATA['raw_data'].index[-1].strftime('%Y-%m')}"
        print(f"   ë°ì´í„° ê¸°ê°„: {date_range}")

# %%
# === ë°ì´í„° ì ‘ê·¼ í•¨ìˆ˜ë“¤ ===

def get_raw_data(series_names=None):
    """ì›ë³¸ ë ˆë²¨ ë°ì´í„° ë°˜í™˜"""
    if not JOLTS_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_jolts_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return pd.DataFrame()
    
    if series_names is None:
        return JOLTS_DATA['raw_data'].copy()
    
    available_series = [s for s in series_names if s in JOLTS_DATA['raw_data'].columns]
    if not available_series:
        print(f"âš ï¸ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤: {series_names}")
        return pd.DataFrame()
    
    return JOLTS_DATA['raw_data'][available_series].copy()

def get_yoy_data(series_names=None):
    """YoY ë³€í™”ìœ¨ ë°ì´í„° ë°˜í™˜"""
    if not JOLTS_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_jolts_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return pd.DataFrame()
    
    if series_names is None:
        return JOLTS_DATA['yoy_data'].copy()
    
    available_series = [s for s in series_names if s in JOLTS_DATA['yoy_data'].columns]
    if not available_series:
        print(f"âš ï¸ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤: {series_names}")
        return pd.DataFrame()
    
    return JOLTS_DATA['yoy_data'][available_series].copy()

def get_mom_data(series_names=None):
    """ì „ì›”ëŒ€ë¹„ ë³€í™”ìœ¨ ë°ì´í„° ë°˜í™˜"""
    if not JOLTS_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_jolts_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return pd.DataFrame()
    
    if series_names is None:
        return JOLTS_DATA['mom_data'].copy()
    
    available_series = [s for s in series_names if s in JOLTS_DATA['mom_data'].columns]
    if not available_series:
        print(f"âš ï¸ ìš”ì²­í•œ ì‹œë¦¬ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤: {series_names}")
        return pd.DataFrame()
    
    return JOLTS_DATA['mom_data'][available_series].copy()

def get_latest_values(series_names=None):
    """ìµœì‹  ê°’ë“¤ ë°˜í™˜"""
    if not JOLTS_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_jolts_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return {}
    
    if series_names is None:
        return JOLTS_DATA['latest_values'].copy()
    
    return {name: JOLTS_DATA['latest_values'].get(name, 0) for name in series_names if name in JOLTS_DATA['latest_values']}

def list_available_series():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œë¦¬ì¦ˆ ëª©ë¡ ë°˜í™˜"""
    if not JOLTS_DATA['load_info']['loaded']:
        return []
    return list(JOLTS_DATA['raw_data'].columns)

# %%
# === ê³ ê¸‰ ë¶„ì„ í•¨ìˆ˜ë“¤ ===

def calculate_labor_market_tightness():
    """
    ë…¸ë™ì‹œì¥ íƒ€ì´íŠ¸ë‹ˆìŠ¤ ì§€í‘œ ê³„ì‚° (V/U ratio proxy)
    êµ¬ì¸/ì‹¤ì—…ì ë¹„ìœ¨ì˜ í”„ë¡ì‹œë¡œ êµ¬ì¸ê±´ìˆ˜ ì‚¬ìš©
    """
    if not JOLTS_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    # Total nonfarm job openings
    job_openings = get_raw_data(['JTS000000000000000JOL'])
    
    if job_openings.empty:
        return None
    
    # ë…¸ë™ì‹œì¥ íƒ€ì´íŠ¸ë‹ˆìŠ¤ ì§€í‘œ (ì •ê·œí™”)
    tightness = job_openings.copy()
    tightness.columns = ['Labor Market Tightness']
    
    return tightness

def calculate_hiring_efficiency():
    """
    ì±„ìš© íš¨ìœ¨ì„± ì§€í‘œ ê³„ì‚° (Hires/Job Openings)
    """
    if not JOLTS_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    hires = get_raw_data(['JTS000000000000000HIL'])
    openings = get_raw_data(['JTS000000000000000JOL'])
    
    if hires.empty or openings.empty:
        return None
    
    # ì±„ìš© íš¨ìœ¨ì„± = ì±„ìš©/êµ¬ì¸
    efficiency = (hires['JTS000000000000000HIL'] / openings['JTS000000000000000JOL']) * 100
    efficiency_df = pd.DataFrame({'Hiring Efficiency': efficiency})
    
    return efficiency_df

def calculate_layoff_rate_changes():
    """
    í•´ê³ ìœ¨ ë³€í™” ë¶„ì„ (ê²½ê¸°ì¹¨ì²´ ì‹ í˜¸)
    """
    if not JOLTS_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    layoffs = get_raw_data(['JTS000000000000000LDL'])
    
    if layoffs.empty:
        return None
    
    # 3ê°œì›” ì´ë™í‰ê· 
    layoffs_3m = calculate_3m_avg(layoffs)
    # ì „ë…„ë™ì›”ëŒ€ë¹„
    layoffs_yoy = calculate_yoy_change(layoffs)
    
    return {
        'raw': layoffs,
        '3m_avg': layoffs_3m,
        'yoy': layoffs_yoy
    }

def get_sector_rotation_signals():
    """
    ì„¹í„° ë¡œí…Œì´ì…˜ ì‹ í˜¸ ë¶„ì„
    """
    if not JOLTS_DATA['load_info']['loaded']:
        print("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    # ì£¼ìš” ì„¹í„°ë³„ êµ¬ì¸ ë°ì´í„°
    sectors = {
        'Manufacturing': 'JTS300000000000000JOL',
        'Financial': 'JTS510099000000000JOL',
        'Tech/Info': 'JTS510000000000000JOL',
        'Prof Services': 'JTS540099000000000JOL',
        'Leisure': 'JTS700000000000000JOL'
    }
    
    sector_data = {}
    for name, series_id in sectors.items():
        data = get_yoy_data([series_id])
        if not data.empty:
            sector_data[name] = data[series_id]
    
    return pd.DataFrame(sector_data)

# %%
# === KPDS í¬ë§· ì‹œê°í™” í•¨ìˆ˜ë“¤ ===

def create_jolts_overview_dashboard(start_date=None):
    """
    JOLTS ì¢…í•© ëŒ€ì‹œë³´ë“œ (í•œêµ­ì–´ ë²„ì „) - KPDS í¬ë§· ì ìš©
    """
    if not JOLTS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_jolts_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ë°ì´í„° ì¤€ë¹„
    openings = get_raw_data(['JTS000000000000000JOL'])['JTS000000000000000JOL']
    hires = get_raw_data(['JTS000000000000000HIL'])['JTS000000000000000HIL']
    layoffs = get_raw_data(['JTS000000000000000LDL'])['JTS000000000000000LDL']
    
    if start_date:
        openings = openings[openings.index >= start_date]
        hires = hires[hires.index >= start_date]
        layoffs = layoffs[layoffs.index >= start_date]
    
    # ê°œë³„ ì°¨íŠ¸ ìƒì„± (KPDS í¬ë§· ì ìš©)
    print("1. êµ¬ì¸ vs ì±„ìš© ì°¨íŠ¸ ìƒì„±...")
    data_dict = {
        'openings': openings,
        'hires': hires
    }
    labels_dict = {
        'openings': 'êµ¬ì¸',
        'hires': 'ì±„ìš©'
    }
    
    print("êµ¬ì¸ vs ì±„ìš©")
    fig1 = df_multi_line_chart(
        pd.DataFrame(data_dict),
        ytitle="ì²œ ê±´",
        labels=labels_dict
    )
    
    print("2. ë…¸ë™ì‹œì¥ íƒ€ì´íŠ¸ë‹ˆìŠ¤ ì°¨íŠ¸ ìƒì„±...")
    tightness_data = {'tightness': openings / hires}
    print("ë…¸ë™ì‹œì¥ íƒ€ì´íŠ¸ë‹ˆìŠ¤")
    fig2 = df_line_chart(
        pd.DataFrame(tightness_data),
        ytitle="êµ¬ì¸/ì±„ìš© ë¹„ìœ¨"
    )
    
    print("3. í•´ê³  ë™í–¥ ì°¨íŠ¸ ìƒì„±...")
    layoffs_3m = calculate_3m_avg(layoffs)
    layoffs_data = {
        'layoffs': layoffs,
        'layoffs_3m': layoffs_3m
    }
    layoffs_labels = {
        'layoffs': 'í•´ê³ ',
        'layoffs_3m': '3ê°œì›” í‰ê· '
    }
    print("í•´ê³  ë™í–¥")
    fig3 = df_multi_line_chart(
        pd.DataFrame(layoffs_data),
        ytitle="ì²œ ê±´",
        labels=layoffs_labels
    )
    
    print("4. ì±„ìš© íš¨ìœ¨ì„± ì°¨íŠ¸ ìƒì„±...")
    efficiency = calculate_hiring_efficiency()
    if efficiency is not None:
        print("ì±„ìš© íš¨ìœ¨ì„±")
        fig4 = df_line_chart(
            efficiency,
            ytitle="%"
        )
        return {'fig1': fig1, 'fig2': fig2, 'fig3': fig3, 'fig4': fig4}
    else:
        return {'fig1': fig1, 'fig2': fig2, 'fig3': fig3}

def create_sector_heatmap(metric='job_openings'):
    """
    ì„¹í„°ë³„ íˆíŠ¸ë§µ (ì „ë…„ë™ì›”ëŒ€ë¹„ ë³€í™”ìœ¨) - KPDS í¬ë§· ì ìš©
    
    Args:
        metric: 'job_openings', 'hires', 'layoffs'
    """
    if not JOLTS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_jolts_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ë©”íŠ¸ë¦­ë³„ ì‹œë¦¬ì¦ˆ ì„ íƒ
    suffix_map = {
        'job_openings': 'JOL',
        'hires': 'HIL',
        'layoffs': 'LDL'
    }
    
    metric_names = {
        'job_openings': 'êµ¬ì¸',
        'hires': 'ì±„ìš©',
        'layoffs': 'í•´ê³ '
    }
    
    suffix = suffix_map.get(metric, 'JOL')
    metric_name = metric_names.get(metric, 'êµ¬ì¸')
    
    # ì„¹í„° ë¦¬ìŠ¤íŠ¸ (í•œêµ­ì–´)
    sectors = {
        'ê´‘ì—… ë° ë²Œëª©ì—…': f'JTS110099000000000{suffix}',
        'ê±´ì„¤ì—…': f'JTS230000000000000{suffix}',
        'ì œì¡°ì—…': f'JTS300000000000000{suffix}',
        'ë¬´ì—­/ìš´ì†¡/ìœ í‹¸ë¦¬í‹°': f'JTS400000000000000{suffix}',
        'ì •ë³´ì‚°ì—…': f'JTS510000000000000{suffix}',
        'ê¸ˆìœµì—…': f'JTS510099000000000{suffix}',
        'ì „ë¬¸/ë¹„ì¦ˆë‹ˆìŠ¤ ì„œë¹„ìŠ¤': f'JTS540099000000000{suffix}',
        'êµìœ¡/ì˜ë£Œ ì„œë¹„ìŠ¤': f'JTS600000000000000{suffix}',
        'ë ˆì €/ìˆ™ë°•ì—…': f'JTS700000000000000{suffix}',
        'ê¸°íƒ€ ì„œë¹„ìŠ¤': f'JTS810000000000000{suffix}',
        'ì •ë¶€': f'JTS900000000000000{suffix}'
    }
    
    # YoY ë°ì´í„° ìˆ˜ì§‘
    yoy_data = get_yoy_data(list(sectors.values()))
    
    if yoy_data.empty:
        print("âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ìµœê·¼ 12ê°œì›” ë°ì´í„°
    recent_data = yoy_data.tail(12)
    
    # íˆíŠ¸ë§µ ë°ì´í„° ì¤€ë¹„
    heatmap_data = []
    for sector_name, series_id in sectors.items():
        if series_id in recent_data.columns:
            heatmap_data.append(recent_data[series_id].values)
    
    # ì›” ë¼ë²¨
    months = [d.strftime('%yë…„%mì›”') for d in recent_data.index]
    
    # KPDS í¬ë§· ì ìš© íˆíŠ¸ë§µ ìƒì„±
    fig = go.Figure(data=go.Heatmap(
        z=heatmap_data,
        x=months,
        y=list(sectors.keys()),
        colorscale='RdBu_r',
        zmid=0,
        text=[[f'{val:.1f}%' for val in row] for row in heatmap_data],
        texttemplate='%{text}',
        textfont={"size": FONT_SIZE_GENERAL-2, "family": "NanumGothic"},
        colorbar=dict(title="ì „ë…„ë™ì›”ëŒ€ë¹„ %", titlefont=dict(family='NanumGothic', size=FONT_SIZE_ANNOTATION))
    ))
    
    print(f"ì„¹í„°ë³„ íˆíŠ¸ë§µ - {metric_name} (ì „ë…„ë™ì›”ëŒ€ë¹„ % ë³€í™”)")
    
    # KPDS ìŠ¤íƒ€ì¼ ë ˆì´ì•„ì›ƒ
    fig.update_layout(
        width=1000,
        height=600,
        paper_bgcolor='white',
        plot_bgcolor='white',
        font=dict(family='NanumGothic', size=FONT_SIZE_GENERAL),
        xaxis=dict(
            showgrid=False,
            showline=True,
            linewidth=1.3,
            linecolor='lightgrey',
            tickfont=dict(family='NanumGothic', size=FONT_SIZE_GENERAL)
        ),
        yaxis=dict(
            showgrid=False,
            showline=False,
            tickfont=dict(family='NanumGothic', size=FONT_SIZE_GENERAL)
        ),
        margin=dict(l=200, r=80, t=80, b=80)
    )
    
    fig.show()
    return fig

def create_beveridge_curve(start_date='2020-01-01'):
    """
    ë² ë²„ë¦¬ì§€ ê³¡ì„  (Beveridge Curve) - êµ¬ì¸ íŠ¸ë Œë“œ í‘œì‹œ (KPDS í¬ë§· ì ìš©)
    """
    if not JOLTS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_jolts_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # êµ¬ì¸ ë°ì´í„°
    openings = get_raw_data(['JTS000000000000000JOL'])['JTS000000000000000JOL']
    
    if start_date:
        openings = openings[openings.index >= start_date]
    
    # KPDS í¬ë§·ìœ¼ë¡œ ë¼ì¸ ì°¨íŠ¸ ìƒì„±
    df = pd.DataFrame({'openings': openings})
    
    print("êµ¬ì¸ ë™í–¥ (ë² ë²„ë¦¬ì§€ ê³¡ì„  í”„ë¡ì‹œ)")
    fig = df_line_chart(
        df,
        column='openings',
        ytitle="ì²œ ê±´",
        label="êµ¬ì¸"
    )
    
    return fig

def create_labor_market_momentum():
    """
    ë…¸ë™ì‹œì¥ ëª¨ë©˜í…€ ì§€í‘œ ì°¨íŠ¸ (KPDS í¬ë§· ì ìš©)
    """
    if not JOLTS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_jolts_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ë°ì´í„° ì¤€ë¹„
    openings_mom = get_mom_data(['JTS000000000000000JOL'])['JTS000000000000000JOL']
    hires_mom = get_mom_data(['JTS000000000000000HIL'])['JTS000000000000000HIL']
    layoffs_mom = get_mom_data(['JTS000000000000000LDL'])['JTS000000000000000LDL']
    
    # 3ê°œì›” ì´ë™í‰ê· 
    openings_3m = calculate_3m_avg(openings_mom)
    hires_3m = calculate_3m_avg(hires_mom)
    layoffs_3m = calculate_3m_avg(layoffs_mom)
    
    # ë°ì´í„°í”„ë ˆì„ ìƒì„±
    momentum_data = {
        'openings': openings_3m,
        'hires': hires_3m,
        'layoffs': -layoffs_3m  # ìŒìˆ˜ë¡œ í‘œì‹œ
    }
    
    labels = {
        'openings': 'êµ¬ì¸ (3ê°œì›” í‰ê· )',
        'hires': 'ì±„ìš© (3ê°œì›” í‰ê· )',
        'layoffs': 'í•´ê³  (3ê°œì›” í‰ê· , ë°˜ì „)'
    }
    
    print("ë…¸ë™ì‹œì¥ ëª¨ë©˜í…€ ì§€í‘œ (ì „ì›”ëŒ€ë¹„ %, 3ê°œì›” ì´ë™í‰ê· )")
    
    # KPDS í¬ë§·ìœ¼ë¡œ ë‹¤ì¤‘ ë¼ì¸ ì°¨íŠ¸ ìƒì„±
    fig = df_multi_line_chart(
        pd.DataFrame(momentum_data),
        ytitle="%",
        labels=labels
    )
    
    return fig

def create_sector_comparison_chart(metric='job_openings', sectors=None):
    """
    ì„¹í„°ë³„ ë¹„êµ ì°¨íŠ¸ - KPDS í¬ë§· ì ìš©
    
    Args:
        metric: 'job_openings', 'hires', 'layoffs'
        sectors: ë¹„êµí•  ì„¹í„° ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ì£¼ìš” ì„¹í„°)
    """
    if not JOLTS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_jolts_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ê¸°ë³¸ ì„¹í„° ì„¤ì •
    if sectors is None:
        sectors = ['ì œì¡°ì—…', 'ê¸ˆìœµì—…', 'ê¸°ìˆ /ì •ë³´', 'ì „ë¬¸ì„œë¹„ìŠ¤', 'ë ˆì €']
    
    # ë©”íŠ¸ë¦­ë³„ ì‹œë¦¬ì¦ˆ ë§¤í•‘
    metric_map = {
        'job_openings': {
            'ì œì¡°ì—…': 'JTS300000000000000JOL',
            'ê¸ˆìœµì—…': 'JTS510099000000000JOL',
            'ê¸°ìˆ /ì •ë³´': 'JTS510000000000000JOL',
            'ì „ë¬¸ì„œë¹„ìŠ¤': 'JTS540099000000000JOL',
            'ë ˆì €': 'JTS700000000000000JOL',
            'ê±´ì„¤ì—…': 'JTS230000000000000JOL',
            'ë¬´ì—­': 'JTS400000000000000JOL',
            'êµìœ¡/ì˜ë£Œ': 'JTS600000000000000JOL'
        },
        'hires': {
            'ì œì¡°ì—…': 'JTS300000000000000HIL',
            'ê¸ˆìœµì—…': 'JTS510099000000000HIL',
            'ê¸°ìˆ /ì •ë³´': 'JTS510000000000000HIL',
            'ì „ë¬¸ì„œë¹„ìŠ¤': 'JTS540099000000000HIL',
            'ë ˆì €': 'JTS700000000000000HIL',
            'ê±´ì„¤ì—…': 'JTS230000000000000HIL',
            'ë¬´ì—­': 'JTS400000000000000HIL',
            'êµìœ¡/ì˜ë£Œ': 'JTS600000000000000HIL'
        },
        'layoffs': {
            'ì œì¡°ì—…': 'JTS300000000000000LDL',
            'ê¸ˆìœµì—…': 'JTS510099000000000LDL',
            'ê¸°ìˆ /ì •ë³´': 'JTS510000000000000LDL',
            'ì „ë¬¸ì„œë¹„ìŠ¤': 'JTS540099000000000LDL',
            'ë ˆì €': 'JTS700000000000000LDL',
            'ê±´ì„¤ì—…': 'JTS230000000000000LDL',
            'ë¬´ì—­': 'JTS400000000000000LDL',
            'êµìœ¡/ì˜ë£Œ': 'JTS600000000000000LDL'
        }
    }
    
    series_map = metric_map.get(metric, metric_map['job_openings'])
    
    # ë°ì´í„° ìˆ˜ì§‘
    data_dict = {}
    for sector in sectors:
        if sector in series_map:
            series_id = series_map[sector]
            data = get_raw_data([series_id])
            
            if not data.empty:
                # ìµœê·¼ 2ë…„ ë°ì´í„°
                recent_data = data[series_id].tail(24)
                data_dict[sector] = recent_data
    
    if not data_dict:
        print("âš ï¸ í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # DataFrame ìƒì„±
    df = pd.DataFrame(data_dict)
    
    # ë ˆì´ì•„ì›ƒ
    title_map = {
        'job_openings': 'ì„¹í„°ë³„ êµ¬ì¸ í˜„í™©',
        'hires': 'ì„¹í„°ë³„ ì±„ìš© í˜„í™©',
        'layoffs': 'ì„¹í„°ë³„ í•´ê³  í˜„í™©'
    }
    
    ytitle_map = {
        'job_openings': 'ì²œ ê±´',
        'hires': 'ì²œ ê±´',
        'layoffs': 'ì²œ ê±´'
    }
    
    print(title_map.get(metric, 'ì„¹í„°ë³„ ë…¸ë™ì‹œì¥ ì§€í‘œ'))
    
    # KPDS í¬ë§·ìœ¼ë¡œ ë‹¤ì¤‘ ë¼ì¸ ì°¨íŠ¸ ìƒì„±
    fig = df_multi_line_chart(
        df,
        ytitle=ytitle_map.get(metric, 'ì²œ ëª…'),
        labels=dict(zip(sectors, sectors))
    )
    
    return fig

def create_ib_style_summary_table():
    """
    IB ìŠ¤íƒ€ì¼ ìš”ì•½ í…Œì´ë¸” ìƒì„± (í•œêµ­ì–´)
    """
    if not JOLTS_DATA['load_info']['loaded']:
        print("âš ï¸ ë¨¼ì € load_all_jolts_data()ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        return None
    
    # ì£¼ìš” ì§€í‘œ ìˆ˜ì§‘
    indicators = {
        'ì „ì²´ êµ¬ì¸': 'JTS000000000000000JOL',
        'ì „ì²´ ì±„ìš©': 'JTS000000000000000HIL',
        'ì „ì²´ í•´ê³ ': 'JTS000000000000000LDL',
        'ì œì¡°ì—… êµ¬ì¸': 'JTS300000000000000JOL',
        'ê¸ˆìœµì—… êµ¬ì¸': 'JTS510099000000000JOL',
        'ê¸°ìˆ ì—… êµ¬ì¸': 'JTS510000000000000JOL',
        'ì „ë¬¸ì„œë¹„ìŠ¤ êµ¬ì¸': 'JTS540099000000000JOL'
    }
    
    # í…Œì´ë¸” ë°ì´í„° ì¤€ë¹„
    table_data = []
    
    for name, series_id in indicators.items():
        raw_data = get_raw_data([series_id])
        yoy_data = get_yoy_data([series_id])
        mom_data = get_mom_data([series_id])
        
        if not raw_data.empty:
            latest_val = raw_data[series_id].iloc[-1]
            yoy_val = yoy_data[series_id].iloc[-1] if not yoy_data.empty else np.nan
            mom_val = mom_data[series_id].iloc[-1] if not mom_data.empty else np.nan
            
            # 3ê°œì›” í‰ê· 
            mom_3m = calculate_3m_avg(mom_data[series_id])
            mom_3m_val = mom_3m.iloc[-1] if len(mom_3m) > 0 else np.nan
            
            table_data.append({
                'ì§€í‘œ': name,
                'ìµœì‹ ê°’': f"{latest_val:,.0f}",
                'ì „ì›”ëŒ€ë¹„(%)': f"{mom_val:+.1f}%" if not np.isnan(mom_val) else "N/A",
                'ì „ë…„ë™ì›”ëŒ€ë¹„(%)': f"{yoy_val:+.1f}%" if not np.isnan(yoy_val) else "N/A",
                '3ê°œì›”í‰ê· (%)': f"{mom_3m_val:+.1f}%" if not np.isnan(mom_3m_val) else "N/A"
            })
    
    # DataFrame ìƒì„±
    df = pd.DataFrame(table_data)
    
    # í…Œì´ë¸” ì‹œê°í™”
    fig = go.Figure(data=[go.Table(
        header=dict(
            values=list(df.columns),
            fill_color='darkblue',
            font=dict(color='white', size=14, family='NanumGothic'),
            align='left'
        ),
        cells=dict(
            values=[df[col] for col in df.columns],
            fill_color=[['lightgray' if i % 2 == 0 else 'white' for i in range(len(df))]],
            font=dict(color='black', size=12, family='NanumGothic'),
            align='left'
        )
    )])
    
    latest_date = JOLTS_DATA['raw_data'].index[-1].strftime('%B %Y')
    
    print(f"JOLTS ì£¼ìš” ì§€í‘œ ìš”ì•½ - {latest_date}")
    
    fig.update_layout(
        width=900,
        height=400,
        paper_bgcolor='white',
        font=dict(family='NanumGothic')
    )
    
    fig.show()
    return fig

# %%
# === í†µí•© ë¶„ì„ í•¨ìˆ˜ ===

def run_complete_jolts_analysis(start_date='2020-01-01', force_reload=False):
    """
    ì™„ì „í•œ JOLTS ë¶„ì„ ì‹¤í–‰ - IB/ì´ì½”ë…¸ë¯¸ìŠ¤íŠ¸ ê´€ì  (KPDS í¬ë§· ì ìš©)
    
    Args:
        start_date: ë°ì´í„° ì‹œì‘ ë‚ ì§œ
        force_reload: ê°•ì œ ì¬ë¡œë“œ ì—¬ë¶€
    
    Returns:
        dict: ìƒì„±ëœ ì°¨íŠ¸ë“¤
    """
    print("ğŸš€ ì™„ì „í•œ JOLTS ë…¸ë™ì‹œì¥ ë¶„ì„ ì‹œì‘ (KPDS í¬ë§·)")
    print("="*50)
    
    # 1. ë°ì´í„° ë¡œë“œ
    print("\n1ï¸âƒ£ ë°ì´í„° ë¡œë”©")
    success = load_all_jolts_data(start_date=start_date, force_reload=force_reload)
    
    if not success:
        print("âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨")
        return None
    
    # 2. ë¶„ì„ ë° ì‹œê°í™” ìƒì„±
    print("\n2ï¸âƒ£ ë¶„ì„ ë° ì‹œê°í™” ìƒì„±")
    
    results = {}
    
    try:
        # IB ìŠ¤íƒ€ì¼ ìš”ì•½ í…Œì´ë¸”
        print("   ğŸ“Š ìš”ì•½ í…Œì´ë¸” ìƒì„±...")
        results['summary_table'] = create_ib_style_summary_table()
        
        # ì¢…í•© ëŒ€ì‹œë³´ë“œ
        print("   ğŸ“ˆ ì¢…í•© ëŒ€ì‹œë³´ë“œ...")
        results['overview_dashboard'] = create_jolts_overview_dashboard()
        
        # ë…¸ë™ì‹œì¥ ëª¨ë©˜í…€
        print("   ğŸ“ˆ ë…¸ë™ì‹œì¥ ëª¨ë©˜í…€ ë¶„ì„...")
        results['momentum'] = create_labor_market_momentum()
        
        # ì„¹í„° íˆíŠ¸ë§µ
        print("   ğŸ”¥ ì„¹í„°ë³„ íˆíŠ¸ë§µ...")
        results['sector_heatmap'] = create_sector_heatmap('job_openings')
        
        # ë² ë²„ë¦¬ì§€ ê³¡ì„ 
        print("   ğŸ“Š ë² ë²„ë¦¬ì§€ ê³¡ì„  í”„ë¡ì‹œ...")
        results['beveridge_curve'] = create_beveridge_curve()
        
        # ì„¹í„° ë¹„êµ
        print("   ğŸ“Š ì£¼ìš” ì„¹í„° ë¹„êµ...")
        results['sector_comparison'] = create_sector_comparison_chart('job_openings')
        
    except Exception as e:
        print(f"âš ï¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
    
    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ! ìƒì„±ëœ ì°¨íŠ¸: {len(results)}ê°œ")
    return results

# %%
# === ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ===

def clear_data():
    """ë°ì´í„° ì´ˆê¸°í™”"""
    global JOLTS_DATA
    JOLTS_DATA = {
        'raw_data': pd.DataFrame(),
        'yoy_data': pd.DataFrame(),
        'mom_data': pd.DataFrame(),
        'rates_data': pd.DataFrame(),
        'latest_values': {},
        'load_info': {'loaded': False, 'load_time': None, 'start_date': None, 'series_count': 0, 'data_points': 0}
    }
    print("ğŸ—‘ï¸ ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤")

def show_available_components():
    """ì‚¬ìš© ê°€ëŠ¥í•œ JOLTS êµ¬ì„±ìš”ì†Œ í‘œì‹œ"""
    print("=== ì‚¬ìš© ê°€ëŠ¥í•œ JOLTS êµ¬ì„±ìš”ì†Œ ===")
    
    for series_id, description in JOLTS_SERIES.items():
        korean_name = JOLTS_KOREAN_NAMES.get(series_id, description)
        print(f"  '{series_id}': {korean_name} ({description})")

def get_data_status():
    """í˜„ì¬ ë°ì´í„° ìƒíƒœ ë°˜í™˜"""
    return {
        'loaded': JOLTS_DATA['load_info']['loaded'],
        'series_count': JOLTS_DATA['load_info']['series_count'],
        'available_series': list_available_series(),
        'load_info': JOLTS_DATA['load_info']
    }

def show_jolts_hierarchy():
    """JOLTS ê³„ì¸µ êµ¬ì¡° í‘œì‹œ"""
    print("=== JOLTS ê³„ì¸µ êµ¬ì¡° ===\n")
    
    for level, groups in JOLTS_HIERARCHY.items():
        print(f"### {level} ###")
        for group_name, series_list in groups.items():
            print(f"  {group_name}:")
            for series_id in series_list:
                korean_name = JOLTS_KOREAN_NAMES.get(series_id, JOLTS_SERIES.get(series_id, series_id))
                print(f"    - {series_id}: {korean_name}")
        print()

# %%
# === ì‚¬ìš© ì˜ˆì‹œ ===

print("\n=== JOLTS ë…¸ë™ì‹œì¥ ë¶„ì„ ë„êµ¬ ì‚¬ìš©ë²• (KPDS í¬ë§·) ===")
print("1. ë°ì´í„° ë¡œë“œ (CSV ìš°ì„ , API ë°±ì—…, ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸):")
print("   load_all_jolts_data()  # CSVê°€ ìˆìœ¼ë©´ ë¡œë“œ í›„ ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸")
print("   load_jolts_data_from_csv()  # CSVì—ì„œë§Œ ë¡œë“œ")
print("   update_jolts_data_from_api()  # ìµœì‹  ë°ì´í„°ë§Œ APIë¡œ ì—…ë°ì´íŠ¸")
print()
print("2. ë°ì´í„° ì €ì¥:")
print("   save_jolts_data_to_csv()  # í˜„ì¬ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥")
print()
print("3. KPDS í¬ë§· ë¶„ì„:")
print("   create_ib_style_summary_table()  # í•œêµ­ì–´ ìš”ì•½ í…Œì´ë¸”")
print("   create_jolts_overview_dashboard()  # KPDS ì¢…í•© ëŒ€ì‹œë³´ë“œ")
print("   create_labor_market_momentum()  # KPDS ëª¨ë©˜í…€ ì§€í‘œ")
print("   create_sector_heatmap()  # KPDS ì„¹í„° íˆíŠ¸ë§µ")
print("   create_beveridge_curve()  # KPDS ë² ë²„ë¦¬ì§€ ê³¡ì„ ")
print("   create_sector_comparison_chart()  # KPDS ì„¹í„° ë¹„êµ")
print()
print("4. ê³ ê¸‰ ë¶„ì„ í•¨ìˆ˜:")
print("   calculate_labor_market_tightness()  # ë…¸ë™ì‹œì¥ íƒ€ì´íŠ¸ë‹ˆìŠ¤")
print("   calculate_hiring_efficiency()  # ì±„ìš© íš¨ìœ¨ì„±")
print("   calculate_layoff_rate_changes()  # í•´ê³ ìœ¨ ë³€í™”")
print("   get_sector_rotation_signals()  # ì„¹í„° ë¡œí…Œì´ì…˜ ì‹ í˜¸")
print()
print("5. í†µí•© ë¶„ì„:")
print("   run_complete_jolts_analysis()  # ì „ì²´ KPDS ë¶„ì„ ì‹¤í–‰")
print()
print("6. ë°ì´í„° ìƒíƒœ í™•ì¸:")
print("   get_data_status()")
print("   show_available_components()")
print("   show_jolts_hierarchy()")

# %%
# ì‚¬ìš© ê°€ëŠ¥í•œ êµ¬ì„±ìš”ì†Œ í‘œì‹œ
show_available_components()

# %%
# ì˜ˆì‹œ ì‹¤í–‰ (ì£¼ì„ ì²˜ë¦¬)
run_complete_jolts_analysis()
# %%
create_beveridge_curve()
# %%
